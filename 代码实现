#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pandas as pd
import numpy as np
import os
import time
import pickle
from datetime import datetime
import pdb
import torch
import torch.nn as nn
import torch.nn.functional as F

import lightgbm as lgb

from sklearn.metrics import roc_auc_score
from collections import defaultdict
from functools import partial
import random
import torch.backends.cudnn as cudnn

import gc

import warnings 
warnings.filterwarnings('ignore')

from typing import Any
import functools
nesting_level = 0
is_start = None

version = datetime.now().strftime("%Y%m%d%H%M%S")
print('Version: ', version)

pd.set_option('max_columns',100)
pd.set_option('max_rows',100)


#是不是直接加载模型，开始预测，为None则不
load = '20201211153132.models'
load = None

#验证模式还是测试模式
valid = True
#线下跑还是线上跑，控制测试集是自己构造还是调用他的接口，提交时要改这个
offline = True

debug = True

seed = 2021
block_num = 10

# N = 3

#tags 特征使用
max_tags = 187

#1:正常没差别，2:特征如同线上一般训练
valid_mode = 2

if (not offline) and (load is None):
    pre = '/online train/input'
else:
    pre = '/input'
    
if debug:
    debug_pre = '/debug'
else:
    debug_pre = ''
    

#由于极其特殊的有些全局统计，会造成valid_mode 2模式下，特征不完全一致，故分开存valid和train的特征
if valid:
    valid_pre = '/valid'
else:
    valid_pre = ''

lgb_model_dir = f'..{valid_pre}{debug_pre}{pre}/user-data/lgb_model/'
all_model_dir = f'..{valid_pre}{debug_pre}{pre}/user-data/all_model/'
feat_dir = f'..{valid_pre}{debug_pre}{pre}/user-data/feat_data/'
feat_merge_dir = f'..{valid_pre}{debug_pre}{pre}/user-data/feat_merge_dir/'
table_dir = f'..{valid_pre}{debug_pre}{pre}/user-data/table_dir/'
test_intermediate_feat_dir = f'..{valid_pre}{debug_pre}{pre}/user-data/test_intermediate_feat_dir/'
feat_imp_dir = f'..{valid_pre}{debug_pre}{pre}/user-data/feat_imp/'
valid_train_data_dir = f'..{valid_pre}{debug_pre}{pre}/user-data/valid_train_data_dir/'
valid_test_data_dir = f'..{valid_pre}{debug_pre}{pre}/user-data/valid_test_data_dir/'
train_data_dir = f'..{valid_pre}{debug_pre}{pre}/user-data/train_data_dir/'


if offline or (load is None):
    if not os.path.exists(lgb_model_dir):
        os.makedirs(lgb_model_dir)
    
    if not os.path.exists(all_model_dir):
        os.makedirs(all_model_dir)
    
    if not os.path.exists(feat_dir):
        os.makedirs(feat_dir)
        
    if not os.path.exists(feat_merge_dir):
        os.makedirs(feat_merge_dir)
        
    if not os.path.exists(table_dir):
        os.makedirs(table_dir)
        
    if not os.path.exists(test_intermediate_feat_dir):
        os.makedirs(test_intermediate_feat_dir)
    
    if not os.path.exists(feat_imp_dir):
        os.makedirs(feat_imp_dir)
        
    if not os.path.exists(valid_train_data_dir):
        os.makedirs(valid_train_data_dir)
        
    if not os.path.exists(valid_test_data_dir):
        os.makedirs(valid_test_data_dir)
        
    if not os.path.exists(train_data_dir):
        os.makedirs(train_data_dir)


def log(entry: Any):
    global nesting_level
    space = "-" * (4 * nesting_level)
    print(f"{space}{entry}")

def timeclass(cls):
    def timeit(method, start_log=None):
        @functools.wraps(method)
        def timed(*args, **kw):
            global is_start
            global nesting_level
    
            if not is_start:
                print()
    
            is_start = True
            log(f"Start [{cls}.{method.__name__}]:" + (start_log if start_log else ""))
            log(f'Start time: {time.strftime("%Y-%m-%d %H:%M:%S")}')
            nesting_level += 1
    
            start_time = time.time()
            result = method(*args, **kw)
            end_time = time.time()
    
            nesting_level -= 1
            log(f"End   [{cls}.{method.__name__}]. Time elapsed: {end_time - start_time:0.2f} sec.")
            log(f'End time: {time.strftime("%Y-%m-%d %H:%M:%S")}')
            is_start = False
    
            return result
    
        return timed
    return timeit

def timeit(method, start_log=None):
    @functools.wraps(method)
    def timed(*args, **kw):
        global is_start
        global nesting_level

        if not is_start:
            print()

        is_start = True
        log(f"Start [{method.__name__}]:" + (start_log if start_log else ""))
        nesting_level += 1

        start_time = time.time()
        result = method(*args, **kw)
        end_time = time.time()

        nesting_level -= 1
        log(f"End   [{method.__name__}]. Time elapsed: {end_time - start_time:0.2f} sec.")
        is_start = False

        return result

    return timed
        
        
def downcast(series,accuracy_loss = True, min_float_type='float16'):
    if series.dtype == np.int64 or series.dtype == np.uint64:
        ii8 = np.iinfo(np.int8)
        ii16 = np.iinfo(np.int16)
        ii32 = np.iinfo(np.int32)
        max_value = series.max()
        min_value = series.min()
        
        if max_value <= ii8.max and min_value >= ii8.min:
            return series.astype(np.int8)
        elif  max_value <= ii16.max and min_value >= ii16.min:
            return series.astype(np.int16)
        elif max_value <= ii32.max and min_value >= ii32.min:
            return series.astype(np.int32)
        else:
            return series
        
    elif series.dtype == np.float64:
        fi16 = np.finfo(np.float16)
        fi32 = np.finfo(np.float32)
        
        if accuracy_loss:
            max_value = series.max()
            min_value = series.min()
            if np.isnan(max_value):
                max_value = 0
            
            if np.isnan(min_value):
                min_value = 0
                
            if min_float_type=='float16' and max_value <= fi16.max and min_value >= fi16.min:
                return series.astype(np.float16)
            elif max_value <= fi32.max and min_value >= fi32.min:
                return series.astype(np.float32)
            else:
                return series
        else:
            tmp = series[~pd.isna(series)]
            if(len(tmp)==0):
                return series.astype(np.float16)
            
            if (tmp == tmp.astype(np.float16)).sum() == len(tmp):
                return series.astype(np.float16)
            elif (tmp == tmp.astype(np.float32)).sum() == len(tmp):
                return series.astype(np.float32)
           
            else:
                return series
            
    else:
        return series
    
# @timeit    
# def load_pickle(file_path):
#     file_dir = file_path[:-4]
#     # if ('feat_data' in file_path) and os.path.exists(file_dir):
#     if os.path.exists(file_dir):
#         datas = []
#         for block_id in range(block_num):
#             file_path = file_dir+'/'+str(block_id)+'.pkl'
#             datas.append( pickle.load( open(file_path,'rb') ) )
#         data = pd.concat( datas )
#         return data
#     else:
#         return pickle.load( open(file_path,'rb') )
    
# @timeit    
# def dump_pickle(obj,file_path):
#     # if ('feat_data' in file_path) and (type(obj) == pd.core.frame.DataFrame) and obj.shape[1]>=5 :
#     if (type(obj) == pd.core.frame.DataFrame) and obj.shape[1]>=5:
#         block_len = len(obj)//block_num
#         file_dir = file_path[:-4]
#         if not os.path.exists(file_dir):
#             os.makedirs( file_dir )
#         for block_id in range(block_num):
#             file_path = file_dir+'/'+str(block_id)+'.pkl'
#             l = block_id * block_len
#             r = (block_id+1) * block_len
#             if block_id == block_num - 1:
#                 pickle.dump( obj.iloc[l:], open(file_path,'wb') )
#             else:
#                 pickle.dump( obj.iloc[l:r], open(file_path,'wb') )
#     else:
#         pickle.dump(obj,open(file_path,'wb'))
    

def load_pickle(file_path):
    return pickle.load(open(file_path,'rb'))

def dump_pickle(obj,file_path):
    pickle.dump(obj,open(file_path,'wb'),protocol=4)
    
def boolean2int(series):
    tmp = pd.Series(np.ones(series.shape[0])*-1,index=series.index,dtype='int8')
    tmp[series==True] = 1
    tmp[series==False] = 0
    
    return tmp

@timeit
def make_submit_zip():
    import os, zipfile
    submit_dir = f'../input/'
    if not os.path.exists(submit_dir):
        os.makedirs(submit_dir)
    
    print('开始结果文件压缩')
    zipf = zipfile.ZipFile(f'{submit_dir}{version}-user_data.zip', 'w', compression=zipfile.ZIP_DEFLATED)
    
    #user的编码
    zipf.write(table_dir+'code2cats.pkl', f'/table_dir/code2cats.pkl')
    zipf.write(table_dir+'cats2code.pkl', f'/table_dir/cats2code.pkl')
    
    #模型文件
    if load is not None:
        zipf.write(all_model_dir+load, f'/all_model/{load}')
    else:
        zipf.write(all_model_dir+version+'.models', f'/all_model/{version}.models')
    
    #中间变量
    first_merge_pipeline = FirstMergeFeatPipeline()
    merge_pipeline = MergeFeatPipeline()
    
    for feat in first_merge_pipeline.feats + merge_pipeline.feats:
        feat.__name__
    
        zipf.write(test_intermediate_feat_dir+feat.__name__+'.pkl', f'/test_intermediate_feat_dir/{feat.__name__}.pkl')
    
    zipf.close()
    print('压缩完成')
    
@timeit
def make_small_model_big_data_submit_zip():
    import os, zipfile
    submit_dir = f'../input/'
    if not os.path.exists(submit_dir):
        os.makedirs(submit_dir)
    
    print('开始结果文件压缩')
    zipf = zipfile.ZipFile(f'{submit_dir}user_data.zip', 'w', compression=zipfile.ZIP_DEFLATED)
    
    
    #user的编码
    zipf.write('../input/user-data/table_dir/'+'code2cats.pkl', f'/table_dir/code2cats.pkl')
    zipf.write('../input/user-data/table_dir/'+'cats2code.pkl', f'/table_dir/cats2code.pkl')
    
    #模型文件加载debug模式的模型
    if load is None:
        zipf.write(f'../debug/input/user-data/all_model/{version}.models', f'/all_model/{version}.models')
    else:
        zipf.write(f'../debug/input/user-data/all_model/{load}', f'/all_model/{load}')
    
    #中间变量
    first_merge_pipeline = FirstMergeFeatPipeline()
    merge_pipeline = MergeFeatPipeline()
    
    for feat in first_merge_pipeline.feats + merge_pipeline.feats:
        zipf.write('../input/user-data/test_intermediate_feat_dir/'+feat.__name__+'.pkl', f'/test_intermediate_feat_dir/{feat.__name__}.pkl')
    
    zipf.close()
    print('压缩完成')

def fix_seed(seed):
    os.environ['PYTHONHASHSEED'] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    cudnn.enabled = True
    cudnn.benchmark = True
    cudnn.deterministic = True
    
def lgb_shap_explainer(model,data_x):
    # https://zhuanlan.zhihu.com/p/101352812?utm_source=qq
    # https://blog.csdn.net/fjssharpsword/article/details/108533474
    
    import shap
    explainer = shap.TreeExplainer(model)
    expected_value = explainer.expected_value
    if isinstance(expected_value, list):
        expected_value = expected_value[1]
    
    print(f"Explainer expected value: {expected_value}")
    
    shap_values = explainer.shap_values(data_x)[1]
    
    
    shap.decision_plot(expected_value, shap_values, model.feature_name())
    
def different_history_num_auc(model):
    test_X,test_Y = load_pickle(valid_test_data_dir+'valid_test_data_dir.pkl')
    test_X['pred'] = model.predict(test_X)
    test_X['label'] = test_Y
    result = []

    for i in np.sort(test_X['feat_user_this_question_history_nums'].unique()):
        tmp = test_X.loc[test_X['feat_user_this_question_history_nums']==i]
        if tmp['label'].nunique() == 1:
            auc = np.nan
        else:
            auc = roc_auc_score(tmp['label'],tmp['pred'])
        result.append([i,tmp.shape[0],tmp['label'].mean(),tmp['pred'].mean(),auc])
    result = pd.DataFrame(result,columns=['history_num','sample_size','label_mean','pred_mean','auc'])
    print(result)
    return result

def different_user_num_auc(model):
    test_X,test_Y = load_pickle(valid_test_data_dir+'valid_test_data_dir.pkl')
    test_X['pred'] = model.predict(test_X)
    test_X['label'] = test_Y
    result = []
    
    test_X['bin'] = pd.qcut(test_X['feat_user_history_question_nums'],10)
    max_num = test_X['feat_user_history_question_nums'].max()+1
    
    
    for i in np.sort(test_X['bin'].unique()):
        tmp = test_X.loc[test_X['bin']==i]
        if tmp['label'].nunique() == 1:
            auc = np.nan
        else:
            auc = roc_auc_score(tmp['label'],tmp['pred'])
        result.append([i,tmp.shape[0],tmp['label'].mean(),tmp['pred'].mean(),auc])
    result = pd.DataFrame(result,columns=['history_num','sample_size','label_mean','pred_mean','auc'])
    print(result)
    return result

def get_time_weight(train_data):
    tmp = train_data[['user_id','task_container_id']].copy()
    tmp['new_container'] = 1
    
    tmp_first = tmp.groupby(['user_id','task_container_id'],sort=False).first()
    tmp_first = tmp_first.groupby('user_id',sort=False).cumsum()
    
    tmp_median = tmp_first.groupby('user_id')['new_container'].median()
    
    tmp_first = tmp_first.reset_index()
    
    tmp_first['container_median'] = tmp_first['user_id'].map(tmp_median)
    
    tmp_first['weight'] = 0.9
    tmp_first.loc[tmp_first['new_container']>tmp_first['container_median'],'weight'] = 1.1
    
    tmp_first = tmp_first[['user_id','task_container_id','weight']]
    tmp = tmp.merge(tmp_first,how='left',on=['user_id','task_container_id'])
    
    time_weight = tmp['weight'].values
    
    
    return time_weight
    

class Table:
    def __init__(self):
        self.df = None
        self.df_model = None
        
        self.lectures_info = None
        self.questions_info = None
        
        self.df_test = None
        self.df_test_model = None
        
        self.last_group = None
        self.last_group_model = None
        
        self.all_history_test = None
        self.all_history_test_model = None
        
        self.init_cols = ['user_id','content_id','task_container_id','prior_question_elapsed_time','prior_question_had_explanation','timestamp']
        self.columns = ['timestamp', 'user_id', 'content_id', 'content_type_id',
                       'task_container_id', 'user_answer', 'answered_correctly',
                       'prior_question_elapsed_time', 'prior_question_had_explanation']
        
        self.cats2code = {}
        self.code2cats = {}
        
    
    @timeclass('Table')
    def read_data(self):
        dtypes = {
            # "row_id": "int64",
            "timestamp": "int64",
            "user_id": "int32",
            "content_id": "int16",
            "content_type_id": "boolean",
            "task_container_id": "int16",
            "user_answer": "int8",
            "answered_correctly": "int8",
            "prior_question_elapsed_time": "float32", 
            "prior_question_had_explanation": "boolean"
        }
        
        cols = ['timestamp','user_id','content_id','content_type_id','task_container_id','user_answer','answered_correctly','prior_question_elapsed_time','prior_question_had_explanation']
        
        nrows = None
        if debug:
            nrows = 2.5e7
        
        self.df = pd.read_csv("../input/riiid-test-answer-prediction/train.csv",usecols=cols,dtype=dtypes,nrows=nrows)
        self.lectures_info = pd.read_csv('../input/riiid-test-answer-prediction/lectures.csv')
        self.questions_info = pd.read_csv('../input/riiid-test-answer-prediction/questions.csv')
        
        self.lectures_info['part'] -= 1
        self.questions_info['part'] -= 1
        
        #有196条异常数据，剔除
        self.df.drop_duplicates(subset=['user_id','content_id','task_container_id'],keep='first',inplace=True)
        self.df = self.df.reset_index(drop=True)
        
        self.encoding_cats()
        
        self.df['prior_question_had_explanation'] = boolean2int(self.df['prior_question_had_explanation'])
        
        # self.df_lectures = self.df[self.df['content_type_id']].reset_index(drop=True)
        # self.df = self.df[~self.df['content_type_id']].reset_index(drop=True)
        
        # self.df.drop(columns=['content_type_id'],inplace=True)
        # self.df_lectures.drop(columns=['content_type_id'],inplace=True)
        
        
        self.df_model = self.df.loc[~self.df['content_type_id'],self.init_cols+['answered_correctly']].reset_index(drop=True)
        self.df_model.rename(columns={'answered_correctly':'label'},inplace=True)
        
    
    @timeclass('Table')
    def encoding_cats(self):
        cats = pd.Categorical(self.df['user_id'])
        self.code2cats['user_id'] = cats.categories.values
        self.cats2code['user_id'] = {self.code2cats['user_id'][i]:i for i in range(len(self.code2cats['user_id']))}
        self.df['user_id'] = cats.codes
        self.df['user_id'] = self.df['user_id'].astype(np.int32)
        
        #tag，线上数据集更新了，不需要重编码了
        for col in ['lecture_id','type_of']:
            cats = pd.Categorical(self.lectures_info[col])
            self.code2cats[col] = cats.categories.values
            self.cats2code[col] = {self.code2cats[col][i]:i for i in range(len(self.code2cats[col]))}
            self.lectures_info[col] = cats.codes
            
            self.lectures_info[col] = downcast(self.lectures_info[col])
            
        self.df.loc[self.df['content_type_id'],'content_id'] = self.df.loc[self.df['content_type_id'],'content_id'].map(self.cats2code['lecture_id'])
        
        
    @timeclass('Table')
    def save_table(self):
        dump_pickle(self.df,table_dir+'df.pkl')
        dump_pickle(self.df_model,table_dir+'df_model.pkl')
            
        dump_pickle(self.lectures_info,table_dir+'lectures_info.pkl')
        dump_pickle(self.questions_info,table_dir+'questions_info.pkl')
        
        dump_pickle(self.code2cats,table_dir+'code2cats.pkl')
        dump_pickle(self.cats2code,table_dir+'cats2code.pkl')
        
        
    @timeclass('Table')
    def load_table(self):
        self.df = load_pickle(table_dir+'df.pkl')
        self.df_model = load_pickle(table_dir+'df_model.pkl')
            
        self.lectures_info = load_pickle(table_dir+'lectures_info.pkl')
        self.questions_info = load_pickle(table_dir+'questions_info.pkl')
        
        self.code2cats = load_pickle(table_dir+'code2cats.pkl')
        self.cats2code = load_pickle(table_dir+'cats2code.pkl')
        


    @timeclass('Table')
    def read_info_data(self):
        self.lectures_info = pd.read_csv('../input/riiid-test-answer-prediction/lectures.csv')
        self.questions_info = pd.read_csv('../input/riiid-test-answer-prediction/questions.csv')
        
        self.code2cats = load_pickle(table_dir+'code2cats.pkl')
        self.cats2code = load_pickle(table_dir+'cats2code.pkl')
        
        for col in ['lecture_id','type_of']:
            self.lectures_info[col] = self.lectures_info[col].map(self.cats2code[col])
            self.lectures_info[col] = downcast(self.lectures_info[col])
        
        
    @timeclass('Table')
    def split_valid2(self, table):
        primary = ['user_id','content_id','task_container_id']
        df = table.df[primary+['content_type_id']].copy()
        
        valid_size = min(20000,df['user_id'].nunique()-10)
        np.random.seed(seed)
        tmp = np.random.choice(df['user_id'].unique(),valid_size,replace=False)
        valid_index = df['user_id'].isin(tmp)
        
        valid = df.loc[valid_index]
        valid_rand = valid.groupby('user_id',sort=False)['task_container_id'].nunique()*np.random.rand(valid_size)
        #每个container_id 给一样的count
        valid['valid_count'] = valid.groupby(['user_id','task_container_id'],sort=False).cumcount() + 1
        valid.loc[valid['valid_count']>1,'valid_count'] = 0
        valid['valid_count'] = valid.groupby('user_id',sort=False)['valid_count'].cumsum()
        
        valid['valid_rand'] = valid['user_id'].map(valid_rand)
        
        valid_index[valid.loc[valid['valid_count']<=valid['valid_rand']].index] = False
        
        valid = df.loc[valid_index]
        del df
        gc.collect()
        
        valid['df_index'] = valid.index
        
        df_model = table.df_model[primary].copy()
        df_model['df_model_index'] = df_model.index
        
        valid = valid.merge(df_model[primary+['df_model_index']],how='left',on=primary)
        del df_model
        gc.collect()
        
        valid = valid[['user_id','task_container_id','content_type_id','df_index','df_model_index']]
        df_valid_index = valid['df_index'].values
        df_model_valid_index = valid.loc[~valid['content_type_id'],'df_model_index'].astype(int).values
        
        
        print(f'valid data : {df_valid_index.shape[0]}')
        
        return valid, df_valid_index, df_model_valid_index
    
    @timeclass('Table')
    def split_valid3(self, table):
        primary = ['user_id','timestamp']
        df = table.df[primary+['content_type_id']].copy()
        
        
        all_days = 2.7*7*7*7
        use_days = 1.8*7
        
        np.random.seed(seed)
        valid_rand = np.random.randint(0,all_days*24*3600*1000,df['user_id'].nunique(),dtype=np.int64)
        valid_rand = pd.Series(valid_rand,index=df['user_id'].unique())
        df['rand_time'] = df['user_id'].map(valid_rand)
        
        df['rand_time'] += df['timestamp']
        
        df['valid_index'] = (df['rand_time']>(all_days-use_days)*24*3600*1000)&(df['rand_time']<=(all_days+use_days+2)*24*3600*1000)
        
        
        ppp = df.loc[df['valid_index']]
        kk = ppp.groupby('user_id')['timestamp'].min()
        df.loc[(df['user_id'].isin(kk[kk==0].index))&(df['rand_time']>(all_days+use_days*0.5)*24*3600*1000),'valid_index'] = False
        
        
        
        ppp = df.loc[df['valid_index']]
        kk = ppp.groupby('user_id')['timestamp'].min()
        ppp['new_user'] = ppp['user_id'].map(kk)
        
        print('验证集数量')
        print(df['valid_index'].value_counts())
        
        
        print('验证集新用户数量')
        print((kk == 0).value_counts())
        
        
        print('验证集新用户数据量')
        print((ppp['new_user']==0).value_counts())
        
        
        df['train_index'] = ~df['valid_index'].copy()
        
        df['valid_max_time'] = df['user_id'].map(ppp.groupby('user_id')['timestamp'].max())
        
        df['useless_index'] = False
        
        
        df.loc[(df['timestamp']>df['valid_max_time']),'useless_index'] = True
        
        df.loc[df['useless_index'],'train_index'] = False
        
        
        
        
        df['task_container_id'] = table.df['task_container_id']
        df['content_id'] = table.df['content_id']
        
        df['df_index'] = df.index
        
        df['df_model_index'] = np.nan
        df.loc[~df['content_type_id'],'df_model_index'] = table.df_model.index
        
        
        
        valid = df.loc[df['valid_index'],['user_id','task_container_id','content_type_id','df_index','df_model_index']]
        df_valid_index = valid['df_index'].values
        df_model_valid_index = valid.loc[~valid['content_type_id'],'df_model_index'].astype(int).values
        
        
        train = df.loc[df['train_index'],['user_id','task_container_id','content_type_id','df_index','df_model_index']]
        df_train_index = train['df_index'].values
        df_model_train_index = train.loc[~train['content_type_id'],'df_model_index'].astype(int).values
        
        
        useless = df.loc[df['useless_index'],['user_id','task_container_id','content_type_id','df_index','df_model_index']]
        df_useless_index = useless['df_index'].values
        df_model_useless_index = useless.loc[~useless['content_type_id'],'df_model_index'].astype(int).values
        
        
        return valid, df_valid_index, df_model_valid_index, df_train_index, df_model_train_index, df_useless_index, df_model_useless_index
    
    
    @timeclass('Table')
    def valid2group(self, valid):
        valid['group_num'] = valid.groupby(['user_id','task_container_id'],sort=False).cumcount() + 1
        valid.loc[valid['group_num']>1,'group_num'] = 0
        valid['group_num'] = valid.groupby('user_id',sort=False)['group_num'].cumsum()
        valid['group_num'] -= 1
        
        df_valid_group_index = valid.groupby('group_num')['df_index'].agg(list)
        df_model_valid_group_index = valid.loc[~valid['content_type_id'],['group_num','df_model_index']].astype(int).groupby('group_num')['df_model_index'].agg(list)
        
        group_index = pd.concat([df_valid_group_index,df_model_valid_group_index],axis=1)
        group_index['df_model_index'] = group_index['df_model_index'].apply(lambda x: [] if x is np.nan else x)
        
        return group_index
        
        
class FeatPipeline:
    def __init__(self):
        self.feats = [
            
        ]

class FeatEngine:
    def __init__(self, feat_pipeline: FeatPipeline):
        self.feat_pipeline = feat_pipeline
    
    @timeclass('FeatEngine')
    def generate_feat(self,table):
        for feat_cls in self.feat_pipeline.feats:
            t1 = time.time()
            feat = feat_cls()
            feat_val,intermediate_feat = feat.generate_feat(table)
            feat_val.index = table.df_model.index
            
            if type(feat_val) == pd.DataFrame:
                for col in feat_val.columns:
                    feat_val[col] = downcast(feat_val[col])
            
            # 先不downcast
            if type(intermediate_feat) == pd.DataFrame:
                for col in intermediate_feat.columns:
                    intermediate_feat[col] = downcast(intermediate_feat[col])
                    
            
            # 因为是list，downcast不这么写，再给加一层
            if type(intermediate_feat) == list:
                for sub_i in range(len(intermediate_feat)):
                    if type(intermediate_feat[sub_i]) == pd.DataFrame:
                        for col in intermediate_feat[sub_i].columns:
                            intermediate_feat[sub_i][col] = downcast(intermediate_feat[sub_i][col])
            
            feat_path = (feat_cls.__name__+'.pkl')
            t2 = time.time()
            print('do feature {} use time {} s'.format(feat_cls.__name__, t2-t1))
            dump_pickle(feat_val, feat_dir + feat_path)
            if intermediate_feat is not None:
                dump_pickle(intermediate_feat, test_intermediate_feat_dir + feat_path)
            t3 = time.time()
            print('save feature {} use time {} s'.format(feat_cls.__name__, t3-t2))
            

    @timeclass('FeatEngine')
    def generate_group_feat(self,table):
        valid_group_index = table.valid_group_index
        
        for feat_cls in self.feat_pipeline.feats:
            t1 = time.time()
            feat = feat_cls()
            feat_val,intermediate_feat = feat.generate_feat(table)
            
            t2 = time.time()
            print('do train set feature {} use time {} s'.format(feat_cls.__name__, t2-t1))
            
            feat_val.index = table.df_model.index
            feat_val = [feat_val]
            for row in valid_group_index.itertuples():
                
                table.df_test = table.all_valid.loc[row.df_index]
                table.df_test_model = table.all_valid_model.loc[row.df_model_index]
                
                feat_val_group = feat.generate_test_feat(table,intermediate_feat)
                feat_val_group.index = row.df_model_index
                
                if feat_val_group.shape[0]>0:
                    feat_val.append(feat_val_group)
                
                table.last_group = table.df_test
                table.last_group_model = table.df_test_model
                
                intermediate_feat = feat.update_intermediate_feat(table,intermediate_feat)
                
                
            feat_val = pd.concat(feat_val,axis=0)
            feat_val = feat_val.sort_index()
                
            
            t3 = time.time()
            print('do group valid set feature {} use time {} s'.format(feat_cls.__name__, t3-t2))
            
            if type(feat_val) == pd.DataFrame:
                for col in feat_val.columns:
                    feat_val[col] = downcast(feat_val[col])
            
            if type(intermediate_feat) == pd.DataFrame:
                for col in intermediate_feat.columns:
                    intermediate_feat[col] = downcast(intermediate_feat[col])
                    
            
            # 因为是list，downcast不这么写，再给加一层
            if type(intermediate_feat) == list:
                for sub_i in range(len(intermediate_feat)):
                    if type(intermediate_feat[sub_i]) == pd.DataFrame:
                        for col in intermediate_feat[sub_i].columns:
                            intermediate_feat[sub_i][col] = downcast(intermediate_feat[sub_i][col])
            
            feat_path = (feat_cls.__name__+'.pkl')
            dump_pickle(feat_val, feat_dir + feat_path)
            if intermediate_feat is not None:
                dump_pickle(intermediate_feat, test_intermediate_feat_dir + feat_path)
            t4 = time.time()
            print('save feature {} use time {} s'.format(feat_cls.__name__, t4-t3))
            
    
    @timeclass('FeatEngine')
    def merge_feat(self,table):
        print('[INFO] before merge feature, data shape is ', table.df_model.shape)
        feat_list = [table.df_model]
        
        for feat_cls in self.feat_pipeline.feats:
            feat_val = load_pickle(feat_dir + feat_cls.__name__ + '.pkl')
            print(feat_cls.__name__, ':',feat_val.shape)
            
            for col in feat_val.columns:
                feat_val[col] = downcast(feat_val[col])
            feat_list.append(feat_val)
                
        # data = pd.concat(feat_list, axis=1).reset_index(drop=True)
        data = pd.concat(feat_list, axis=1)
        del feat_list
        gc.collect()
        
        print('[INFO] after merge feature, data shape is ', data.shape)
        print('[INFO] features: ', data.columns)
        
        #这里先不存了哈，服务器内存不够了
        # dump_pickle(data, feat_merge_dir+'feat_merge.pkl')
        
        return data
    
    def generate_test_feat(self,table):
        # print('[INFO] before merge feature, d1ata shape is ', table.df_test_model.shape)
        feat_list = [table.df_test_model]
        
        for i,feat_cls in enumerate(self.feat_pipeline.feats):
            feat = feat_cls()
            #如果存中间变量量就用中间变量算
            feat_val = feat.generate_test_feat(table,table.intermediate_feat_list[i])
            feat_list.append(feat_val)
        
        data = pd.concat(feat_list, axis=1).reset_index(drop=True)
        
        # print('[INFO] after merge feature, data shape is ', data.shape)
        # print('[INFO] features: ', data.columns)
        
        table.df_test_model = data
        
    # @timeclass('FeatEngine')
    def update_intermediate_feat(self,table):
        for i,feat_cls in enumerate(self.feat_pipeline.feats):
            feat = feat_cls()
            table.intermediate_feat_list[i] = feat.update_intermediate_feat(table,table.intermediate_feat_list[i])
        
    
    @timeclass('FeatEngine')
    def load_test_intermediate_feat(self,table):
        print('[INFO] Starting load all intermediate feature, number is ', len(self.feat_pipeline.feats))
        
        table.intermediate_feat_list = []
        for feat_cls in self.feat_pipeline.feats:
            feat_path = (feat_cls.__name__ + '.pkl')
            intermediate_feat = load_pickle(test_intermediate_feat_dir + feat_path)
            table.intermediate_feat_list.append(intermediate_feat)
        
        print('[INFO] Finish load all intermediate feature')

    def generate_first_test_feat(self,table):
        # print('[INFO] before merge feature, d1ata shape is ', table.df_test_model.shape)
        feat_list = [table.df_test_model]
        
        for i,feat_cls in enumerate(self.feat_pipeline.feats):
            feat = feat_cls()
            #如果存中间变量量就用中间变量算
            feat_val = feat.generate_test_feat(table,table.first_intermediate_feat_list[i])
            feat_list.append(feat_val)
            
        data = pd.concat(feat_list, axis=1).reset_index(drop=True)
        
        # print('[INFO] after merge feature, data shape is ', data.shape)
        # print('[INFO] features: ', data.columns)
        
        table.df_test_model = data
        
    # @timeclass('FeatEngine')
    def update_first_intermediate_feat(self,table):
        for i,feat_cls in enumerate(self.feat_pipeline.feats):
            feat = feat_cls()
            table.first_intermediate_feat_list[i] = feat.update_intermediate_feat(table,table.first_intermediate_feat_list[i])
        
    
    @timeclass('FeatEngine')
    def load_first_test_intermediate_feat(self,table):
        print('[INFO] Starting load first intermediate feature, number is ', len(self.feat_pipeline.feats))
        
        table.first_intermediate_feat_list = []
        for feat_cls in self.feat_pipeline.feats:
            feat_path = (feat_cls.__name__ + '.pkl')
            intermediate_feat = load_pickle(test_intermediate_feat_dir + feat_path)
            table.first_intermediate_feat_list.append(intermediate_feat)
        
        print('[INFO] Finish load first intermediate feature')

class LGBModel:
    def __init__(self, model, OPT_ROUNDS=600):
        LR = 0.2
        self.EARLY_STOP = 30
        self.MAX_ROUNDS = 2000
        self.OPT_ROUNDS = OPT_ROUNDS
        
        self.params = {
            'boosting': 'gbdt',
            'metric' : 'binary_logloss',
            #'metric' : 'auc',
            'objective': 'binary',
            'learning_rate': LR,
            'max_depth': -1,
            'min_child_samples': 20,
            'max_bin': 255,
            'subsample': 0.85,
            'subsample_freq': 10,
            'colsample_bytree': 0.8,
            'min_child_weight': 0.001,
            'subsample_for_bin': 200000,
            'min_split_gain': 0,
            'reg_alpha': 0,
            'reg_lambda': 0,
            'num_leaves':255,
            'seed': seed,
            'nthread': 16,
            # 'scale_pos_weight': 1.5
            #'is_unbalance': True,
        }
    
    @timeclass('LGBModel')
    def modeling(self, categoricals, mode, weight=None):        
        print(f'Now Version {version}')
        if mode == 'valid':
            print('Start train and validate...')
            train_X, train_Y = load_pickle(valid_train_data_dir+'valid_train_data_dir.pkl')
            
            print('feature number:', len(train_X.columns))
            feat_cols = list(train_X.columns)
            
            print('transform train_X')
            for col in train_X:
                train_X[col] = train_X[col].astype('float32',copy=False)
                gc.collect()
            train_X = train_X.values
            gc.collect()
            train_Y = train_Y.astype('float32',copy=False).values
            gc.collect()
            
            test_X, test_Y = load_pickle(valid_test_data_dir+'valid_test_data_dir.pkl')
            
            print('transform test_X')
            for col in test_X:
                test_X[col] = test_X[col].astype('float32',copy=False)
                gc.collect()
            test_X = test_X.values
            gc.collect()
            test_Y = test_Y.astype('float32',copy=False).values
            gc.collect()
            
            dtrain = lgb.Dataset(data=train_X, label=train_Y, feature_name=feat_cols,weight=weight)
            dvalid = lgb.Dataset(data=test_X, label=test_Y, feature_name=feat_cols)
            
            del train_X, train_Y,test_X, test_Y
            gc.collect()
            
            print('开始训练')
            model = lgb.train(self.params,
                              dtrain,
                              categorical_feature=categoricals,
                              num_boost_round=self.MAX_ROUNDS,
                              early_stopping_rounds=self.EARLY_STOP,
                              verbose_eval=5,
                              valid_sets=[dtrain, dvalid],
                              valid_names=['train', 'valid']
                              )
            importances = pd.DataFrame({'features':model.feature_name(),
                                    'importances':model.feature_importance()})
            importances.sort_values('importances',ascending=False,inplace=True)
            print(importances)
            importances.to_csv( (feat_imp_dir+'{}_imp.csv').format(version), index=False )
            self.model = model
            return model
        else:
            print('Start training... Please set OPT-ROUNDS.')
            train_X, train_Y = load_pickle(train_data_dir+'train_data_dir.pkl')
            
            print('feature number:', len(train_X.columns))
            print('feature :', train_X.columns)
            feat_cols = list(train_X.columns)
            print('transform train_X')
            for col in train_X:
                train_X[col] = train_X[col].astype('float32',copy=False)
                gc.collect()
            
            print('pandas to numpy')
            train_X = train_X.values
            
            gc.collect()
            train_Y = train_Y.astype('float32',copy=False).values
            gc.collect()
            
            dtrain = lgb.Dataset(data=train_X, label=train_Y, feature_name=feat_cols,weight=weight)
            
            del train_X, train_Y
            gc.collect()
            
            print('开始训练')
            
            model = lgb.train(self.params,
                              dtrain,
                              categorical_feature=categoricals,
                              num_boost_round=self.OPT_ROUNDS,
                              verbose_eval=5,
                              valid_sets=[dtrain],
                              valid_names='train'
                              )
            
            importances = pd.DataFrame({'features':model.feature_name(),
                                    'importances':model.feature_importance()})
            importances.sort_values('importances',ascending=False,inplace=True)
            importances.to_csv( (feat_imp_dir+'{}_imp.csv').format(version), index=False )
            
            model.save_model(lgb_model_dir+'{}.model'.format(version))
            self.model = model
            return model
        
    def predict(self, test_X, info=False):
        if info:
            print('Start LGB Predict ...')
            print('Num of features: ', len(test_X.columns))
            print(test_X.columns)
        
        predict = self.model.predict(test_X, num_iteration=self.model.best_iteration)

        return predict
    
class DNN(torch.nn.Module):
    def __init__(self, embedding_nums,embedding_bag_nums, inputs=16):
        super(DNN, self).__init__()
         
        all_embedding_size = 0
        
        self.embeddings = nn.ModuleList()
        for max_features,embedding_size in embedding_nums:
            self.embeddings.append(nn.Embedding(max_features, embedding_size))
            all_embedding_size += embedding_size
            
        
        self.embedding_bags = nn.ModuleList()
        for max_features,embedding_bag_size in embedding_bag_nums:
            self.embedding_bags.append(nn.EmbeddingBag(max_features, embedding_bag_size,mode='sum'))
            all_embedding_size += embedding_bag_size
        
        input_size = all_embedding_size+inputs
        
        
        self.linears = nn.ModuleList()
        self.relus = nn.ModuleList()
        self.bns = nn.ModuleList()
        self.dropouts = nn.ModuleList()
        
        last_size = input_size
        for size in [128,32]:
            self.linears.append(nn.Linear(last_size,size))
            self.relus.append(nn.ReLU())
            self.bns.append(nn.BatchNorm1d(size))
            self.dropouts.append(nn.Dropout(0.1))
            last_size = size
            
        self.out = nn.Linear(last_size,1)
        
        
    def forward(self, x_cats, x_cats_bags, x):
        embeddings = []
        for i in range(x_cats.shape[1]):
            embeddings.append(self.embeddings[i](x_cats[:,i]))
            
        
        embedding_bags = []
        for i in range(len(x_cats_bags)):
            embedding_bags.append(self.embedding_bags[i](x_cats_bags[i][0],x_cats_bags[i][1]))
        
        inputs = torch.cat(embeddings+embedding_bags+[x],1)
        
        
        for i in range(len(self.linears)):
            inputs = self.linears[i](inputs)
            inputs = self.relus[i](inputs)
            inputs = self.bns[i](inputs)
            inputs = self.dropouts[i](inputs)
            
            
        inputs = self.out(inputs)
        inputs = torch.sigmoid(inputs).flatten()
        
        
        return inputs

    
class DNNModel:
    def __init__(self,model,best_iteration=3):
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        
        self.num_boost_round = 1
        self.early_stopping_rounds = 10
        self.best_iteration = best_iteration
        self.learning_rate = 0.005
        self.echo_epochs = 1
        self.batch_size = 8192
        
        self.embedding_categorical_list = model.embedding_categorical_list
        self.embedding_nums = model.embedding_nums
        
        self.embedding_bag_list = model.embedding_bag_list
        self.embedding_bag_nums = model.embedding_bag_nums
        
        print(self.device)
        
    def preprocess(self,X,y=None):
        categorical_X = X[self.embedding_categorical_list]
        categorical_bags_X = X[self.embedding_bag_list]
        
        X = X[[col for col in X.columns if col not in self.embedding_categorical_list+self.embedding_bag_list]]
        
        categorical_X = torch.tensor(categorical_X.fillna(0).values,dtype=torch.long).to(self.device)
        
        X = torch.tensor(X.fillna(0).values,dtype=torch.float).to(self.device)
        if y is not None:
            y = torch.tensor(y.values,dtype=torch.float).to(self.device)
            return categorical_X,categorical_bags_X,X,y
        
        return categorical_X,categorical_bags_X,X
    
    def embedding_bags_preprocess(self,categorical_bags_X):
        result_categorical_bags_X = []
        for col in categorical_bags_X.columns:
            inputs = np.concatenate(categorical_bags_X[col].tolist())
            inputs = torch.tensor(inputs,dtype=torch.long).to(self.device)
            
            offsets = torch.tensor(categorical_bags_X[col].apply(len).shift().fillna(0).cumsum().values,dtype=torch.long).to(self.device)
            result_categorical_bags_X.append((inputs,offsets))
            
        return result_categorical_bags_X
    
    def cal_norm(self,X):
        X_mean = X.mean(axis=0)
        X_std = X.std(axis=0)
        return [X_mean,X_std]
    
    # 归一化
    def data_norm(self,X,norm):
        X_mean,X_std = norm
        X = (X-X_mean)/X_std
        return X
        
    @timeclass('DNNModel')  
    def init_model(self, inputs):
        model = DNN(self.embedding_nums,self.embedding_bag_nums, inputs=inputs)
        
        model = model.to(self.device)
        optimizer = torch.optim.Adam(model.parameters(), lr=self.learning_rate)
        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.9, patience=3, verbose=True, threshold=1e-4, threshold_mode='rel', cooldown=5, min_lr=self.learning_rate/100, eps=1e-08)
        
        return model,optimizer

    @timeclass('DNNModel')
    def modeling(self, categoricals, mode, weight=None):
        if mode == 'valid':
            train_X, train_Y = load_pickle(valid_train_data_dir+'valid_train_data_dir.pkl')
            test_X, test_Y = load_pickle(valid_test_data_dir+'valid_test_data_dir.pkl')
        else:
            train_X, train_Y = load_pickle(train_data_dir+'train_data_dir.pkl')
        
        train_X = train_X.sample(frac=1)
        train_Y = train_Y.loc[train_X.index]
        
        inputs = train_X.shape[1]-len(self.embedding_categorical_list)-len(self.embedding_bag_list)
                 
        model,optimizer = self.init_model(inputs)
        
        train_categorical_X,train_categorical_bags_X,train_X,train_y = self.preprocess(train_X,train_Y)
        
        norm = self.cal_norm(train_X)
        train_X = self.data_norm(train_X,norm)
        
        train_data_set = torch.utils.data.TensorDataset(train_categorical_X,train_X,train_y)
        
        train_loader = torch.utils.data.DataLoader(dataset = train_data_set,
                                    batch_size = self.batch_size,
                                    shuffle = False,
                                    num_workers=4
                                    )
        
        loss_fn = torch.nn.BCELoss(reduce=True, size_average=True)
        
        if mode == 'valid':
            valid_categorical_X,valid_categorical_bags_X,valid_X,valid_Y = self.preprocess(test_X,test_Y)
            valid_X = self.data_norm(valid_X,norm)
            
            valid_data_set = torch.utils.data.TensorDataset(valid_categorical_X,valid_X,valid_Y)
            valid_loader = torch.utils.data.DataLoader(dataset = valid_data_set,
                                        batch_size = self.batch_size,
                                        shuffle = False,
                                        num_workers=4
                                        )
        
        for epoch in range(self.num_boost_round):
            model.train()
            avg_loss = 0
            i = 0
            t1 = time.time()
            loss_list = []
            for batch in train_loader:
                batch_categorical_bags_X = self.embedding_bags_preprocess(train_categorical_bags_X.iloc[i*self.batch_size:(i+1)*self.batch_size])
                
                i += 1
                batch_categorical_X = batch[0]
                batch_X = batch[1]
                batch_Y = batch[2]
                
                
                y_pred = model(batch_categorical_X,batch_categorical_bags_X,batch_X)
                loss = loss_fn(y_pred,batch_Y)
                
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                
                avg_loss += loss.item() / len(train_loader)
                loss_list.append(loss.item())
                
                    
                if i % 100 == 0:
                    t2 = time.time()
                    print(f'{i}/{len(train_loader)}: loss {loss.item():.4f} avg loss {np.mean(loss_list[-100:]):.4f}   {t2-t1:.2f} sec ')
                    t1 = t2
                
            end = '' if mode == 'valid' else '\n'
            print('Epoch {}/{} \t loss={:.4f} \t'.format(epoch + 1, self.num_boost_round, avg_loss), end=end)
            
            model.eval()
            if mode == 'valid':
                valid_pred = torch.zeros(test_Y.shape[0])
                for j, batch in enumerate(valid_loader):
                    valid_batch_categorical_bags_X = self.embedding_bags_preprocess(valid_categorical_bags_X.iloc[j*self.batch_size:(j+1)*self.batch_size])
                    y_pred = model(batch[0],valid_batch_categorical_bags_X,batch[1]).detach()
                        
                    valid_pred[j * self.batch_size:(j+1) * self.batch_size] = y_pred
                
                valid_loss = torch.nn.functional.binary_cross_entropy(valid_pred,valid_Y.cpu()).item()
                print(f'valid loss: {valid_loss:.4f}')
            
        self.norm = norm
        
        self.model = model
        return model
    
    
    def predict(self, test_X, info=False):
        if info:
            print('Start DNN Predict ...')
            print('Num of features: ', len(test_X.columns))
            print(test_X.columns)
            print('Embedding features: ', len(self.embedding_categorical_list))
            print(self.embedding_categorical_list)
        
        
        test_categorical_X,test_categorical_bags_X,test_X = self.preprocess(test_X)
        test_categorical_bags_X = self.embedding_bags_preprocess(test_categorical_bags_X)
                
        test_X = self.data_norm(test_X,self.norm)
        self.model.eval()
        predict = self.model(test_categorical_X,test_categorical_bags_X,test_X).cpu().detach().numpy().flatten()
        
        return predict

class Model:
    def __init__(self,table):
        self.test_drop_list = ['timestamp']
        self.drop_list = ['label'] + self.test_drop_list
        self.categorical_list = []
        print(f'[INFO] drop list: {self.drop_list}')
        
        
        self.embedding_categorical_list = ['user_id','content_id','task_container_id','part']
        self.embedding_nums = [(500000,16),
                               (table.questions_info['question_id'].max()+1,16),
                               (max(table.df_model['task_container_id'].max()+1,10000),16),
                               (table.questions_info['part'].max()+1,4)]
        
        #feat_dnn_question_tags+2，一个0，一个是没有值填充
        self.embedding_bag_list = ['feat_dnn_question_tags']
        self.embedding_bag_nums = [(max_tags+2,16)]
        
        
        
        self.embedding_categorical_list = ['user_id','content_id','task_container_id']
        self.embedding_nums = [(500000,16),
                               (table.questions_info['question_id'].max()+1,16),
                               (max(table.df_model['task_container_id'].max()+1,10000),16)]
        
        #feat_dnn_question_tags+2，一个0，一个是没有值填充
        self.embedding_bag_list = []
        self.embedding_bag_nums = []
        
        # self.mode_list = [LGBModel,DNNModel]
        self.mode_list = [LGBModel]
    
    @timeclass('Model')
    def train_and_batch_valid(self,train_data,OPT_ROUNDS):
        valid_data,valid_batch,train_data = self.get_valid(train_data)
        
        train_Y = train_data['label']
        train_X = train_data.drop(self.drop_list, axis=1)
        
        all_test_Y = valid_data['label']
        all_test_X = valid_data.drop(self.drop_list, axis=1)
        
        
        lgb_model = LGBModel(self,OPT_ROUNDS=OPT_ROUNDS)
        lgb_model.modeling(train_X, train_Y, None, None, self.categorical_list, 'test')
        
        label_list = []
        preds_list = []
        t1 = time.time()
        start_index = 0
        for i,batch in enumerate(valid_batch):
            test_X = all_test_X.loc[batch]
            test_Y = all_test_Y.loc[batch]
            
            label_list.extend(test_Y)
            
            preds = lgb_model.predict(test_X,False)
            preds_list.extend(preds)
            
            if i % 1000==0:
                batch_score = roc_auc_score(label_list[start_index:],preds_list[start_index:]) 
                start_index = len(label_list)
                t2 = time.time()
                print(f'valid batch {i}: total time {t2-t1:.2f} sec, auc:{batch_score:0.3f}')
        
        score = roc_auc_score(label_list,preds_list)
        
        self.models = [lgb_model]
        print(f'auc: {score}')
    
    @timeclass('Model')
    def train_and_valid(self,time_weight):
        gc.collect()
        scores = []
        self.models = []
        for model in self.mode_list:
        
            model = model(self)
            model.modeling(self.categorical_list, 'valid', time_weight)
            
            
            test_X,test_Y = load_pickle(valid_test_data_dir+'valid_test_data_dir.pkl')
            
            preds = model.predict(test_X)
            
            score = roc_auc_score(test_Y,preds)
            print(f'[INFO] {type(model).__name__} score: {score}')
            
            scores.append(score)
            self.models.append(model)
        
        print(f'auc: {np.mean(scores,axis=0)}')
        
    
    @timeclass('Model')
    def train(self,OPT_ROUNDS,time_weight):
        
        gc.collect()
        self.models = []
        for model in self.mode_list:
            model = model(self,OPT_ROUNDS)
            
            model.modeling(self.categorical_list, 'test', time_weight)
            
            self.models.append(model)
            
        return self.models
    
    
    @timeclass('Model')
    def split_valid(self, data):
        valid_size = min(20000,int(np.ceil(data['user_id'].nunique()*0.05)))
        np.random.seed(seed)
        tmp = np.random.choice(data['user_id'].unique(),valid_size,replace=False)
        valid_index = data['user_id'].isin(tmp)
        
        valid = data.loc[valid_index]
        valid_rand = valid.groupby('user_id',sort=False)['task_container_id'].nunique()*np.random.rand(valid_size)
        #每个container_id 给一样的count
        valid['valid_count'] = valid.groupby(['user_id','task_container_id'],sort=False).cumcount() + 1
        valid.loc[valid['valid_count']>1,'valid_count'] = 0
        valid['valid_count'] = valid.groupby('user_id',sort=False)['valid_count'].cumsum()
        
        valid['valid_rand'] = valid['user_id'].map(valid_rand)
        
        valid_index[valid.loc[valid['valid_count']<=valid['valid_rand']].index] = False
        
        valid = data.loc[valid_index]
        data2 = data.loc[~valid_index]
        
        return valid, data2
    
    @timeclass('Model')
    def get_valid(self, data):   
        valid_size = min(20000,int(np.ceil(data['user_id'].nunique()*0.05)))
        batch_size = 25
        
        valid, data2 = self.split_valid(data)
        
        tmp = pd.Series(np.random.rand(valid_size),index=valid['user_id'].unique())
        valid['rand_order'] = valid['user_id'].map(tmp)
        valid = valid.reset_index().sort_values(['rand_order','index'])
        valid.index = valid['index']
        valid.drop(columns=['rand_order','index'],inplace=True)
        
        df = load_pickle(table_dir+'df.pkl')
        df_model_time = df.loc[~df['content_type_id'],'timestamp'].reset_index(drop=True)
        
        valid_t = pd.concat([valid,df_model_time.iloc[valid.index]],axis=1)
        valid_t = valid_t.sort_values('timestamp').reset_index()
        cols = ['user_id','task_container_id','index']
        valid_tmps = valid_t[ cols ].values.tolist()
              
        anss = []
        start_index = 0
        while(True):
            ans = []
            vis_ut = {}  
            queue = []
            for index in range( start_index,len(valid_tmps)):
                valid_tmp = valid_tmps[index]
                u = valid_tmp[0]
                t = valid_tmp[1]
                i = valid_tmp[2]
                if u in vis_ut:
                    if t in vis_ut[u]:
                        ans.append(i)
                    else:
                        queue.append(valid_tmp)
                else:
                    vis_ut[u] = {}
                    vis_ut[u][t] = 1
                    ans.append(i)
            
                if len(ans)>=batch_size:
                    for j in range(len(queue)):
                        valid_tmps[index+1-len(queue)+j] = queue[j]
                    start_index = index+1 - len(queue)
                    anss.append(ans)
                    break
                    
            if len(ans) < batch_size:
                break
            
        return valid,anss,data2
    
    def predict(self,test_X):
        predict = []
        for model in self.models:
            predict.append(model.predict(test_X))
            
        return np.mean(predict,axis=0)
        

class Test:
    def __init__(self):
        if not offline:
            import riiideducation
            self.env = riiideducation.make_env()
            self.iter_test = self.env.iter_test()
    
    @timeclass('Test')
    def old_predict_test(self,table,feat_engine,model):
        feat_engine.load_test_intermediate_feat(table)
        
        if offline:
            self.iter_test = pd.read_csv('../input/riiid-test-answer-prediction/example_test.csv').groupby('group_num')
            
        columns = table.columns
        table.all_history_test = pd.DataFrame([])
        table.all_history_test_model = pd.DataFrame([])
        
        #存一下，前面batch的数据
        last_group = pd.DataFrame([],columns=columns)
        last_group_model = pd.DataFrame([])
        
        prior_group_answers_correct = None
        prior_group_responses = None
        question_index = None
        last_question_index = pd.Series([])
        
        init_cols = table.init_cols
        
        for (df_test, sample_prediction_df) in self.iter_test:
            if offline:
                df_test = sample_prediction_df
                
            table.df_test = df_test
            question_index = df_test['content_type_id']==0
            table.df_test_model = df_test.loc[question_index,init_cols]

            result = df_test.loc[question_index,['row_id']]
            
            feat_engine.generate_test_feat(table)
            
            result['answered_correctly'] =  model.predict(table.df_test_model)
            
            #存一下结果
            prior_group_answers_correct,prior_group_responses = df_test[['prior_group_answers_correct','prior_group_answers_correct']].iloc[0]
            
            if isinstance(prior_group_answers_correct,str) and isinstance(prior_group_responses,str):
                prior_group_answers_correct = eval(prior_group_answers_correct)
                prior_group_responses = eval(prior_group_responses)
                
                last_group['answered_correctly'] = prior_group_answers_correct
                last_group['user_answer'] = prior_group_responses
                table.all_history_test = table.all_history_test.append(last_group[columns])
                
                last_group_model['answered_correctly'] = last_group.loc[last_question_index, 'answered_correctly'].values
                last_group_model['user_answer'] = last_group.loc[last_question_index,'user_answer'].values
                table.all_history_test_model = table.all_history_test_model.append(last_group_model)
                
            last_question_index = question_index
            last_group = df_test.copy()
            last_group_model = table.df_test_model.copy()
            
            if offline:
                pass
                # print(result)
            else:
                self.env.predict(result)
                

    @timeclass('Test')
    def predict_test(self,table,first_feat_engine,feat_engine,model):
        first_feat_engine.load_first_test_intermediate_feat(table)
        feat_engine.load_test_intermediate_feat(table)
        
        if offline:
            self.iter_test = pd.read_csv('../input/riiid-test-answer-prediction/example_test.csv').groupby('group_num')
            
        columns = table.columns
        
        #存一下，前面batch的数据
        # last_group = pd.DataFrame([],columns=columns)
        # last_group_model = pd.DataFrame([])
        last_group = None
        last_group_model = None
        
        prior_group_answers_correct = None
        prior_group_responses = None
        question_index = None
        last_question_index = pd.Series([])
        
        init_cols = table.init_cols
        t1 = time.time()
        
        for (df_test, sample_prediction_df) in self.iter_test:
            if offline:
                df_test = sample_prediction_df.set_index('group_num')
            
            df_test['prior_question_had_explanation'] = boolean2int(df_test['prior_question_had_explanation'])
            
            user_num = len(table.cats2code['user_id'])
            df_n = df_test.shape[0]
            new_user_code = np.zeros(df_n,dtype=int)
            j = 0
            for i in range(df_n):
                u = df_test['user_id'].iloc[i]
                if u in table.cats2code['user_id']:
                    new_user_code[i] = table.cats2code['user_id'][u]
                else:
                    new_user_code[i] = user_num + j
                    table.cats2code['user_id'][u] = user_num + j
                    j += 1
            
            df_test['user_id'] = new_user_code
            
            df_test.loc[df_test['content_type_id']==1,'content_id'] = df_test.loc[df_test['content_type_id']==1,'content_id'].map(table.cats2code['lecture_id'])
            
            
            table.df_test = df_test
            question_index = df_test['content_type_id']==0
            table.df_test_model = df_test.loc[question_index,init_cols]
            
            #存一下结果
            prior_group_answers_correct,prior_group_responses = df_test[['prior_group_answers_correct','prior_group_answers_correct']].iloc[0]
            
            if last_group is not None and isinstance(prior_group_answers_correct,str) and isinstance(prior_group_responses,str):
                prior_group_answers_correct = eval(prior_group_answers_correct)
                prior_group_responses = eval(prior_group_responses)
                
                last_group['answered_correctly'] = prior_group_answers_correct
                last_group['user_answer'] = prior_group_responses
                
                last_group_model['label'] = last_group.loc[last_group['content_type_id']==0,'answered_correctly'].values
                
                table.last_group = last_group
                table.last_group_model = last_group_model
                
                
                first_feat_engine.update_first_intermediate_feat(table)
                feat_engine.update_intermediate_feat(table)
            
            
            result = df_test.loc[question_index,['row_id']]
            
            
            first_feat_engine.generate_first_test_feat(table)
            feat_engine.generate_test_feat(table)
            
            
            last_group = df_test.copy()
            last_group_model = table.df_test_model.copy()
            
            if table.df_test_model.shape[0]>0:
                result['answered_correctly'] =  model.predict(table.df_test_model.drop(columns=model.test_drop_list))
            else:
                result['answered_correctly'] = -1
            #藏分
            # result['answered_correctly'] = 1-result['answered_correctly']
            
            
            if offline:
                # pass
                # print(result)
                t2 = time.time()
                print(f'test time {t2-t1:.4f}')
                t1=t2
            else:
                self.env.predict(result)
                
                

class Feat:
    def generate_feat(self,table):
        pass 
    
    def generate_test_feat(self,table):
        pass
        
#这里写特征，训练集特征生成完存下来；测试集所需数据单独写，主要还是分成几类，全局统计类的，时序的，等等等等
class feat_question_part(Feat):
    @timeclass('feat_question_part')
    def generate_feat(self,table):
        df = table.df_model.copy()
        df = df[['content_id']]
        question2part = table.questions_info.set_index('question_id')['part']
        df['part'] = df['content_id'].map(question2part)
        feat = df[['part']]
        return feat,[question2part]
    
    # @timeclass('feat_question_part')
    def generate_test_feat(self,table,tmp):
        question2part, = tmp
        df_test_model = table.df_test_model[['content_id']].copy()
        df_test_model['part'] = df_test_model['content_id'].map(question2part)

        feat = df_test_model[['part']]
        
        return feat
    
    # @timeclass('feat_question_part')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    

class feat_question_tags(Feat):
    @timeclass('feat_question_tags')
    def generate_feat(self,table):
        tmp = table.questions_info['tags'].str.strip().str.split(' ').str.join('|').str.get_dummies()
        tmp = tmp.astype(bool)
        tmp.columns = [f'question_tags{i}' for i in tmp.columns]
        tmp['content_id'] = tmp.index
        
        df = table.df_model.copy()
        df = df[['content_id']]
        
        df = df.merge(tmp,how='left',on='content_id')
        
        df.drop(columns=['content_id'],inplace=True)
        
        return df,[tmp]
    
    # @timeclass('feat_question_tags')
    def generate_test_feat(self,table,tmp):
        df_test_model = table.df_test_model[['content_id']].copy()
        
        df_test_model = df_test_model.merge(tmp,how='left',on='content_id')
        
        df_test_model.drop(columns=['content_id'],inplace=True)
        
        return df_test_model
    
    # @timeclass('feat_question_tags')
    def update_intermediate_feat(self,table,tmp):
        pass
    
class feat_user_history_question_nums_and_corroct_nums_and_rate(Feat):
    #这里说一下，一个task_container里可能有多个question，而且是同一batch给出，所以必须只能统计本task_container之前的值
    @timeclass('feat_user_history_question_nums_and_corroct_nums_and_rate')
    def generate_feat(self,table):
        df = table.df.copy()
        df = df.loc[~df['content_type_id'],['user_id','task_container_id','answered_correctly']]
        tmp = df.groupby(['user_id','task_container_id'],sort=False)['answered_correctly'].agg(['size',sum])
        
        tmp = tmp.groupby('user_id',sort=False).cumsum()
        
        tmp.columns = ['feat_user_history_question_nums','feat_user_history_corroct_nums']
        
        result = tmp.groupby('user_id',sort=False).last()
        
        tmp = tmp.groupby('user_id',sort=False).shift(1,fill_value=0)
        
        df = table.df_model[['user_id','task_container_id']].copy()
        df = df.merge(tmp,how='left',on=['user_id','task_container_id'])
        df.index = table.df_model.index
        df['feat_user_history_corroct_rate'] = df['feat_user_history_corroct_nums']/df['feat_user_history_question_nums']
        
        feat = df[['feat_user_history_question_nums','feat_user_history_corroct_nums','feat_user_history_corroct_rate']]
        
        feat_user_history_question_nums = defaultdict(int)
        feat_user_history_corroct_nums = defaultdict(int)
        
        feat_user_history_question_nums.update(result['feat_user_history_question_nums'])
        feat_user_history_corroct_nums.update(result['feat_user_history_corroct_nums'])
        
        
        return feat,[feat_user_history_question_nums,feat_user_history_corroct_nums]
    
    # @timeclass('feat_user_history_question_nums_and_corroct_nums_and_rate')
    def generate_test_feat(self,table,tmp):
        feat_user_history_question_nums,feat_user_history_corroct_nums = tmp
        
        df_test_model = table.df_test_model[['user_id']].copy()
        
        df_test_model['feat_user_history_question_nums'] = df_test_model['user_id'].map(feat_user_history_question_nums)
        df_test_model['feat_user_history_corroct_nums'] = df_test_model['user_id'].map(feat_user_history_corroct_nums)
        df_test_model['feat_user_history_corroct_rate'] = df_test_model['feat_user_history_corroct_nums']/df_test_model['feat_user_history_question_nums']


        feat = df_test_model[['feat_user_history_question_nums','feat_user_history_corroct_nums','feat_user_history_corroct_rate']]
        
        return feat

    # @timeclass('feat_user_history_question_nums_and_corroct_nums_and_rate')
    def update_intermediate_feat(self,table,tmp):
        
        feat_user_history_question_nums,feat_user_history_corroct_nums = tmp
        df = table.last_group.copy()

        df = df.loc[df['content_type_id']==0,['user_id','task_container_id','answered_correctly']]
        
        if df.shape[0] == 0:
            return tmp
        
        tmp2 = df.groupby(['user_id','task_container_id'],sort=False)['answered_correctly'].agg(['size',sum])
        tmp2 = tmp2.groupby('user_id',sort=False).cumsum()
        
        tmp2.columns = ['feat_user_history_question_nums','feat_user_history_corroct_nums']
        
        tmp2 = tmp2.groupby('user_id',sort=False).last()
        
        for user in tmp2.index:
            feat_user_history_question_nums[user] += tmp2.loc[user,'feat_user_history_question_nums']
            feat_user_history_corroct_nums[user] += tmp2.loc[user,'feat_user_history_corroct_nums']
        
        return [feat_user_history_question_nums,feat_user_history_corroct_nums]
    
    
class feat_user_history_lecture_nums(Feat):
    @timeclass('feat_user_history_lecture_nums')
    def generate_feat(self, table):
        df = table.df.copy()
        df = df[['user_id','task_container_id','content_type_id']]
        
        tmp = df.groupby(['user_id','task_container_id'],sort=False)['content_type_id'].agg([sum])
        tmp = tmp.groupby('user_id',sort=False).cumsum()
        tmp.columns = ['feat_user_history_lecture_nums']
        
        result = tmp.groupby('user_id',sort=False).last()
        
        tmp = tmp.groupby('user_id',sort=False).shift(1,fill_value=0).astype('int64')
        
        df = table.df_model[['user_id','task_container_id']].copy()
        
        #合并的意义在于可以返回一个和df行数相同且和每个userid及task_container_id相对应的feat_user_history_lecture_nums的series
        df = df.merge(tmp,how='left',on=['user_id','task_container_id'])
        
        feat = df[['feat_user_history_lecture_nums']]
        
        feat_user_history_lecture_nums = defaultdict(int)
        
        feat_user_history_lecture_nums.update(result['feat_user_history_lecture_nums'])
        
        return feat,[feat_user_history_lecture_nums]    
    
    # @timeclass('feat_user_history_lecture_nums')
    def generate_test_feat(self,table,tmp):
        feat_user_history_lecture_nums, = tmp
        
        df_test_model = table.df_test_model[['user_id']].copy()
        
        df_test_model['feat_user_history_lecture_nums'] = df_test_model['user_id'].map(feat_user_history_lecture_nums)

        feat = df_test_model[['feat_user_history_lecture_nums']]
        
        return feat

    # @timeclass('feat_user_history_lecture_nums')
    def update_intermediate_feat(self,table,tmp):
        feat_user_history_lecture_nums, = tmp
        
        df = table.last_group.copy()
        
        df = df.loc[df['content_type_id']==1,['user_id','task_container_id','content_type_id']]
        
        if df.shape[0] == 0:
            return tmp
        
        tmp2 = df.groupby(['user_id','task_container_id'],sort=False)['content_type_id'].agg(['size'])
        tmp2 = tmp2.groupby('user_id',sort=False).cumsum()
        
        tmp2.columns = ['feat_user_history_lecture_nums']
        
        tmp2 = tmp2.groupby('user_id',sort=False).last()
        
        for user in tmp2.index:
            feat_user_history_lecture_nums[user] += tmp2.loc[user,'feat_user_history_lecture_nums']
        
        return [feat_user_history_lecture_nums]
    
    
class feat_question_asked_nums_and_corroct_nums_and_rate(Feat):
    @timeclass('feat_question_asked_nums_and_corroct_nums_and_rate')
    def generate_feat(self,table):
        df = table.df.copy()
        df = df.loc[~df['content_type_id'],['content_id','answered_correctly']]
        
        tmp = df.groupby(['content_id'],sort=False)['answered_correctly'].agg(['size',sum])
        
        tmp.columns = ['feat_question_asked_nums','feat_question_asked_corroct_nums']
        
        feat_question_asked_nums = defaultdict(int)
        feat_question_asked_corroct_nums = defaultdict(int)
        
        feat_question_asked_nums.update(tmp['feat_question_asked_nums'])
        feat_question_asked_corroct_nums.update(tmp['feat_question_asked_corroct_nums'])
        
        #回答次数小于50的，给置空吧，leak太严重了感觉，也没啥统计意义。一共83个问题。而且正好可以学习一下没见过的问题要怎么预测。
        tmp.loc[tmp['feat_question_asked_nums']<50,'feat_question_asked_corroct_nums'] = 0
        tmp.loc[tmp['feat_question_asked_nums']<50,'feat_question_asked_nums'] = 0
        
        tmp['feat_question_asked_corroct_rate'] = tmp['feat_question_asked_corroct_nums']/tmp['feat_question_asked_nums']

        df = table.df_model[['content_id']].copy()
        df = df.merge(tmp,how='left',on=['content_id'])
        feat = df[['feat_question_asked_nums','feat_question_asked_corroct_nums','feat_question_asked_corroct_rate']]
        
        feat['feat_question_asked_nums'] = feat['feat_question_asked_nums'].fillna(0)
        feat['feat_question_asked_corroct_nums'] = feat['feat_question_asked_corroct_nums'].fillna(0)

        return feat,[feat_question_asked_nums, feat_question_asked_corroct_nums]    
    
    # @timeclass('feat_question_asked_nums_and_corroct_nums_and_rate')
    def generate_test_feat(self,table,tmp):
        feat_question_asked_nums, feat_question_asked_corroct_nums = tmp
        
        df_test_model = table.df_test_model[['content_id']].copy()
        
        df_test_model['feat_question_asked_nums'] = df_test_model['content_id'].map(feat_question_asked_nums).fillna(0)
        df_test_model['feat_question_asked_corroct_nums'] = df_test_model['content_id'].map(feat_question_asked_corroct_nums).fillna(0)
        df_test_model['feat_question_asked_corroct_rate'] = df_test_model['feat_question_asked_corroct_nums']/df_test_model['feat_question_asked_nums']


        feat = df_test_model[['feat_question_asked_nums','feat_question_asked_corroct_nums','feat_question_asked_corroct_rate']]
        
        return feat

    # @timeclass('feat_question_asked_nums_and_corroct_nums_and_rate')
    def update_intermediate_feat(self,table,tmp):
        feat_question_asked_nums, feat_question_asked_corroct_nums = tmp
        df = table.last_group.copy()

        df = df.loc[df['content_type_id']==0,['content_id','answered_correctly']]
        
        if df.shape[0] == 0:
            return tmp
        
        tmp2 = df.groupby(['content_id'],sort=False)['answered_correctly'].agg(['size',sum])
        
        tmp2.columns = ['feat_question_asked_nums','feat_question_asked_corroct_nums']
        
        for content in tmp2.index:
            feat_question_asked_nums[content] += tmp2.loc[content,'feat_question_asked_nums']
            feat_question_asked_corroct_nums[content] += tmp2.loc[content,'feat_question_asked_corroct_nums']
        
        return [feat_question_asked_nums,feat_question_asked_corroct_nums]
    
    
# 最近一次的做题时间
class feat_time_interval_of_the_last_question(Feat):
    @timeclass('feat_time_interval_of_the_last_question')
    def generate_feat(self,table):
        df = table.df.copy()
        
        df = df.loc[~df['content_type_id'],['user_id','task_container_id','timestamp']]
        tmp = df.groupby(['user_id','task_container_id'],sort=False).first()
     
        result = tmp.groupby('user_id',sort=False).last()
        result.columns = ['last_timestamp']
        
        # pdb.set_trace()
        tmp -= tmp.groupby('user_id', sort=False).shift(1, fill_value=0)
        tmp.columns = ['time_interval_of_the_last_question']
        
        df = table.df_model[['user_id','task_container_id']].copy()
        df = df.merge(tmp, how='left',on=['user_id', 'task_container_id'])
        feat = df[['time_interval_of_the_last_question']].fillna(0)
        last_timestamp = defaultdict(int)
        last_timestamp.update(result['last_timestamp'])
        
        return feat,[last_timestamp]
        
    # @timeclass('feat_time_interval_of_the_last_question')
    def generate_test_feat(self,table,tmp):
        last_timestamp, = tmp
        df_test_model = table.df_test_model[['user_id','task_container_id','timestamp']].copy()
        df_test_model[['last_timestamp']] = df_test_model['user_id'].map(last_timestamp).fillna(0)

        # pdb.set_trace()
        df_test_model['time_interval_of_the_last_question'] = df_test_model['timestamp']-df_test_model['last_timestamp']
        
        feat = df_test_model[['time_interval_of_the_last_question']]
        
        return feat
    
    
    # @timeclass('feat_time_interval_of_the_last_question')
    def update_intermediate_feat(self,table,tmp):
        last_timestamp, = tmp
        df = table.last_group.copy()
        df = df.loc[df['content_type_id']==0,['user_id','task_container_id','timestamp']]
        if df.shape[0] == 0:
            return tmp
        
        tmp2 = df.groupby(['user_id','task_container_id'],sort=False).first()
        tmp2.columns = ['last_timestamp']
        tmp2 = tmp2.groupby('user_id',sort=False).last()
        
        for user in tmp2.index:
            last_timestamp[user] = tmp2.loc[user,'last_timestamp']
        return [last_timestamp]
    
    
class feat_user_this_part_history_question_nums_and_corroct_nums_and_rate(Feat):
    #这里说一下，一个task_container里可能有多个question，而且是同一batch给出，所以必须只能统计本task_container之前的值
    @timeclass('feat_user_this_part_history_question_nums_and_corroct_nums_and_rate')
    def generate_feat(self,table):
        df = table.df_model[['user_id','part','task_container_id','label']].copy()
        
        tmp = df.groupby(['user_id','task_container_id', 'part'],sort=False)['label'].agg(['size',sum])
        
        tmp = tmp.groupby(['user_id','part'],sort=False).cumsum()
        tmp.columns = ['feat_user_this_part_history_question_nums','feat_user_this_part_history_corroct_nums']
        
        result = tmp.groupby(['user_id','part'],sort=False).last()
        
        tmp = tmp.groupby(['user_id','part'],sort=False).shift(1).fillna(0).astype(int)
        
        
        df = df[['user_id','task_container_id']]
        df = df.merge(tmp,how='left',on=['user_id','task_container_id'])
        df.index = table.df_model.index
        
        df['feat_user_this_part_history_corroct_rate'] = df['feat_user_this_part_history_corroct_nums']/df['feat_user_this_part_history_question_nums']
        
        feat = df[['feat_user_this_part_history_question_nums','feat_user_this_part_history_corroct_nums','feat_user_this_part_history_corroct_rate']]
        
        
        result.reset_index(inplace=True)
        result.index = result['user_id'].astype(np.int64)*10+result['part']
        result.drop(columns=['user_id','part'],inplace=True)
        
        intermediate_feat = {}
        
        result_nums = result['feat_user_this_part_history_question_nums'].to_dict()
        result_corrects = result['feat_user_this_part_history_corroct_nums'].to_dict()
        
        
        return feat,[result_nums,result_corrects,intermediate_feat]
    
    
    # @timeclass('feat_user_this_part_history_question_nums_and_corroct_nums_and_rate')
    def generate_test_feat(self,table,tmp):
        result_nums,result_corrects,intermediate_feat = tmp
        
        df_test_model = table.df_test_model[['user_id','part']].copy()
        
        df_test_model = df_test_model['user_id'].astype(np.int64)*10+df_test_model['part']
        
        df_n = df_test_model.shape[0]
        
        feat = np.zeros((df_n,2),dtype=np.int16)
        
        
        for i,index in zip(range(df_n),df_test_model.values):
            # if index in result.index:
            if index in result_nums:
                feat[i,0] = result_nums[index]
                feat[i,1] = result_corrects[index]
            elif index in intermediate_feat:
                feat[i,:] = intermediate_feat[index]
                
        
        feat = pd.DataFrame(feat,index=df_test_model.index,columns=['feat_user_this_part_history_question_nums','feat_user_this_part_history_corroct_nums'])
        
        feat['feat_user_this_part_history_corroct_rate'] = feat['feat_user_this_part_history_corroct_nums']/feat['feat_user_this_part_history_question_nums']
        
        
        return feat
    

    # @timeclass('feat_user_this_part_history_question_nums_and_corroct_nums_and_rate')
    def update_intermediate_feat(self,table,tmp):    
        # result,intermediate_feat,question2part = tmp
        result_nums,result_corrects,intermediate_feat = tmp
        
        df = table.last_group_model[['user_id','part','label']].copy()
        
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*10+df['part']
        
        df = df['label']
        
        
        for i,v in zip(df.index,df.values):
            if i in result_nums:
                result_nums[i] += 1
                result_corrects[i] += v
            elif i in intermediate_feat:
                intermediate_feat[i] += np.array((1,v))
            else:
                intermediate_feat[i] = np.array((1,v))
        
        return [result_nums,result_corrects,intermediate_feat]
    

class feat_user_this_part_history_lecture_nums(Feat):
    #这里说一下，一个task_container里可能有多个question，而且是同一batch给出，所以必须只能统计本task_container之前的值
    @timeclass('feat_user_this_part_history_lecture_nums')
    def generate_feat(self,table):
        df = table.df.copy()
        df = df[['user_id','content_id','task_container_id','content_type_id']]
        
        question2part = table.questions_info.set_index('question_id')['part'].to_dict()
        
        df['part'] = df['content_id'].map(question2part)
        
        tmp = df.groupby(['user_id','task_container_id','part'],sort=False)['content_type_id'].agg([sum])
        tmp = tmp.groupby(['user_id','part'],sort=False).cumsum()
        tmp.columns = ['feat_user_this_part_history_lecture_nums']
        
        result = tmp.groupby(['user_id','part'],sort=False).last()
        
        tmp = tmp.groupby(['user_id','part'],sort=False).shift(1).fillna(0).astype(int)
        
        df = table.df_model[['user_id','task_container_id']].copy()
        
        #合并的意义在于可以返回一个和df行数相同且和每个userid及task_container_id相对应的feat_user_history_lecture_nums的series
        df = df.merge(tmp,how='left',on=['user_id','task_container_id'])
        
        feat = df[['feat_user_this_part_history_lecture_nums']]
        
        feat_user_this_part_history_lecture_nums = defaultdict(int)
        
        feat_user_this_part_history_lecture_nums.update(result['feat_user_this_part_history_lecture_nums'])
        
        return feat,[feat_user_this_part_history_lecture_nums,question2part]   
        
    
    # @timeclass('feat_user_this_part_history_lecture_nums')
    def generate_test_feat(self,table,tmp):
        
        feat_user_this_part_history_lecture_nums,question2part = tmp
        
        df_test_model = table.df_test_model[['user_id','content_id']].copy()
        df_test_model['part'] = df_test_model['content_id'].map(question2part)
        
        df_test_model['feat_user_this_part_history_lecture_nums'] = df_test_model.set_index(['user_id','part']).index.map(feat_user_this_part_history_lecture_nums)


        feat = df_test_model[['feat_user_this_part_history_lecture_nums']]
        
        return feat

    # @timeclass('feat_user_this_part_history_lecture_nums')
    def update_intermediate_feat(self,table,tmp):
        
        feat_user_this_part_history_lecture_nums,question2part = tmp
        
        df = table.last_group.copy()

        df = df.loc[df['content_type_id']==1,['user_id','content_id','task_container_id','content_type_id']]
        
        if df.shape[0] == 0:
            return tmp
        
        df['part'] = df['content_id'].map(question2part)
        
        tmp2 = df.groupby(['user_id','task_container_id', 'part'],sort=False)['content_type_id'].agg(['size'])
        tmp2 = tmp2.groupby(['user_id','part'],sort=False).cumsum()
        
        tmp2.columns = ['feat_user_this_part_history_lecture_nums']
        
        tmp2 = tmp2.groupby(['user_id','part'],sort=False).last()
        
        for index in tmp2.index:
            feat_user_history_lecture_nums[index] += tmp2.loc[index,'feat_user_this_part_history_lecture_nums']
            
        return [feat_user_this_part_history_lecture_nums,question2part]
    
    
class user_in_task_container_rate(Feat):
    def generate_feat(self, table):
        df = table.df_model[['task_container_id', 'user_id']].copy()
        
        tmp = df.groupby(['task_container_id'],sort=False)['user_id'].agg(['count','nunique'])
        
        tmp['user_in_task_container_rate'] = tmp['count']/tmp['nunique']
        
        df['user_in_task_container_rate'] = df['task_container_id'].map(tmp['user_in_task_container_rate'])
        
        feat = df[['user_in_task_container_rate']].fillna(0)
            
        return feat,[]
        
        
class feat_user_this_question_history_nums_and_correct_nums_and_rate(Feat):
    @timeclass('feat_user_this_question_history_nums_and_correct_nums_and_rate')
    def generate_feat(self,table):
        df = table.df_model[['user_id','content_id','label']].copy()
        df = df.set_index(['user_id','content_id'])
        
        tmp = df.groupby(['user_id','content_id'],sort=False)['label'].agg(['cumcount','cumsum'])

        tmp['cumcount'] += 1
        
        tmp.columns = ['feat_user_this_question_history_nums','feat_user_this_question_history_correct_nums']
        
        result = tmp.groupby(['user_id','content_id'],sort=False).last().astype(np.uint8).reset_index()
        
        
        tmp = tmp.groupby(['user_id','content_id'],sort=False).shift(1).fillna(0).astype(np.uint8)
        tmp['feat_user_this_question_history_correct_rate'] = tmp['feat_user_this_question_history_correct_nums']/tmp['feat_user_this_question_history_nums']
        tmp.index = table.df_model.index
        
        result.index = result['user_id'].astype(np.int64)*20000+result['content_id']
        result.drop(columns=['user_id','content_id'],inplace=True)
        
        intermediate_feat = {}
        
        return tmp,[result,intermediate_feat]
    
    # @timeclass('feat_user_this_question_history_nums_and_correct_nums_and_rate')
    def generate_test_feat(self,table,tmp):
        result,intermediate_feat = tmp
        df_test_model = table.df_test_model['user_id'].astype(np.int64)*20000+table.df_test_model['content_id']
        
        df_n = df_test_model.shape[0]
        
        
        feat = np.zeros((df_n,2),dtype=np.uint8)
        for i,index in zip(range(df_n),df_test_model.values):
            if index in result.index:
                feat[i,:] = result.loc[index]
            elif index in intermediate_feat:
                feat[i,:] = intermediate_feat[index]
        
        
        feat = pd.DataFrame(feat,index=df_test_model.index,columns=['feat_user_this_question_history_nums','feat_user_this_question_history_correct_nums'])
        
        feat['feat_user_this_question_history_correct_rate'] = feat['feat_user_this_question_history_correct_nums']/feat['feat_user_this_question_history_nums']
        
        return feat

    # @timeclass('feat_user_this_question_history_nums_and_correct_nums_and_rate')
    def update_intermediate_feat(self,table,tmp):
        result,intermediate_feat = tmp
        
        df = table.last_group_model[['user_id','content_id','label']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']

        df = df['label']
        
        
        for i,v in zip(df.index,df.values):
            if i in result.index:
                result.loc[i] += [1,v]
            elif i in intermediate_feat:
                intermediate_feat[i] += np.array((1,v),dtype=np.uint8)
            else:
                intermediate_feat[i] = np.array((1,v),dtype=np.uint8)
        
        return [result,intermediate_feat]


# 题目做错了，且没有explanation的题目数
class wa_and_no_explanation(Feat):
    def generate_feat(self, table):
        df = table.df.copy()
        df = df.loc[~df['content_type_id'],['user_id','task_container_id','answered_correctly','prior_question_had_explanation']]
        
        tmp = df.groupby(['user_id','task_container_id'], sort=False)['prior_question_had_explanation'].agg(['first'])
        tmp.columns = ['cur_question_had_explanation']
        tmp = tmp.groupby('user_id', sort=False).shift(-1)
        
        df = table.df[['user_id','task_container_id','answered_correctly']].copy()
        df = df.merge(tmp, how = 'left', on=['user_id', 'task_container_id'] )
        df['answered_correctly'] = df['answered_correctly'].shift(1)
        
        # 在该题之前改了多少题
        df['cur_question_had_explanation'] = df['cur_question_had_explanation'].shift(1)
        df['wa_and_no_explanation_num'] = ((df['cur_question_had_explanation']==0)&(df['cur_question_had_explanation']==0))
        tmp = df.groupby(['user_id','task_container_id'],sort=False)['wa_and_no_explanation_num'].agg(['size',sum])
        tmp = tmp.groupby('user_id',sort=False).cumsum()
        tmp.columns = ['question_nums','wa_and_no_explanation_num']
        tmp['question_nums'] -= 1
        result = tmp.groupby('user_id',sort=False).last()
        
        df1 = table.df.copy()
        tmp1 = df1.groupby(['user_id','task_container_id'],sort=False)['answered_correctly'].sum()
        result['last_question_correct'] = tmp1.groupby(['user_id'],sort=False).last()
        tmp1 = df1.groupby(['user_id','task_container_id'],sort=False)['answered_correctly'].size()
        result['last_question_size'] = tmp1.groupby(['user_id'],sort=False).last()
        
        
        df = table.df_model[['user_id','task_container_id']].copy()
        df = df.merge(tmp,how='left',on=['user_id','task_container_id'])
        # pdb.set_trace()
        df['wa_and_no_explanation_rate'] = df['wa_and_no_explanation_num']/df['question_nums']

        
        feat = df[['wa_and_no_explanation_num','question_nums','wa_and_no_explanation_rate']]
        
        
        wa_and_no_explanation_num = defaultdict(int)
        question_nums = defaultdict(int)
        last_question_correct = defaultdict(int)
        last_question_size = defaultdict(int)
        
        wa_and_no_explanation_num.update(result['wa_and_no_explanation_num'])
        question_nums.update(result['question_nums'])
        last_question_correct.update(result['last_question_correct'])
        last_question_size.update(result['last_question_size'])
        return feat, [wa_and_no_explanation_num,question_nums,last_question_correct,last_question_size]
        
        # df['prior_question_had_explanation'] = np.maximum(df['prior_question_had_explanation'], 0)
        # result = pd.DataFrame()
        # result['last_question_answer'] = df.groupby('user_id',sort=False)['answered_correctly'].last()
        # tmp = df.groupby('user_id',sort=False)['answered_correctly'].shift(1)
        # tmp1 = df.groupby('user_id',sort=False)['prior_question_had_explanation'].shift(0)
        # pdb.set_trace()
        # df['wa_and_no_explanation_num'] = ((tmp==0) & (tmp1==0))
        # df['wa_and_no_explanation_num'] = df.groupby('user_id', sort=False)['wa_and_no_explanation_num'].cumsum()
        # df['question_sum'] = 1
        # df['question_sum'] = df.groupby('user_id', sort=False)['question_sum'].cumsum()
        # df['wa_and_no_explanation_rate'] = df['wa_and_no_explanation_num']/df['question_sum']
        
        # result['wa_and_no_explanation_num'] = df.groupby('user_id',sort=False)['wa_and_no_explanation_num'].last()
        # result['question_sum'] = df.groupby('user_id',sort=False)['question_sum'].last()
        
        # feat = df[['wa_and_no_explanation_num','question_sum','wa_and_no_explanation_rate']]
        # wa_and_no_explanation_num = defaultdict(int)
        # question_sum = defaultdict(int)
        # last_question_answer = defaultdict(int)
        
        # wa_and_no_explanation_num.update(result['wa_and_no_explanation_num'])
        # question_sum.update(result['question_sum'])
        # last_question_answer.update(result['last_question_answer'])
        
        # return feat,[wa_and_no_explanation_num,question_sum,last_question_answer]
    
    def generate_test_feat(self,table,tmp):
        wa_and_no_explanation_num,question_sum,last_question_correct,last_question_size = tmp
        
        df_test_model = table.df_test_model[['user_id']].copy()
        df_test_model['wa_and_no_explanation_num'] = df_test_model['user_id'].map(wa_and_no_explanation_num)
        df_test_model['question_sum'] = df_test_model['user_id'].map(question_sum)
        df_test_model['wa_and_no_explanation_rate'] = df_test_model['wa_and_no_explanation_num']/df_test_model['question_sum']
        
        feat = df_test_model[['wa_and_no_explanation_num','question_sum','wa_and_no_explanation_rate']]
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        wa_and_no_explanation_num,question_nums,last_question_correct,last_question_size = tmp
        df = table.df.copy()
        df1 = table.last_group.copy()
        
        tmp = df.loc[df['content_type_id']==0,['user_id','task_container_id','prior_question_had_explanation']]
        
        tmp1 = tmp.groupby('user_id', sort=False).size()
        tmp = tmp.groupby('user_id', sort=False).first()
        for user in tmp.index:
            if( tmp.loc[user,'prior_question_had_explanation'] == 0 ):
                wa_and_no_explanation_num[user] += last_question_correct[user]
            question_nums[user] += last_question_size[user]
        
        tmp = df.groupby(['user_id','task_container_id'], sort=False)['answered_correctly'].sum()
        tmp = tmp.groupby('user_id').last()
        tmp1 = df.groupby(['user_id','task_container_id'], sort=False)['answered_correctly'].size()
        tmp1 = tmp1.groupby('user_id').last()
        for user in tmp.index:
            last_question_correct[user] = tmp[user]
            last_question_size[user] = tmp1[user]
            
        return [wa_and_no_explanation_num,question_nums,last_question_correct,last_question_size]
     
    
class feat_user_history_rolling3_container_question_nums_and_corroct_nums_and_rate(Feat):
    #这里说一下，一个task_container里可能有多个question，而且是同一batch给出，所以必须只能统计本task_container之前的值
    @timeclass('feat_user_history_rolling3_container_question_nums_and_corroct_nums_and_rate')
    def generate_feat(self,table):
        k = 3
        data_type = np.uint16
        df = table.df.copy()
        df = df.loc[~df['content_type_id'],['user_id','task_container_id','answered_correctly']]
        tmp = df.groupby(['user_id','task_container_id'],sort=False)['answered_correctly'].agg(['size',sum])
        
        tmp.reset_index(inplace=True)
        
        result = tmp[['user_id','size','sum']].groupby('user_id',sort=False).tail(k)
        result['num'] = result.groupby('user_id',sort=False).cumcount()+1
        result['num_sum'] = result['user_id'].map(result.groupby('user_id').size())
        result['num_sum'] = k-result['num_sum']
        result['num'] += result['num_sum']
        
        result = pd.pivot_table(result,index='user_id',columns='num',values=['size','sum'])
        result = result.fillna(0).astype(data_type)
        
        result_n = tmp['user_id'].max() + 1
        result_size = np.zeros((result_n,k),dtype=data_type)
        result_size[result.index,:] = result['size'].values
        result_sum = np.zeros((result_n,k),dtype=data_type)
        result_sum[result.index,:] = result['sum'].values
        
        
        tmp.set_index('task_container_id',inplace=True)
        
        tmp = tmp.groupby('user_id',sort=False)['size','sum'].rolling(window=k,min_periods=1).sum()
        
        tmp = tmp.groupby('user_id').shift(1).fillna(0).astype(data_type)
        
        tmp.columns = ['feat_user_history_rolling3_container_question_nums','feat_user_history_rolling3_container_question_corroct_nums']
        
        
        df = table.df_model[['user_id','task_container_id']].copy()
        df = df.merge(tmp,how='left',on=['user_id','task_container_id'])
        df.index = table.df_model.index
        df['feat_user_history_rolling3_container_question_corroct_rate'] = df['feat_user_history_rolling3_container_question_corroct_nums']/df['feat_user_history_rolling3_container_question_nums']
        
        feat = df[['feat_user_history_rolling3_container_question_nums','feat_user_history_rolling3_container_question_corroct_nums','feat_user_history_rolling3_container_question_corroct_rate']]
        
        
        intermediate_feat_size = {}
        intermediate_feat_sum = {}
        
        return feat,[result_size,result_sum,intermediate_feat_size,intermediate_feat_sum]
    
    # @timeclass('feat_user_history_rolling3_container_question_nums_and_corroct_nums_and_rate')
    def generate_test_feat(self,table,tmp):
        result_size,result_sum,intermediate_feat_size,intermediate_feat_sum = tmp
        
        df_test_model = table.df_test_model['user_id'].copy()
        
        df_n = df_test_model.shape[0]
        result_size_len = result_size.shape[0]
        
        feat = np.zeros((df_n,2),dtype=np.uint16)
        for i,user in zip(range(df_n),df_test_model.values):
            if user < result_size_len:
                feat[i,0] = result_size[user,:].sum()
                feat[i,1] = result_sum[user,:].sum()
            elif user in intermediate_feat_size:
                feat[i,0] = intermediate_feat_size[user].sum()
                feat[i,1] = intermediate_feat_sum[user].sum()
                
        feat = pd.DataFrame(feat,index=df_test_model.index,columns=['feat_user_history_rolling3_container_question_nums','feat_user_history_rolling3_container_question_corroct_nums'])
        
        feat['feat_user_history_rolling3_container_question_corroct_rate'] = feat['feat_user_history_rolling3_container_question_corroct_nums']/feat['feat_user_history_rolling3_container_question_nums']
        
        return feat

    # @timeclass('feat_user_history_rolling3_container_question_nums_and_corroct_nums_and_rate')
    def update_intermediate_feat(self,table,tmp):
        result_size,result_sum,intermediate_feat_size,intermediate_feat_sum = tmp
        df = table.last_group_model[['user_id','label']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        result_size_len = result_size.shape[0]
        
        df = df.groupby('user_id')['label'].agg(['size',sum])
        
        
        for user,label_size,label_sum in zip(df.index,df['size'],df['sum']):
            if user < result_size_len:
                result_size[user,:] = np.concatenate([result_size[user,1:],[label_size]])
                result_sum[user,:] = np.concatenate([result_sum[user,1:],[label_sum]])
            elif user in intermediate_feat_size:
                intermediate_feat_size[user] = np.concatenate([intermediate_feat_size[user][1:],[label_size]])
                intermediate_feat_sum[user] = np.concatenate([intermediate_feat_sum[user][1:],[label_sum]])
            else:
                intermediate_feat_size[user] = np.array([0,0,label_size])
                intermediate_feat_sum[user] = np.array([0,0,label_sum])
        
        return [result_size,result_sum,intermediate_feat_size,intermediate_feat_sum]
    
class feat_user_history_rolling_k_container_question_nums_and_corroct_nums_and_rate(Feat):
    #这里说一下，一个task_container里可能有多个question，而且是同一batch给出，所以必须只能统计本task_container之前的值
    @timeclass('feat_user_history_rolling_k_container_question_nums_and_corroct_nums_and_rate')
    def generate_feat(self,table):
        min_k = 3
        max_k = 10
        
        data_type = np.uint16
        df = table.df.copy()
        df = df.loc[~df['content_type_id'],['user_id','task_container_id','answered_correctly']]
        tmp = df.groupby(['user_id','task_container_id'],sort=False)['answered_correctly'].agg(['size',sum])
        
        tmp.reset_index(inplace=True)
        
        result = tmp[['user_id','size','sum']].groupby('user_id',sort=False).tail(max_k)
        result['num'] = result.groupby('user_id',sort=False).cumcount()+1
        result['num_sum'] = result['user_id'].map(result.groupby('user_id').size())
        result['num_sum'] = max_k-result['num_sum']
        result['num'] += result['num_sum']
        
        result = pd.pivot_table(result,index='user_id',columns='num',values=['size','sum'])
        result = result.fillna(0).astype(data_type)
        
        result_n = tmp['user_id'].max() + 1
        result_size = np.zeros((result_n,max_k),dtype=data_type)
        result_size[result.index,:] = result['size'].values
        result_sum = np.zeros((result_n,max_k),dtype=data_type)
        result_sum[result.index,:] = result['sum'].values
        
        
        tmp.set_index('task_container_id',inplace=True)
        
        tmp_list = []
        for k in range(min_k,max_k+1):
            print(f'feat rolling {k}')
        
            tmp2 = tmp.groupby('user_id',sort=False)['size','sum'].rolling(window=k,min_periods=1).sum()
            
            tmp2 = tmp2.groupby('user_id').shift(1).fillna(0).astype(data_type)
            
            tmp2.columns = [f'feat_user_history_rolling_{k}_container_question_nums',f'feat_user_history_rolling_{k}_container_question_corroct_nums']
            
            if k == min_k:
                tmp_index = tmp2.index
                
            tmp2.reset_index(drop=True,inplace=True)
            
            tmp_list.append(tmp2)
        
        tmp = pd.concat(tmp_list,axis=1)
        tmp.index = tmp_index
        
        df = table.df_model[['user_id','task_container_id']].copy()
        df = df.merge(tmp,how='left',on=['user_id','task_container_id'])
        
        for k in range(min_k,max_k+1):
            df[f'feat_user_history_rolling_{k}_container_question_corroct_rate'] = df[f'feat_user_history_rolling_{k}_container_question_corroct_nums']/df[f'feat_user_history_rolling_{k}_container_question_nums']
        
        df.index = table.df_model.index
        
        feat = df.drop(columns=['user_id','task_container_id'])
        
        intermediate_feat_size = {}
        intermediate_feat_sum = {}
        
        return feat,[min_k,max_k,result_size,result_sum,intermediate_feat_size,intermediate_feat_sum]
    
    # @timeclass('feat_user_history_rolling_k_container_question_nums_and_corroct_nums_and_rate')
    def generate_test_feat(self,table,tmp):
        min_k,max_k,result_size,result_sum,intermediate_feat_size,intermediate_feat_sum = tmp
        
        
        df_test_model = table.df_test_model['user_id'].copy()
        
        df_n = df_test_model.shape[0]
        result_size_len = result_size.shape[0]
        
        k_n = max_k-min_k+1
        
        feat = np.zeros((df_n,2*k_n),dtype=np.uint16)
        for i,user in zip(range(df_n),df_test_model.values):
            if user < result_size_len:
                for k,j in zip(range(min_k,max_k+1),range(k_n)):
                    feat[i,j*2] = result_size[user,-k:].sum()
                    feat[i,j*2+1] = result_sum[user,-k:].sum()
            elif user in intermediate_feat_size:
                for k,j in zip(range(min_k,max_k+1),range(k_n)):
                    feat[i,j*2] = intermediate_feat_size[user][-k:].sum()
                    feat[i,j*2+1] = intermediate_feat_size[user][-k:].sum()
        
        columns = []
        for k in range(min_k,max_k+1):
            columns.extend([f'feat_user_history_rolling_{k}_container_question_nums',f'feat_user_history_rolling_{k}_container_question_corroct_nums'])
        
        feat = pd.DataFrame(feat,index=df_test_model.index,columns=columns)
        
        for k in range(min_k,max_k+1):
            feat[f'feat_user_history_rolling_{k}_container_question_corroct_rate'] = feat[f'feat_user_history_rolling_{k}_container_question_corroct_nums']/feat[f'feat_user_history_rolling_{k}_container_question_nums']
            
        return feat

    # @timeclass('feat_user_history_rolling_k_container_question_nums_and_corroct_nums_and_rate')
    def update_intermediate_feat(self,table,tmp):
        min_k,max_k,result_size,result_sum,intermediate_feat_size,intermediate_feat_sum = tmp
        df = table.last_group_model[['user_id','label']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        result_size_len = result_size.shape[0]
        
        df = df.groupby('user_id')['label'].agg(['size',sum])
        
        
        for user,label_size,label_sum in zip(df.index,df['size'],df['sum']):
            if user < result_size_len:
                result_size[user,:] = np.concatenate([result_size[user,1:],[label_size]])
                result_sum[user,:] = np.concatenate([result_sum[user,1:],[label_sum]])
            elif user in intermediate_feat_size:
                intermediate_feat_size[user] = np.concatenate([intermediate_feat_size[user][1:],[label_size]])
                intermediate_feat_sum[user] = np.concatenate([intermediate_feat_sum[user][1:],[label_sum]])
            else:
                intermediate_feat_size[user] = np.array([0]*(max_k-1)+[label_size])
                intermediate_feat_sum[user] = np.array([0]*(max_k-1)+[label_sum])
        
        return [min_k,max_k,result_size,result_sum,intermediate_feat_size,intermediate_feat_sum]
    
    
    
class feat_loop_group_question_corroct_rate(Feat):
    #这里说一下，一个task_container里可能有多个question，而且是同一batch给出，所以必须只能统计本task_container之前的值
    @timeclass('feat_loop_group_question_corroct_rate')
    def generate_feat(self,table):
        df = table.df_model[['user_id','content_id','label']].copy()
        
        user_n = df['user_id'].nunique()
        k = 5
        smoothly_n = 20
        
        np.random.seed(seed)
        rand_group = np.random.randint(0,k,user_n)
        
        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))
        
        
        
        #三种映射方式，顺延一个；其余4个的均；其余所有（有权重）
        # #1
        # tmp = df.groupby(['group','content_id'])['label'].mean()
        # tmp['group'] = (tmp['group'] + 1) % 5
        
        # #2
        # tmp = df.groupby(['group','content_id'])['label'].mean().reset_index()
        
        # tmp = tmp.pivot_table(index='content_id',columns='group',values='label')
        # tmp_list = []
        # for i in range(k):
        #     tmp_a = tmp[[j for j in range(k) if j!=i]].mean(axis=1)
        #     tmp_a = tmp_a.rename('feat_loop_group_question_corroct_rate').reset_index()
        #     tmp_a['group'] = i
            
        #     tmp_list.append(tmp_a)
            
        # tmp = pd.concat(tmp_list,axis=0)
        
        #3
        
        columns = [f'feat_loop_group_question_{col}' for col in ['num','correct_num','corroct_rate']]
        
        tmp_list = []
        for i in range(k):
            tmp_a = df.loc[df['group']!=i].groupby('content_id')['label'].agg(['count','sum']).astype('int')
            tmp_a['mean'] = tmp_a['sum']/(tmp_a['count']+smoothly_n)
            
            tmp_a.columns = columns
            
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i
        
            tmp_list.append(tmp_a)
        
        tmp = pd.concat(tmp_list,axis=0)
        

        
        df = df.merge(tmp,how='left',on=['group','content_id'])
        df.index = table.df_model.index
        print(f"{df.loc[df['feat_loop_group_question_corroct_rate'].isnull(),'content_id'].nunique()} question is null")
        

        feat = df[columns]

        #测试集两种方式，5个的mean；整体的mean
        #1
        result = tmp.groupby('content_id')[columns].mean()
        result['feat_loop_group_question_num'] = result['feat_loop_group_question_num'].round().astype('int')
        result['feat_loop_group_question_correct_num'] = result['feat_loop_group_question_correct_num'].round().astype('int')
        # #2
        # result = df.groupby(['content_id'])['label'].mean().rename('feat_loop_group_question_corroct_rate')
        
        
        
        return feat,[result]
    
    # @timeclass('feat_loop_group_question_corroct_rate')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        columns = [f'feat_loop_group_question_{col}' for col in ['num','correct_num','corroct_rate']]
        
        df_test_model = table.df_test_model[['content_id']].copy()
        for col in columns:
            df_test_model[col] = df_test_model['content_id'].map(result[col])
        
        feat = df_test_model[columns]
        
        return feat

    # @timeclass('feat_loop_group_question_corroct_rate')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    

class feat_question_bundle_id(Feat):
    @timeclass('feat_question_bundle_id')
    def generate_feat(self,table):
        df = table.df_model.copy()
        df = df[['content_id']]
        question2bundle = table.questions_info.set_index('question_id')['bundle_id']
        df['bundle_id'] = df['content_id'].map(question2bundle)
        
        feat = df[['bundle_id']]
        return feat,[question2bundle]
    
    # @timeclass('feat_question_bundle_id')
    def generate_test_feat(self,table,tmp):
        question2bundle, = tmp
        df_test_model = table.df_test_model[['content_id']].copy()
        df_test_model['bundle_id'] = df_test_model['content_id'].map(question2bundle)

        feat = df_test_model[['bundle_id']]
        
        return feat
    
    # @timeclass('feat_question_bundle_id')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
class feat_dnn_question_tags(Feat):
    @timeclass('feat_dnn_question_tags')
    def generate_feat(self,table):
        question2tags = table.questions_info.copy()
        question2tags = question2tags.set_index('question_id')['tags']
        #没有tag，则给个默认值
        question2tags[question2tags.isnull()] = f'{max_tags+1}'
        question2tags = question2tags.str.strip().str.split(' ')
        
        
        question2tags = question2tags.apply(lambda x:[int(i) for i in x])
        
        # tmp_len = tmp.apply(len)
        
        df = table.df_model.copy()
        df = df[['content_id']]
        
        df['feat_dnn_question_tags'] = df['content_id'].map(question2tags)
        
        feat = df[['feat_dnn_question_tags']]
        
        return feat,[question2tags]
    
    # @timeclass('feat_dnn_question_tags')
    def generate_test_feat(self,table,tmp):
        question2tags, = tmp
        df_test_model = table.df_test_model[['content_id']].copy()
        df_test_model['feat_dnn_question_tags'] = df_test_model['content_id'].map(question2tags)

        feat = df_test_model[['feat_dnn_question_tags']]
        return feat
    
    # @timeclass('feat_dnn_question_tags')
    def update_intermediate_feat(self,table,tmp):
        return tmp
        
    
class feat_this_question_had_explanation_num_and_rate(Feat):
    @timeclass('feat_this_question_had_explanation_num_and_rate')
    def generate_feat(self, table):
        df = table.df_model.copy()
        df = df[['user_id','task_container_id','prior_question_had_explanation']]


        df.drop_duplicates(subset=['user_id','task_container_id'], keep='first', inplace=True)
        df['question_had_explanation'] = df.groupby(['user_id'],sort=False)['prior_question_had_explanation'].shift(-1).fillna(0)
        tmp = df[['user_id','task_container_id', 'question_had_explanation']]

        df = table.df_model.copy()
        df = df[['user_id', 'task_container_id', 'content_id']]
        df = df.merge(tmp, how='left', on=['user_id', 'task_container_id'])
        df = df[['content_id','question_had_explanation']]

        tmp = df.groupby(['content_id'],sort=False)['question_had_explanation'].agg(['size',sum])

        tmp.columns = ['this_question_num','this_question_had_explanation_num']
        tmp['this_question_had_explanation_rate'] = tmp['this_question_had_explanation_num']/tmp['this_question_num']

        df=table.df_model[['content_id']].copy()
        df=df.merge(tmp,how='left',on='content_id')
        df.index= table.df_model.index

        feat=df[['this_question_had_explanation_num','this_question_had_explanation_rate']]

        this_question_had_explanation_num = defaultdict(int)
        this_question_had_explanation_rate = defaultdict(int)

        this_question_had_explanation_num.update(tmp['this_question_had_explanation_num'])
        this_question_had_explanation_rate.update(tmp['this_question_had_explanation_rate'])
        return feat,[this_question_had_explanation_num,this_question_had_explanation_rate]

    def generate_test_feat(self, table, tmp):
        this_question_had_explanation_num, this_question_had_explanation_rate = tmp

        df_test_model = table.df_test_model[['content_id']].copy()

        df_test_model['this_question_had_explanation_num'] = df_test_model['content_id'].map(this_question_had_explanation_num)
        df_test_model['this_question_had_explanation_rate'] = df_test_model['content_id'].map(this_question_had_explanation_rate)
        df_test_model['this_question_had_explanation_num'].fillna(df_test_model['this_question_had_explanation_num'].mean())
        df_test_model['this_question_had_explanation_rate'].fillna(df_test_model['this_question_had_explanation_rate'].mean())
        feat = df_test_model[
            ['this_question_had_explanation_num', 'this_question_had_explanation_rate']]

        return feat

    def update_intermediate_feat(self, table, tmp):
        return tmp

class feat_question_bundleid(Feat):
    @timeclass('feat_question_bundleid')
    def generate_feat(self, table):
        df = table.df_model.copy()
        df = df[['content_id']]
        question2bundle = table.questions_info.set_index('question_id')['bundle_id']
        df['bundleid'] = df['content_id'].map(question2bundle)

        feat = df[['bundleid']]
        return feat, [question2bundle]

    # @timeclass('feat_question_part')
    def generate_test_feat(self, table, tmp):
        question2bundle, = tmp
        df_test_model = table.df_test_model[['content_id']].copy()
        df_test_model['bundleid'] = df_test_model['content_id'].map(question2bundle)

        feat = df_test_model[['bundleid']]

        return feat

    # @timeclass('feat_question_part')
    def update_intermediate_feat(self, table, tmp):
        return tmp

class feat_whole_user_lecture_nums(Feat):
    @timeclass('feat_whole_user_lecture_nums')
    def generate_feat(self, table):
        df = table.df.copy()
        df = df[['user_id', 'content_type_id']]
        df['content_type_id'] = boolean2int(df['content_type_id'])
        tmp = df.groupby(['user_id'], sort=False)['content_type_id'].agg([sum])
        tmp.columns = ['feat_whole_user_lecture_nums']

        df = table.df_model[['user_id']].copy()

        # 合并的意义在于可以返回一个和df行数相同且和每个userid及task_container_id相对应的feat_user_history_lecture_nums的series

        df[['feat_whole_user_lecture_nums']]  = df['user_id'].map(tmp['feat_whole_user_lecture_nums'])
        feat = df[['feat_whole_user_lecture_nums']].fillna(0)

        feat_whole_user_lecture_nums = defaultdict(int)

        feat_whole_user_lecture_nums.update(tmp['feat_whole_user_lecture_nums'])

        return feat, [feat_whole_user_lecture_nums]

        # @timeclass('feat_user_history_lecture_nums')

    def generate_test_feat(self, table, tmp):
        feat_whole_user_lecture_nums, = tmp

        df_test_model = table.df_test_model[['user_id']].copy()

        df_test_model['feat_whole_user_lecture_nums'] = df_test_model['user_id'].map(feat_whole_user_lecture_nums)


        feat = df_test_model[['feat_whole_user_lecture_nums']]

        return feat

    # @timeclass('feat_user_history_lecture_nums')
    def update_intermediate_feat(self, table, tmp):
        feat_whole_user_lecture_nums, = tmp

        df = table.last_group.copy()

        df = df.loc[df['content_type_id'] == 1, ['user_id',  'content_type_id']]

        if df.shape[0] == 0:
            return tmp

        tmp2 = df.groupby(['user_id'], sort=False)['content_type_id'].agg(['sum'])


        tmp2.columns = ['feat_whole_user_lecture_nums']



        for user in tmp2.index:
            feat_whole_user_lecture_nums[user] += tmp2.loc[user, 'feat_whole_user_lecture_nums']

        return [feat_whole_user_lecture_nums]

class feat_whole_user_avg_questiontime(Feat):
    @timeclass('feat_whole_user_avg_questiontime')
    def generate_feat(self, table):
        df = table.df.copy()
        df = df.loc[~df['content_type_id'], ['user_id', 'prior_question_elapsed_time']]

        tmp = df.groupby(['user_id'], sort=False)['prior_question_elapsed_time'].agg(['size', sum])

        tmp.columns = ['feat_user_questiontime_size', 'feat_user_questiontime_sum']

        feat_user_questiontime_size = defaultdict(int)
        feat_user_questiontime_sum = defaultdict(int)

        feat_user_questiontime_size.update(tmp['feat_user_questiontime_size'])
        feat_user_questiontime_sum.update(tmp['feat_user_questiontime_sum'])

        # 回答次数小于50的，给置空吧，leak太严重了感觉，也没啥统计意义。一共83个问题。而且正好可以学习一下没见过的问题要怎么预测。

        tmp['feat_user_questiontime_avg'] = tmp['feat_user_questiontime_sum'] / tmp['feat_user_questiontime_size']

        df = table.df_model[['user_id']].copy()
        df = df.merge(tmp, how='left', on=['user_id'])
        feat = df[['feat_user_questiontime_avg']]

        feat['feat_user_questiontime_avg'] = feat['feat_user_questiontime_avg'].fillna(0)

        return feat, [feat_user_questiontime_size, feat_user_questiontime_sum]

        # @timeclass('feat_question_asked_nums_and_corroct_nums_and_rate')

    def generate_test_feat(self, table, tmp):
        feat_user_questiontime_size, feat_user_questiontime_sum = tmp

        df_test_model = table.df_test_model[['user_id']].copy()

        df_test_model['feat_user_questiontime_size'] = df_test_model['user_id'].map(feat_user_questiontime_size).fillna(1)
        df_test_model['feat_user_questiontime_sum'] = df_test_model['user_id'].map(feat_user_questiontime_sum).fillna(0)
        df_test_model['feat_user_questiontime_avg'] = df_test_model['feat_user_questiontime_sum'] / df_test_model['feat_user_questiontime_size']

        feat = df_test_model[['feat_user_questiontime_avg']]

        return feat

    # @timeclass('feat_question_asked_nums_and_corroct_nums_and_rate')
    def update_intermediate_feat(self, table, tmp):
        feat_user_questiontime_size, feat_user_questiontime_sum = tmp
        df = table.last_group.copy()

        df = df.loc[df['content_type_id'] == 0, ['user_id', 'prior_question_elapsed_time']]

        if df.shape[0] == 0:
            return tmp

        tmp2 = df.groupby(['user_id'], sort=False)['prior_question_elapsed_time'].agg(['size', sum])

        tmp2.columns = ['feat_user_questiontime_size', 'feat_user_questiontime_sum']

        for content in tmp2.index:
            feat_user_questiontime_size[content] += tmp2.loc[content, 'feat_user_questiontime_size']
            feat_user_questiontime_sum[content] += tmp2.loc[content, 'feat_user_questiontime_sum']

        return [feat_user_questiontime_size, feat_user_questiontime_sum]

class feat_whole_question_avg_questiontime(Feat):
    @timeclass('feat_whole_user_avg_questiontime')
    def generate_feat(self, table):
        df = table.df_model.copy()
        df = df[['user_id', 'task_container_id', 'prior_question_elapsed_time']]

        df.drop_duplicates(subset=['user_id', 'task_container_id'], keep='first', inplace=True)
        df['question_elapsed_time'] = df.groupby(['user_id'], sort=False)['prior_question_elapsed_time'].shift(-1)
        df['question_elapsed_time'].fillna(df['question_elapsed_time'].mean())
        tmp = df[['user_id', 'task_container_id', 'question_elapsed_time']]

        df = table.df_model.copy()
        df = df[['user_id', 'task_container_id', 'content_id']]
        df = df.merge(tmp, how='left', on=['user_id', 'task_container_id'])
        df = df[['content_id', 'question_elapsed_time']]

        tmp = df.groupby(['content_id'], sort=False)['question_elapsed_time'].agg(['mean'])
        tmp.columns = ['feat_question_questiontime_avg']

        feat_question_questiontime_avg = defaultdict(int)

        feat_question_questiontime_avg.update(tmp['feat_question_questiontime_avg'])

        df = table.df_model[['content_id']].copy()
        df = df.merge(tmp, how='left', on=['content_id'])
        feat = df[['feat_question_questiontime_avg']]

        feat['feat_question_questiontime_avg'] = feat['feat_question_questiontime_avg'].fillna(0)

        return feat, feat_question_questiontime_avg


    def generate_test_feat(self, table, tmp):
        feat_question_questiontime_avg = tmp

        df_test_model = table.df_test_model[['content_id']].copy()

        df_test_model['feat_question_questiontime_avg'] = df_test_model['content_id'].map(feat_question_questiontime_avg)

        feat = df_test_model[['feat_question_questiontime_avg']].fillna(df_test_model['feat_question_questiontime_avg'].mean())

        return feat

    # @timeclass('feat_question_asked_nums_and_corroct_nums_and_rate')
    def update_intermediate_feat(self, table, tmp):
        return tmp


class feat_about_last_N_Container_content_id(Feat):
    @timeclass('feat_about_last_N_Container_content_id')
    def generate_feat(self, table):
        t1 = time.time()
        N = 3
        df = table.df.copy()
        # 不带label不用单独处理question
        df = df.loc[~df['content_type_id'],['user_id', 'task_container_id', 'content_id']]
        
        
        # 计算各个container中的活动数目
        tmp = df.groupby(['user_id', 'task_container_id'], sort=False)['content_id'].agg(['size'])
    
        last_N_container_content_num = defaultdict(list)
        
        tmp1 = tmp.groupby('user_id', sort=False).tail(N)
        
        #这里可以这样写
        tmp1 = tmp1.groupby('user_id',sort=False).agg(list)
        last_N_container_content_num.update(tmp1['size'])
        
        
        t2 = time.time()
        print(f'{t2-t1:.2f}sec')
        
        # count，计算前K个container中的活动数
        tmp.columns = ['feat_about_last_N_Container_content_id_count_']
        # tmp_count_statistics_all = tmp.groupby('user_id', sort=False).rolling(window=N, min_periods=1).agg(['mean','max','min','sum'])
        
        
        
        tmp_count_statistics_all = tmp.rolling(window=N, min_periods=1).agg(['mean','max','min','sum'])
        tmp_count_statistics_all.columns = [i+j for i,j in tmp_count_statistics_all.columns]
        
        tmp_count_statistics_all_values = tmp_count_statistics_all.values
        
        tmp['row'] = range(tmp.shape[0])
        
        tmp_count_statistics_1 = tmp.groupby('user_id', sort=False).first()
        tmp_count_statistics_all_values[tmp_count_statistics_1['row'],:] = tmp_count_statistics_1['feat_about_last_N_Container_content_id_count_'].values.reshape((-1,1))
        
        tmp_count_statistics_2 = tmp.groupby('user_id', sort=False).head(2)
        tmp_count_statistics_2_index = tmp_count_statistics_2.groupby('user_id',sort=False)['row'].last()
        tmp_count_statistics_2_values = tmp_count_statistics_2.groupby('user_id', sort=False)['feat_about_last_N_Container_content_id_count_'].agg(['mean','max','min','sum'])
        
        tmp_count_statistics_all_values[tmp_count_statistics_2_index,:] = tmp_count_statistics_2_values.values
        
        print(f'{(tmp_count_statistics_all_values!=tmp_count_statistics_all.values).sum()} data error')
        
        t3 = time.time()
        print(f'{t3-t2:.2f}sec')
        
        result = tmp_count_statistics_all.groupby('user_id', sort=False).last()
        
        tmp_count_statistics_all = tmp_count_statistics_all.groupby('user_id', sort=False).shift(1).fillna(0)
        
        
        t4 = time.time()
        print(f'{t4-t3:.2f}sec')
        
        df = table.df_model[['user_id', 'task_container_id']].copy()
        
        df = df.merge(tmp_count_statistics_all, how='left', on=['user_id', 'task_container_id'])
        
        t5 = time.time()
        print(f'{t5-t4:.2f}sec')
        
        feat = df[['feat_about_last_N_Container_content_id_count_mean', 'feat_about_last_N_Container_content_id_count_max', 
                    'feat_about_last_N_Container_content_id_count_min','feat_about_last_N_Container_content_id_count_sum']]
        
        feat_about_last_N_Container_content_id_count_mean = defaultdict(int)
        feat_about_last_N_Container_content_id_count_max = defaultdict(int)
        feat_about_last_N_Container_content_id_count_min = defaultdict(int)
        feat_about_last_N_Container_content_id_count_sum = defaultdict(int)
        
        feat_about_last_N_Container_content_id_count_mean.update(result['feat_about_last_N_Container_content_id_count_mean'])
        feat_about_last_N_Container_content_id_count_max.update(result['feat_about_last_N_Container_content_id_count_max'])
        feat_about_last_N_Container_content_id_count_min.update(result['feat_about_last_N_Container_content_id_count_min'])
        feat_about_last_N_Container_content_id_count_sum.update(result['feat_about_last_N_Container_content_id_count_sum'])
        
        
        t6 = time.time()
        print(f'{t6-t5:.2f}sec')
        
        return feat, [N,last_N_container_content_num, feat_about_last_N_Container_content_id_count_mean, 
                      feat_about_last_N_Container_content_id_count_max, feat_about_last_N_Container_content_id_count_min,
                      feat_about_last_N_Container_content_id_count_sum]
    
    
    # @timeclass('feat_about_last_N_Container_content_id')
    def generate_test_feat(self, table, tmp):
        N, last_N_container_content_num, feat_about_last_N_Container_content_id_count_mean, feat_about_last_N_Container_content_id_count_max, feat_about_last_N_Container_content_id_count_min, feat_about_last_N_Container_content_id_count_sum = tmp
        df_test_model = table.df_test_model[['user_id']].copy()
        
        
        df_test_model['feat_about_last_N_Container_content_id_count_mean'] = df_test_model['user_id'].map(feat_about_last_N_Container_content_id_count_mean)
        df_test_model['feat_about_last_N_Container_content_id_count_max'] = df_test_model['user_id'].map(feat_about_last_N_Container_content_id_count_max)
        df_test_model['feat_about_last_N_Container_content_id_count_min'] = df_test_model['user_id'].map(feat_about_last_N_Container_content_id_count_min)
        df_test_model['feat_about_last_N_Container_content_id_count_sum'] = df_test_model['user_id'].map(feat_about_last_N_Container_content_id_count_sum)
        feat = df_test_model[['feat_about_last_N_Container_content_id_count_mean', 'feat_about_last_N_Container_content_id_count_max', 
                    'feat_about_last_N_Container_content_id_count_min', 'feat_about_last_N_Container_content_id_count_sum']]
        
        return feat
    
    # @timeclass('feat_about_last_N_Container_content_id')
    def update_intermediate_feat(self, table, tmp):
        
        N,last_N_container_content_num, feat_about_last_N_Container_content_id_count_mean, feat_about_last_N_Container_content_id_count_max, feat_about_last_N_Container_content_id_count_min, feat_about_last_N_Container_content_id_count_sum = tmp
        #这里有问题，改了一点儿啊，last_group 是包含lecture的，和你训练集的逻辑不一致啊
        df = table.last_group_model.copy()
        # 每个batch只有一个container
        tmp1 = df.groupby(['user_id'], sort=False)['content_id'].size()
        tmp1.columns = ['content_num']
        # pdb.set_trace()
        for user in tmp1.index:
            if(user in last_N_container_content_num):
                last_N_container_content_num[user].append(tmp1[user])
            else:
                last_N_container_content_num[user] = [tmp1[user]]
            if(len(last_N_container_content_num[user]) > N):
                del(last_N_container_content_num[user][0])
            feat_about_last_N_Container_content_id_count_mean[user] = np.mean(last_N_container_content_num[user])
            feat_about_last_N_Container_content_id_count_max[user] = np.max(last_N_container_content_num[user])
            feat_about_last_N_Container_content_id_count_min[user] = np.min(last_N_container_content_num[user])
            feat_about_last_N_Container_content_id_count_sum[user] = np.sum(last_N_container_content_num[user])
        return [N,last_N_container_content_num, feat_about_last_N_Container_content_id_count_mean, 
                      feat_about_last_N_Container_content_id_count_max, feat_about_last_N_Container_content_id_count_min,
                      feat_about_last_N_Container_content_id_count_sum]


class feat_about_last_N_Container_timestamp(Feat):
    @timeclass('feat_about_last_N_Container_timestamp')
    def generate_feat(self, table):
        t1 = time.time()
        N = 3
        df = table.df.copy()
        # 不带label不用单独处理question
        df = df.loc[~df['content_type_id'],['user_id', 'task_container_id', 'timestamp']]
        
        # count 活动数目，已统计
        # mean 时间戳差值求均值，可计算出参加活动的频率
        tmp = df.groupby(['user_id', 'task_container_id'], sort=False).first()
        
        
        
        last_N_container_timestamp = defaultdict(list)
        
        tmp1 = tmp.groupby('user_id', sort=False).tail(N)
        
        #这里可以这样写
        tmp1 = tmp1.groupby('user_id',sort=False).agg(list)
        last_N_container_timestamp.update(tmp1['timestamp'])
        
        
        
        t2 = time.time()
        print(f'{t2-t1:.2f}sec')
        
        
        tmp.columns = ['feat_user_last_N_container_timestamp_']
        
        
        
        tmp_timestamp_statistics_all = tmp.rolling(window=N, min_periods=1).agg(['mean','max','min','sum'])
        tmp_timestamp_statistics_all.columns = [i+j for i,j in tmp_timestamp_statistics_all.columns]
        
        tmp_timestamp_statistics_all_values = tmp_timestamp_statistics_all.values
        
        tmp['row'] = range(tmp.shape[0])
        
        tmp_timestamp_statistics_1 = tmp.groupby('user_id', sort=False).first()
        tmp_timestamp_statistics_all_values[tmp_timestamp_statistics_1['row'],:] = tmp_timestamp_statistics_1['feat_user_last_N_container_timestamp_'].values.reshape((-1,1))
        
        tmp_timestamp_statistics_2 = tmp.groupby('user_id', sort=False).head(2)
        tmp_timestamp_statistics_2_index = tmp_timestamp_statistics_2.groupby('user_id',sort=False)['row'].last()
        tmp_timestamp_statistics_2_values = tmp_timestamp_statistics_2.groupby('user_id', sort=False)['feat_user_last_N_container_timestamp_'].agg(['mean','max','min','sum'])
        
        tmp_timestamp_statistics_all_values[tmp_timestamp_statistics_2_index,:] = tmp_timestamp_statistics_2_values.values
        
        print(f'{(tmp_timestamp_statistics_all_values!=tmp_timestamp_statistics_all.values).sum()} data error')
        
        t3 = time.time()
        print(f'{t3-t2:.2f}sec')
        
        result = tmp_timestamp_statistics_all.groupby('user_id', sort=False).last()
        
        tmp_timestamp_statistics_all = tmp_timestamp_statistics_all.groupby('user_id', sort=False).shift(1).fillna(0)
        
        
        t4 = time.time()
        print(f'{t4-t3:.2f}sec')
        
        df = table.df_model[['user_id', 'task_container_id','timestamp']].copy()
        
        df = df.merge(tmp_timestamp_statistics_all, how='left', on=['user_id', 'task_container_id'])
        
        
        df['feat_user_last_N_container_timestamp_mean'] = df['timestamp']-df['feat_user_last_N_container_timestamp_mean']        
        df['feat_user_last_N_container_timestamp_max'] = df['timestamp']-df['feat_user_last_N_container_timestamp_max']
        df['feat_user_last_N_container_timestamp_min'] = df['timestamp']-df['feat_user_last_N_container_timestamp_min']
        df['feat_user_last_N_container_timestamp_sum'] = df['timestamp']*N-df['feat_user_last_N_container_timestamp_sum']
        #*N这里有问题，如果不足3个呢？
        
        t5 = time.time()
        print(f'{t5-t4:.2f}sec')
        
        
        feat = df[['feat_user_last_N_container_timestamp_mean', 'feat_user_last_N_container_timestamp_max', 
                   'feat_user_last_N_container_timestamp_min','feat_user_last_N_container_timestamp_sum']]
        
        feat_user_last_N_container_timestamp_mean = defaultdict(int)
        feat_user_last_N_container_timestamp_max = defaultdict(int)
        feat_user_last_N_container_timestamp_min = defaultdict(int)
        feat_user_last_N_container_timestamp_sum = defaultdict(int)
        
        feat_user_last_N_container_timestamp_mean.update(result['feat_user_last_N_container_timestamp_mean'])
        feat_user_last_N_container_timestamp_max.update(result['feat_user_last_N_container_timestamp_max'])
        feat_user_last_N_container_timestamp_min.update(result['feat_user_last_N_container_timestamp_min'])
        feat_user_last_N_container_timestamp_sum.update(result['feat_user_last_N_container_timestamp_sum'])
        
        # pdb.set_trace()
        return feat, [N, last_N_container_timestamp, feat_user_last_N_container_timestamp_mean, 
                      feat_user_last_N_container_timestamp_max, feat_user_last_N_container_timestamp_min,
                      feat_user_last_N_container_timestamp_sum]
    
    def generate_test_feat(self, table, tmp):
        N,last_N_container_timestamp, feat_user_last_N_container_timestamp_mean, feat_user_last_N_container_timestamp_max, feat_user_last_N_container_timestamp_min, feat_user_last_N_container_timestamp_sum = tmp
        df_test_model = df_test_model = table.df_test_model[['user_id','timestamp']].copy()


        df_test_model['feat_user_last_N_container_timestamp_mean'] = df_test_model['timestamp'] - df_test_model['user_id'].map(feat_user_last_N_container_timestamp_mean)
        df_test_model['feat_user_last_N_container_timestamp_max'] = df_test_model['timestamp'] - df_test_model['user_id'].map(feat_user_last_N_container_timestamp_max)
        df_test_model['feat_user_last_N_container_timestamp_min'] = df_test_model['timestamp'] - df_test_model['user_id'].map(feat_user_last_N_container_timestamp_min)
        df_test_model['feat_user_last_N_container_timestamp_sum'] = df_test_model['timestamp']*N - df_test_model['user_id'].map(feat_user_last_N_container_timestamp_sum)
        feat = df_test_model[['feat_user_last_N_container_timestamp_mean', 'feat_user_last_N_container_timestamp_max', 
                   'feat_user_last_N_container_timestamp_min', 'feat_user_last_N_container_timestamp_sum']]
        
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        N,last_N_container_timestamp, feat_user_last_N_container_timestamp_mean, feat_user_last_N_container_timestamp_max, feat_user_last_N_container_timestamp_min, feat_user_last_N_container_timestamp_sum = tmp
        # df = table.last_group.copy()
        #这里有问题
        df = table.last_group_model.copy()
        
        tmp1 = df.groupby(['user_id'], sort=False)['timestamp'].first()
        tmp1.columns = ['timestamp']
        
        for user in tmp1.index:
            if(user in last_N_container_timestamp):
                last_N_container_timestamp[user].append(tmp1[user])
            else:
                last_N_container_timestamp[user] = [tmp1[user]]
            if(len(last_N_container_timestamp[user]) > N):
                del(last_N_container_timestamp[user][0])
            feat_user_last_N_container_timestamp_mean[user] = np.mean(last_N_container_timestamp[user])
            feat_user_last_N_container_timestamp_max[user] = np.max(last_N_container_timestamp[user])
            feat_user_last_N_container_timestamp_min[user] = np.min(last_N_container_timestamp[user])
            feat_user_last_N_container_timestamp_sum[user] = np.sum(last_N_container_timestamp[user])
        return [N,last_N_container_timestamp, feat_user_last_N_container_timestamp_mean, 
                      feat_user_last_N_container_timestamp_max, feat_user_last_N_container_timestamp_min,
                      feat_user_last_N_container_timestamp_sum]
    


class feat_timestamp(Feat):
    @timeclass('feat_timestamp')
    def generate_feat(self,table):
        df = table.df.copy()
        
        df = df.loc[~df['content_type_id'],['user_id','task_container_id','timestamp']]
        tmp = df.groupby(['user_id','task_container_id'],sort=False).first()
     
        tmp.columns = ['feat_timestamp']
        
        df = table.df_model[['user_id','task_container_id']].copy()
        df = df.merge(tmp, how='left',on=['user_id', 'task_container_id'])
        feat = df[['feat_timestamp']].fillna(0)
        
        return feat,[]
        
    # @timeclass('feat_timestamp')
    def generate_test_feat(self,table,tmp):
        df_test_model = table.df_test_model[['timestamp']].copy()
        df_test_model.rename(columns={'timestamp':'feat_timestamp'},inplace=True)
        
        feat = df_test_model[['feat_timestamp']]
        
        return feat
    
    
    # @timeclass('feat_timestamp')
    def update_intermediate_feat(self,table,tmp):
        return []

    
class feat_question_correct_answer(Feat):
    @timeclass('feat_question_correct_answer')
    def generate_feat(self, table):
        df = table.df_model[['content_id']].copy()
        question_correct_answer = table.questions_info.set_index('question_id')['correct_answer']
        df['correct_answer'] = df['content_id'].map(question_correct_answer)

        feat = df[['correct_answer']]
        return feat, [question_correct_answer]

    # @timeclass('feat_question_correct_answer')
    def generate_test_feat(self, table, tmp):
        question_correct_answer, = tmp
        df_test_model = table.df_test_model[['content_id']].copy()
        df_test_model['correct_answer'] = df_test_model['content_id'].map(question_correct_answer)

        feat = df_test_model[['correct_answer']]

        return feat

    # @timeclass('feat_question_correct_answer')
    def update_intermediate_feat(self, table, tmp):
        return tmp
    
    
class feat_user_question_history_every_answer_nums(Feat):
    @timeclass('feat_user_question_history_every_answer_nums')
    def generate_feat(self, table):
        df = table.df.loc[~table.df['content_type_id'],['user_id','task_container_id','user_answer']]
        
        df = pd.concat([df[['user_id','task_container_id']],pd.get_dummies(df['user_answer'])],axis=1)
        
        df = df.groupby(['user_id','task_container_id'],sort=False).sum()
        columns = [f'user_history_answer{i}_nums' for i in df.columns]
        df.columns = columns
        df = df.groupby('user_id',sort=False).cumsum()
        
        result = df.groupby('user_id',sort=False).last()
        result2 = np.zeros((500000,4))
        result2[result.index,:] = result.values
        
        df = df.groupby('user_id',sort=False).shift(1).fillna(0).astype(int)
        
        feat = table.df_model[['user_id','task_container_id']].copy()
        feat = feat.merge(df,how='left',on=['user_id','task_container_id'])
        feat = feat[columns]
        feat.index = table.df_model.index
        
        return feat, [result2,columns]

    # @timeclass('feat_user_question_history_every_answer_nums')
    def generate_test_feat(self, table, tmp):
        result,columns = tmp
        
        feat = pd.DataFrame(result[table.df_test_model['user_id'],:],index=table.df_test_model.index,columns=columns)


        return feat

    # @timeclass('feat_user_question_history_every_answer_nums')
    def update_intermediate_feat(self, table, tmp):
        result,columns = tmp
        
        #性能优化
        df = table.last_group.loc[['content_type_id','user_id','user_answer']].copy()
        df['content_type_id'] = df['content_type_id'].astype(bool)
        
        df = table.last_group.loc[~table.last_group['content_type_id'],['user_id','user_answer']]
        df.set_index('user_id',inplace=True)
        df = pd.get_dummies(df['user_answer'])
        
        for i in df.columns:
            result[df.index,i] += df[i]
        
        
        return [result,columns]
    
    
class feat_user_question_history_every_answer_nums2(Feat):
    @timeclass('feat_user_question_history_every_answer_nums2')
    def generate_feat(self, table):
        df = table.df.loc[~table.df['content_type_id'],['user_id','task_container_id','user_answer']]
        
        df = pd.concat([df[['user_id','task_container_id']],pd.get_dummies(df['user_answer'])],axis=1)
        
        df = df.groupby(['user_id','task_container_id'],sort=False).sum()
        columns = [f'user_history_answer{i}_nums' for i in df.columns]
        df.columns = columns
        df = df.groupby('user_id',sort=False).cumsum()
        
        result = df.groupby('user_id',sort=False).last()
        result2 = np.zeros((500000,4))
        result2[result.index,:] = result.values
        
        df = df.groupby('user_id',sort=False).shift(1).fillna(0).astype(int)
        
        
        feat = table.df_model[['user_id','task_container_id']].copy()
        feat = feat.merge(df,how='left',on=['user_id','task_container_id'])
        feat = feat[columns]
        
        
        question_correct_answer = table.questions_info.set_index('question_id')['correct_answer']
        
        feat['user_history_maximum_likelihood_answer_equal_question_correct_answer'] = feat.values.argmax(axis=1) == table.df_model['content_id'].map(question_correct_answer).values
        
        feat['user_history_maximum_likelihood_answer_equal_question_correct_answer'] = feat['user_history_maximum_likelihood_answer_equal_question_correct_answer'].astype(np.int8)
        
        feat.index = table.df_model.index
        
        return feat, [result2,columns,question_correct_answer]

    # @timeclass('feat_user_question_history_every_answer_nums2')
    def generate_test_feat(self, table, tmp):
        result,columns,question_correct_answer = tmp
        
        feat = pd.DataFrame(result[table.df_test_model['user_id'],:],index=table.df_test_model.index,columns=columns)

        feat['user_history_maximum_likelihood_answer_equal_question_correct_answer'] = feat.values.argmax(axis=1) == table.df_test_model['content_id'].map(question_correct_answer).values
        
        feat['user_history_maximum_likelihood_answer_equal_question_correct_answer'] = feat['user_history_maximum_likelihood_answer_equal_question_correct_answer'].astype(np.int8)
        

        return feat

    # @timeclass('feat_user_question_history_every_answer_nums2')
    def update_intermediate_feat(self, table, tmp):
        result,columns,question_correct_answer = tmp
        
        #性能优化
        df = table.last_group[['content_type_id','user_id','user_answer']].copy()
        df['content_type_id'] = df['content_type_id'].astype(bool)
        
        df = df.loc[~df['content_type_id'],['user_id','user_answer']]
        df.set_index('user_id',inplace=True)
        df = pd.get_dummies(df['user_answer'])
        
        for i in df.columns:
            result[df.index,i] += df[i]
        
        
        return [result,columns,question_correct_answer]
    
class feat_question_tags_encoding(Feat):
    @timeclass('feat_question_tags_encoding')
    def generate_feat(self, table):
        question_tags_encoding = table.questions_info.copy()
        question_tags_encoding = question_tags_encoding.set_index('question_id')['tags']
        #没有tag，则给个默认值
        question_tags_encoding[question_tags_encoding.isnull()] = f'{max_tags+1}'
        question_tags_encoding = question_tags_encoding.str.strip().str.split(' ')
        
        question_tags_encoding = question_tags_encoding.apply(lambda x:[int(i) for i in x])
        question_tags_encoding = question_tags_encoding.apply(np.sort)
        question_tags_encoding = question_tags_encoding.apply(str)
        
        tag_dict = dict((v, i) for i,v in enumerate(question_tags_encoding.unique()))
        
        question_tags_encoding = question_tags_encoding.map(tag_dict)
        
        df = table.df_model[['content_id']].copy()
        df['feat_question_tags_encoding'] = df['content_id'].map(question_tags_encoding)

        feat = df[['feat_question_tags_encoding']]
        return feat, [question_tags_encoding]

    # @timeclass('feat_question_tags_encoding')
    def generate_test_feat(self, table, tmp):
        question_tags_encoding, = tmp
        df_test_model = table.df_test_model[['content_id']].copy()
        df_test_model['feat_question_tags_encoding'] = df_test_model['content_id'].map(question_tags_encoding)

        feat = df_test_model[['feat_question_tags_encoding']]

        return feat

    # @timeclass('feat_question_tags_encoding')
    def update_intermediate_feat(self, table, tmp):
        return tmp
    
    
class feat_question_first_tag6(Feat):
    @timeclass('feat_question_first_tag6')
    def generate_feat(self,table):
        question_tags = table.questions_info.copy()
        question_tags = question_tags.set_index('question_id')['tags']
        #没有tag，则给个默认值
        question_tags[question_tags.isnull()] = f'{max_tags+1}'
        question_tags = question_tags.str.strip().str.split(' ')
        
        
        def get_k(x,i):
            if i<len(x):
                return int(x[i])
            return np.nan
        
        range_n = 6
        question_tags_values = np.zeros((question_tags.shape[0],range_n))
        
        for i in range(range_n):
            question_tags_values[:,i] = question_tags.apply(lambda x:get_k(x,i)).values
        
        columns = [f'feat_question_tags_{i}' for i in range(range_n)]
        
        
        feat = pd.DataFrame(question_tags_values[table.df_model['content_id'],:],index=table.df_model.index,columns=columns)

        return feat,[question_tags_values,columns]
    
    # @timeclass('feat_question_first_tag6')
    def generate_test_feat(self,table,tmp):
        question_tags_values,columns = tmp
        
        feat = pd.DataFrame(question_tags_values[table.df_test_model['content_id'],:],index=table.df_test_model.index,columns=columns)
        
        return feat
    
    # @timeclass('feat_question_first_tag6')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    
class feat_last_3_lecture_id(Feat):
    @timeclass('feat_last_3_lecture_id')
    def generate_feat(self,table):
        #这个甚至不用last container，因为测试集也能拿到
        N = 3
        
        df = table.df[['user_id','content_id','content_type_id']]
        df['user_lecture_num'] = df.groupby('user_id',sort=False)['content_type_id'].cumsum()
        df_lecture = df.loc[df['content_type_id'],['user_id','content_id','user_lecture_num']]
        
        for i in range(N-1):
            df_lecture[f'last_{i+2}_lecture_id'] = df_lecture.groupby('user_id',sort=False)['content_id'].shift(i+1)
        
        df_lecture.rename(columns={'content_id':f'last_1_lecture_id'},inplace=True)
        
        df = df.loc[~df['content_type_id']]
        df = df.merge(df_lecture,how='left',on=['user_id','user_lecture_num'])
        
        columns = [f'last_{i+1}_lecture_id' for i in range(N)]
        feat = df[columns]
        
        tmp = df.groupby('user_id',sort=False)[columns].last()
        result = np.zeros((500000,N))*np.nan
        result[tmp.index,:] = tmp.values
        
        return feat,[N,result,columns]
    
    # @timeclass('feat_last_3_lecture_id')
    def generate_test_feat(self,table,tmp):
        N,result,columns = tmp
        df = table.df_test.copy()
        df['content_type_id'] = df['content_type_id'].astype(bool)
        
        feat_n = (~df['content_type_id']).sum()
        
        feat = np.zeros((feat_n,N))*np.nan
        
        p = 0
        for user,content,content_type in zip(df['user_id'],df['content_id'],df['content_type_id']):
            if content_type:
                result[user,1:] = result[user,:N-1]
                result[user,0] = content
            else:
                feat[p,:] = result[user,:]
                p += 1
        
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=columns)
        
        #这里result没有返回，不过也会更新的，因为直接改了内存中的值
        return feat
    
    # @timeclass('feat_last_3_lecture_id')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    
class feat_question_tags_num(Feat):
    @timeclass('feat_question_tags_num')
    def generate_feat(self,table):
        question_tags = table.questions_info.copy()
        question_tags = question_tags.set_index('question_id')['tags']
        
        def get_len(x):
            if type(x) is float:
                return 0
            else:
                return len(x)
        
        question_tags = question_tags.str.strip().str.split(' ')
        question_tags_num = question_tags.apply(get_len)
        
        df = table.df_model[['content_id']].copy()
        df['feat_question_tags_num'] = df['content_id'].map(question_tags_num)
        feat = df[['feat_question_tags_num']]
        
        return feat,[question_tags_num]
    
    # @timeclass('feat_question_tags_num')
    def generate_test_feat(self,table,tmp):
        question_tags_num, = tmp
        
        df = table.df_test_model[['content_id']].copy()
        df['feat_question_tags_num'] = df['content_id'].map(question_tags_num)
        feat = df[['feat_question_tags_num']]
        
        return feat
    
    # @timeclass('feat_question_tags_num')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    
class feat_question_tags_num(Feat):
    @timeclass('feat_question_tags_num')
    def generate_feat(self,table):
        question_tags = table.questions_info.copy()
        question_tags = question_tags.set_index('question_id')['tags']
        
        def get_len(x):
            if type(x) is float:
                return 0
            else:
                return len(x)
        
        question_tags = question_tags.str.strip().str.split(' ')
        question_tags_num = question_tags.apply(get_len)
        
        df = table.df_model[['content_id']].copy()
        df['feat_question_tags_num'] = df['content_id'].map(question_tags_num)
        feat = df[['feat_question_tags_num']]
        
        return feat,[question_tags_num]
    
    # @timeclass('feat_question_tags_num')
    def generate_test_feat(self,table,tmp):
        question_tags_num, = tmp
        
        df = table.df_test_model[['content_id']].copy()
        df['feat_question_tags_num'] = df['content_id'].map(question_tags_num)
        feat = df[['feat_question_tags_num']]
        
        return feat
    
    # @timeclass('feat_question_tags_num')
    def update_intermediate_feat(self,table,tmp):
        return tmp


class feat_user_history_loop_group_question_corroct_rate_mean(Feat):
    @timeclass('feat_user_history_loop_group_question_corroct_rate_mean')
    def generate_feat(self,table):
        df = table.df_model[['user_id','feat_loop_group_question_corroct_rate']].copy()
        
        df.set_index('user_id',inplace=True)
        tmp = pd.concat([df.groupby('user_id',sort=False).cumsum(),df.groupby('user_id',sort=False).cumcount()+1],axis=1)
        tmp.columns = ['user_history_loop_group_question_corroct_rate_mean','count']
        
        result = tmp.groupby('user_id',sort=False).last()
        
        tmp['user_history_loop_group_question_corroct_rate_mean'] /= tmp['count']
        
        feat = tmp[['user_history_loop_group_question_corroct_rate_mean']]
        feat.index = table.df_model.index
        
        result_val = np.zeros((500000,2))
        result_val[result.index,:] = result.values
        
        return feat,[result_val]
    
    # @timeclass('feat_user_history_loop_group_question_corroct_rate_mean')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        df = table.df_test_model[['user_id','feat_loop_group_question_corroct_rate']].copy()
        
        feat_n = df.shape[0]
        
        feat = np.zeros((feat_n,1))
        
        i = 0
        for user,corroct_rate in zip(df['user_id'],df['feat_loop_group_question_corroct_rate']):
            result[user,1] += 1
            result[user,0] += corroct_rate
            feat[i,0] = result[user,0]/result[user,1]
            
            i += 1
        
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['user_history_loop_group_question_corroct_rate_mean'])
        
        #这里result没有返回，不过也会更新的，因为直接改了内存中的值
        return feat

    # @timeclass('feat_user_history_loop_group_question_corroct_rate_mean')
    def update_intermediate_feat(self,table,tmp):
        return tmp   
    
    
class feat_loop_group_bundle_id_corroct_rate(Feat):
    @timeclass('feat_loop_group_bundle_id_corroct_rate')
    def generate_feat(self,table):
        df = table.df_model[['user_id','bundleid','label']].copy()
        
        user_n = df['user_id'].nunique()
        k = 5
        
        np.random.seed(seed)
        rand_group = np.random.randint(0,k,user_n)
        
        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))

        
        columns = ['feat_loop_group_bundle_id_corroct_rate']
        
        tmp_list = []
        for i in range(k):
            tmp_a = df.loc[df['group']!=i].groupby('bundleid')['label'].agg(['mean'])
            tmp_a.columns = columns
            
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i
        
            tmp_list.append(tmp_a)
        
        tmp = pd.concat(tmp_list,axis=0)
        

        
        df = df.merge(tmp,how='left',on=['group','bundleid'])
        df.index = table.df_model.index

        feat = df[columns]

        #测试集两种方式，5个的mean；整体的mean
        #1
        result = tmp.groupby(['bundleid'])[columns].mean()
        
        
        return feat,[result]
    
    # @timeclass('feat_loop_group_bundle_id_corroct_rate')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        columns = ['feat_loop_group_bundle_id_corroct_rate']
        
        df_test_model = table.df_test_model[['bundleid']].copy()
        for col in columns:
            df_test_model[col] = df_test_model['bundleid'].map(result[col])
        
        feat = df_test_model[columns]
        
        return feat

    # @timeclass('feat_loop_group_bundle_id_corroct_rate')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    
class feat_loop_group_tags_encoding_corroct_rate(Feat):
    @timeclass('feat_loop_group_tags_encoding_corroct_rate')
    def generate_feat(self,table):
        df = table.df_model[['user_id','feat_question_tags_encoding','label']].copy()
        
        user_n = df['user_id'].nunique()
        k = 5
        
        np.random.seed(seed)
        rand_group = np.random.randint(0,k,user_n)
        
        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))

        
        columns = ['feat_loop_group_tags_encoding_corroct_rate']
        
        tmp_list = []
        for i in range(k):
            tmp_a = df.loc[df['group']!=i].groupby('feat_question_tags_encoding')['label'].agg(['mean'])
            tmp_a.columns = columns
            
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i
        
            tmp_list.append(tmp_a)
        
        tmp = pd.concat(tmp_list,axis=0)
        

        
        df = df.merge(tmp,how='left',on=['group','feat_question_tags_encoding'])
        df.index = table.df_model.index

        feat = df[columns]

        #测试集两种方式，5个的mean；整体的mean
        #1
        result = tmp.groupby(['feat_question_tags_encoding'])[columns].mean()
        
        
        return feat,[result]
    
    # @timeclass('feat_loop_group_tags_encoding_corroct_rate')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        columns = ['feat_loop_group_tags_encoding_corroct_rate']
        
        df_test_model = table.df_test_model[['feat_question_tags_encoding']].copy()
        for col in columns:
            df_test_model[col] = df_test_model['feat_question_tags_encoding'].map(result[col])
        
        feat = df_test_model[columns]
        
        return feat

    # @timeclass('feat_loop_group_tags_encoding_corroct_rate')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    
class feat_user_session(Feat):
    @timeclass('feat_user_session')
    def generate_feat(self,table):
        
        df = table.df_model[['user_id','timestamp']].copy()
        
        
        df['timestamp_diff'] = df.groupby('user_id',sort=False)['timestamp'].diff().fillna(0)
        df['timestamp_diff'] = df['timestamp_diff']/1000/3600
        
        df['session'] = 0
        df.loc[df['timestamp_diff']>1,'session'] = 1
        df['session'] = df.groupby('user_id',sort=False)['session'].cumsum()
        
        feat = df[['session']]
        
        
        result = df.groupby('user_id',sort=False)[['timestamp','session']].last()
        
        result_v = np.zeros((500000,2),dtype=np.int64)
        
        result_v[result.index,:] = result.values
        
        return feat,[result_v]
    
    # @timeclass('feat_user_session')
    def generate_test_feat(self,table,tmp):
        result_v, = tmp
        
        df = table.df_test_model[['user_id','timestamp']].copy()
        
        feat_n = df.shape[0]
        
        feat = np.zeros((feat_n,1),dtype=np.int)
        
        i = 0
        for user,timestamp in zip(df['user_id'],df['timestamp']):
            t = result_v[user,0]
            if (timestamp - t)/3600000 > 1:
                result_v[user,1] += 1
            feat[i,0] = result_v[user,1]
            
            result_v[user,0] = timestamp
            
            i += 1
            
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['session'])
        
        #这里result没有返回，不过也会更新的，因为直接改了内存中的值
        return feat
    
    # @timeclass('feat_user_session')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    
class feat_user_this_session_history_nums_and_correct_nums_and_rate(Feat):
    @timeclass('feat_user_this_session_history_nums_and_correct_nums_and_rate')
    def generate_feat(self,table):
        df = table.df_model[['user_id','task_container_id','session','label']].copy()
        df.set_index(['user_id','session','task_container_id'],inplace=True)
        
        tmp = df.groupby(['user_id','session','task_container_id'],sort=False)['label'].agg(['count','sum'])
        columns = [f'feat_user_this_session_history_{col}' for col in ['num','correct_num']]
        tmp.columns = columns
        
        tmp = tmp.groupby(['user_id','session'],sort=False).cumsum()
        
        result = tmp.reset_index().groupby(['user_id'],sort=False)[['session']+columns].last()
        result_v = np.zeros((500000,3),dtype=np.int)
        result_v[result.index,:] = result.values
        
        tmp = tmp.groupby(['user_id','session'],sort=False).shift().fillna(0).astype(int)
        
        df = df.merge(tmp,how='left',on=['user_id','task_container_id'])
        df.index = table.df_model.index
        feat = df[columns]
        feat[f'feat_user_this_session_history_correct_rate'] = feat[f'feat_user_this_session_history_correct_num']/feat[f'feat_user_this_session_history_num']
        
        return feat,[result_v]
    
    # @timeclass('feat_user_this_session_history_nums_and_correct_nums_and_rate')
    def generate_test_feat(self,table,tmp):
        result_v, = tmp
        df = table.df_test_model[['user_id','session']].copy()
        feat = result_v[df['user_id'],:].copy()
        
        feat[feat[:,0]!=df['session'],1:] = 0
        
        columns = [f'feat_user_this_session_history_{col}' for col in ['num','correct_num']]
        
        feat = pd.DataFrame(feat[:,1:],index=df.index,columns=columns)
        
        feat[f'feat_user_this_session_history_correct_rate'] = feat[f'feat_user_this_session_history_correct_num']/feat[f'feat_user_this_session_history_num']
        
        
        return feat
    

    # @timeclass('feat_user_this_session_history_nums_and_correct_nums_and_rate')
    def update_intermediate_feat(self,table,tmp):
        result_v, = tmp
        
        df = table.last_group_model[['user_id','session','label']].copy()
        df.set_index(['user_id','session'],inplace=True)
        tmp = df.groupby(['user_id','session'])['label'].agg(['count','sum']).reset_index()
        
        change = result_v[tmp['user_id'],:].copy()
        change_index = (change[:,0] == tmp['session'].values)
        
        change[change_index,1:] += tmp.loc[change_index,['count','sum']].values
        change[~change_index,] = tmp.loc[~change_index,['session','count','sum']].values
        
        
        result_v[tmp['user_id'],:] = change
        
        
        return [result_v]
    
    
class feat_loop_group_session_corroct_rate(Feat):
    @timeclass('feat_loop_group_session_corroct_rate')
    def generate_feat(self,table):
        df = table.df_model[['user_id','session','label']].copy()
        
        user_n = df['user_id'].nunique()
        k = 5
        
        np.random.seed(seed)
        rand_group = np.random.randint(0,k,user_n)
        
        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))

        
        columns = ['feat_loop_group_session_corroct_rate']
        
        tmp_list = []
        for i in range(k):
            tmp_a = df.loc[df['group']!=i].groupby('session')['label'].agg(['mean'])
            tmp_a.columns = columns
            
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i
        
            tmp_list.append(tmp_a)
        
        tmp = pd.concat(tmp_list,axis=0)
        

        
        df = df.merge(tmp,how='left',on=['group','session'])
        df.index = table.df_model.index

        feat = df[columns]

        #测试集两种方式，5个的mean；整体的mean
        #1
        result = tmp.groupby(['session'])[columns].mean()
        
        
        return feat,[result]
    
    # @timeclass('feat_loop_group_session_corroct_rate')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        columns = ['feat_loop_group_session_corroct_rate']
        
        df_test_model = table.df_test_model[['session']].copy()
        for col in columns:
            df_test_model[col] = df_test_model['session'].map(result[col])
        
        feat = df_test_model[columns]
        
        return feat

    # @timeclass('feat_loop_group_session_corroct_rate')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    
class feat_user_this_part_history_loop_group_question_corroct_rate_mean(Feat):
    @timeclass('feat_user_history_loop_group_question_corroct_rate_mean')
    def generate_feat(self,table):
        df = table.df_model[['user_id','feat_loop_group_question_corroct_rate']].copy()
        
        df.set_index('user_id',inplace=True)
        tmp = pd.concat([df.groupby('user_id',sort=False).cumsum(),df.groupby('user_id',sort=False).cumcount()+1],axis=1)
        tmp.columns = ['user_history_loop_group_question_corroct_rate_mean','count']
        
        result = tmp.groupby('user_id',sort=False).last()
        
        tmp['user_history_loop_group_question_corroct_rate_mean'] /= tmp['count']
        
        feat = tmp[['user_history_loop_group_question_corroct_rate_mean']]
        feat.index = table.df_model.index
        
        result_val = np.zeros((500000,2))
        result_val[result.index,:] = result.values
        
        return feat,[result_val]    
    
    @timeclass('feat_user_this_part_history_question_nums_and_corroct_nums_and_rate')
    def generate_feat(self,table):
        df = table.df_model[['user_id','content_id','task_container_id','label']].copy()
        question2part = table.questions_info.set_index('question_id')['part'].astype(np.int8)
        
        df['part'] = df['content_id'].map(question2part)
        
        tmp = df.groupby(['user_id','task_container_id', 'part'],sort=False)['label'].agg(['size',sum])
        
        tmp = tmp.groupby(['user_id','part'],sort=False).cumsum()
        tmp.columns = ['feat_user_this_part_history_question_nums','feat_user_this_part_history_corroct_nums']
        
        result = tmp.groupby(['user_id','part'],sort=False).last()
        
        tmp = tmp.groupby(['user_id','part'],sort=False).shift(1).fillna(0).astype(int)
        
        
        df = df[['user_id','task_container_id']]
        df = df.merge(tmp,how='left',on=['user_id','task_container_id'])
        df.index = table.df_model.index
        
        df['feat_user_this_part_history_corroct_rate'] = df['feat_user_this_part_history_corroct_nums']/df['feat_user_this_part_history_question_nums']
        
        feat = df[['feat_user_this_part_history_question_nums','feat_user_this_part_history_corroct_nums','feat_user_this_part_history_corroct_rate']]
        
        
        result.reset_index(inplace=True)
        result.index = result['user_id'].astype(np.int64)*10+result['part']
        result.drop(columns=['user_id','part'],inplace=True)
        
        intermediate_feat = {}
        
        result_nums = result['feat_user_this_part_history_question_nums'].to_dict()
        result_corrects = result['feat_user_this_part_history_corroct_nums'].to_dict()
        
        
        # return feat,[result,intermediate_feat,question2part]
        return feat,[result_nums,result_corrects,intermediate_feat,question2part]
    
    

    
    # @timeclass('feat_user_history_loop_group_question_corroct_rate_mean')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        df = table.df_test_model[['user_id','feat_loop_group_question_corroct_rate']].copy()
        
        feat_n = df.shape[0]
        
        feat = np.zeros((feat_n,1))
        
        i = 0
        for user,corroct_rate in zip(df['user_id'],df['feat_loop_group_question_corroct_rate']):
            result[user,1] += 1
            result[user,0] += corroct_rate
            feat[i,0] = result[user,0]/result[user,1]
            
            i += 1
        
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['user_history_loop_group_question_corroct_rate_mean'])
        
        #这里result没有返回，不过也会更新的，因为直接改了内存中的值
        return feat
    
        # @timeclass('feat_user_this_part_history_question_nums_and_corroct_nums_and_rate')
    def generate_test_feat(self,table,tmp):
        # result,intermediate_feat,question2part = tmp
        result_nums,result_corrects,intermediate_feat,question2part = tmp
        
        df_test_model = table.df_test_model[['user_id','content_id']].copy()
        
        df_test_model['part'] = df_test_model['content_id'].map(question2part)
        # df_test_model['part'] = 1
        
        df_test_model = df_test_model['user_id'].astype(np.int64)*10+df_test_model['part']
        
        df_n = df_test_model.shape[0]
        
        feat = np.zeros((df_n,2),dtype=np.int16)
        
        
        for i,index in zip(range(df_n),df_test_model.values):
            # if index in result.index:
            if index in result_nums:
                feat[i,0] = result_nums[index]
                feat[i,1] = result_corrects[index]
            elif index in intermediate_feat:
                feat[i,:] = intermediate_feat[index]
                
        
        feat = pd.DataFrame(feat,index=df_test_model.index,columns=['feat_user_this_part_history_question_nums','feat_user_this_part_history_corroct_nums'])
        
        feat['feat_user_this_part_history_corroct_rate'] = feat['feat_user_this_part_history_corroct_nums']/feat['feat_user_this_part_history_question_nums']
        
        
        return feat


    # @timeclass('feat_user_history_loop_group_question_corroct_rate_mean')
    def update_intermediate_feat(self,table,tmp):
        return tmp   
    
    # @timeclass('feat_user_this_part_history_question_nums_and_corroct_nums_and_rate')
    def update_intermediate_feat(self,table,tmp):    
        # result,intermediate_feat,question2part = tmp
        result_nums,result_corrects,intermediate_feat,question2part = tmp
        
        df = table.last_group_model[['user_id','content_id','label']].copy()
        
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df['part'] = df['content_id'].map(question2part)
        # df['part'] = 1
        
        df.index = df['user_id'].astype(np.int64)*10+df['part']
        
        df = df['label']
        
        
        for i,v in zip(df.index,df.values):
            if i in result_nums:
                result_nums[i] += 1
                result_corrects[i] += v
            elif i in intermediate_feat:
                intermediate_feat[i] += np.array((1,v))
            else:
                intermediate_feat[i] = np.array((1,v))
        
        return [result_nums,result_corrects,intermediate_feat,question2part]
    

  
class feat_continue_user_this_question_history_correct_and_incorrect_nums(Feat):
    @timeclass('feat_continue_user_this_question_history_correct_and_incorrect_nums')
    def generate_feat(self,table):
        df = table.df_model[['user_id','content_id','label']].copy()
        
        df['label_equal'] = (df.groupby(['user_id','content_id'],sort=False)['label'].shift() == df['label'])
        
        df['continue_id'] = 0
        df.loc[~df['label_equal'],'continue_id'] = 1
        
        df['continue_id'] = df.groupby(['user_id','content_id'],sort=False)['continue_id'].cumsum()
        
        df['feat_continue_user_this_question_history_correct_nums'] = df.groupby(['user_id','content_id','continue_id'],sort=False).cumcount()+1
        df['feat_continue_user_this_question_history_incorrect_nums'] = 0
        
        correct_index = (df['label']==1)
        df.loc[~correct_index,'feat_continue_user_this_question_history_incorrect_nums'] = \
        df.loc[~correct_index,'feat_continue_user_this_question_history_correct_nums']
        
        df.loc[~correct_index,'feat_continue_user_this_question_history_correct_nums'] = 0
        
        columns = ['feat_continue_user_this_question_history_correct_nums','feat_continue_user_this_question_history_incorrect_nums']
        
        result = df.groupby(['user_id','content_id'],sort=False)[columns].last().astype(np.uint8).reset_index()
        result.index = result['user_id'].astype(np.int64)*20000+result['content_id']
        result.drop(columns=['user_id','content_id'],inplace=True)
        
        feat = df.groupby(['user_id','content_id'],sort=False)[columns].shift().fillna(0).astype(np.uint8)
        
        intermediate_feat = {}
        
        return feat,[result,intermediate_feat,columns]
    
    # @timeclass('feat_continue_user_this_question_history_correct_and_incorrect_nums')
    def generate_test_feat(self,table,tmp):
        result,intermediate_feat,columns = tmp
        
        df_test_model = table.df_test_model['user_id'].astype(np.int64)*20000+table.df_test_model['content_id']
        
        df_n = df_test_model.shape[0]
        
        
        feat = np.zeros((df_n,2),dtype=np.uint8)
        for i,index in zip(range(df_n),df_test_model.values):
            if index in result.index:
                feat[i,:] = result.loc[index]
            elif index in intermediate_feat:
                feat[i,:] = intermediate_feat[index]
        
        feat = pd.DataFrame(feat,index=df_test_model.index,columns=columns).astype(np.uint8)
        
        return feat

    # @timeclass('feat_continue_user_this_question_history_correct_and_incorrect_nums')
    def update_intermediate_feat(self,table,tmp):
        result,intermediate_feat,columns = tmp
        
        df = table.last_group_model[['user_id','content_id','label']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']

        df = df['label']
        
        for i,v in zip(df.index,df.values):
            if i in result.index:
                if v == 1:
                    result.loc[i,'feat_continue_user_this_question_history_correct_nums'] += 1
                    result.loc[i,'feat_continue_user_this_question_history_incorrect_nums'] = 0
                else:
                    result.loc[i,'feat_continue_user_this_question_history_correct_nums'] = 0
                    result.loc[i,'feat_continue_user_this_question_history_incorrect_nums'] += 1
            elif i in intermediate_feat:
                if v == 1:
                    intermediate_feat[i][0] += 1
                    intermediate_feat[i][1] = 0
                else:
                    intermediate_feat[i][0] = 0
                    intermediate_feat[i][1] += 1
            else:
                if v == 1:
                    intermediate_feat[i] = np.array((1,0),dtype=np.uint8)
                else:
                    intermediate_feat[i] = np.array((0,1),dtype=np.uint8)
                    
        return [result,intermediate_feat,columns]
    

class feat_session_timediff(Feat):
    @timeclass('feat_session_timediff')
    def generate_feat(self,table):
        df = table.df_model[['user_id','session','timestamp']].copy()
        
        tmp = pd.concat([\
        df.groupby(['user_id','session'],sort=False)['timestamp'].first().rename('first_time'),\
        df.groupby(['user_id','session'],sort=False)['timestamp'].last().rename('last_time'),\
            ],axis=1)
        
        tmp['last_session_last_time'] = tmp.groupby('user_id')['last_time'].shift().fillna(0).astype(int)
        
        result = tmp.reset_index().groupby('user_id',sort=False)[['session','first_time','last_time','last_session_last_time']].last()
        
        tmp['session_gap_time'] = tmp['first_time']-tmp['last_session_last_time']
        
        df = df.merge(tmp[['first_time','session_gap_time']],how='left',on=['user_id','session'])
        df['this_session_started_time_to_now'] = df['timestamp'] - df['first_time']
        
        feat = df[['session_gap_time','this_session_started_time_to_now']]
        
        result_v = np.zeros((500000,4),dtype=np.int64)
        result_v[result.index,:] = result.values
        
        return feat,[result_v]
    
    # @timeclass('feat_session_timediff')
    def generate_test_feat(self,table,tmp):
        result_v, = tmp
        
        df = table.df_test_model[['user_id','session','timestamp']].copy()
        
        df_n = df.shape[0]
        feat = np.zeros((df_n,2),dtype=np.int64)
        
        for i,user,session,timestamp in zip(range(df_n),df['user_id'],df['session'],df['timestamp']):
            row = result_v[user,:]
            if row[0] == session:
                feat[i,0] = row[1] - row[3]
                feat[i,1] = timestamp - row[1]
                result_v[user,2] = timestamp
            else:
                feat[i,0] = timestamp - row[2]
                
                row[3] = row[2]
                row[0] = session
                row[1] = timestamp
                row[2] = timestamp
                
                result_v[user,:] = row
        
        feat = pd.DataFrame(feat,index=df.index,columns=['session_gap_time','this_session_started_time_to_now'])
        
        return feat

    # @timeclass('feat_session_timediff')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    
class leak_feat_continue_user_history_correct_and_incorrect_nums(Feat):
    @timeclass('leak_feat_continue_user_history_correct_and_incorrect_nums')
    def generate_feat(self,table):
        df = table.df_model[['user_id','label']].copy()
        
        df['label_equal'] = (df.groupby('user_id',sort=False)['label'].shift() == df['label'])
        
        df['continue_id'] = 0
        df.loc[~df['label_equal'],'continue_id'] = 1
        
        df['continue_id'] = df.groupby('user_id',sort=False)['continue_id'].cumsum()
        
        df['feat_continue_user_history_correct_nums'] = df.groupby(['user_id','continue_id'],sort=False).cumcount()+1
        df['feat_continue_user_history_incorrect_nums'] = 0
        
        correct_index = (df['label']==1)
        df.loc[~correct_index,'feat_continue_user_history_incorrect_nums'] = \
        df.loc[~correct_index,'feat_continue_user_history_correct_nums']
        
        df.loc[~correct_index,'feat_continue_user_history_correct_nums'] = 0
        
        columns = ['feat_continue_user_history_correct_nums','feat_continue_user_history_incorrect_nums']
        
        result = df.groupby('user_id',sort=False)[columns].last().astype(np.int)
        result_v = np.zeros((500000,2),dtype=np.int)
        result_v[result.index,:] = result.values
        
        feat = df.groupby('user_id',sort=False)[columns].shift().fillna(0).astype(np.int)
        
        return feat,[result_v,columns]
    
    # @timeclass('leak_feat_continue_user_history_correct_and_incorrect_nums')
    def generate_test_feat(self,table,tmp):
        result_v,columns = tmp
        
        feat = result_v[table.df_test_model['user_id'],:]
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=columns).astype(np.int)
        
        return feat
    

    # @timeclass('leak_feat_continue_user_history_correct_and_incorrect_nums')
    def update_intermediate_feat(self,table,tmp):
        result_v,columns = tmp
        
        df = table.last_group_model[['user_id','label']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.set_index('user_id',inplace=True)
        df = df['label']
        
        for i,v in zip(df.index,df.values):
            if v == 1:
                result_v[i,0] += 1
                result_v[i,1] = 0
            else:
                result_v[i,0] = 0
                result_v[i,1] += 1
            
        return [result_v,columns]
    
    
class feat_continue_user_history_correct_and_incorrect_nums(Feat):
    @timeclass('feat_continue_user_history_correct_and_incorrect_nums')
    def generate_feat(self,table):
        df = table.df_model[['user_id','label']].copy()
        
        df['label_equal'] = (df.groupby('user_id',sort=False)['label'].shift() == df['label'])
        
        df['continue_id'] = 0
        df.loc[~df['label_equal'],'continue_id'] = 1
        
        df['continue_id'] = df.groupby('user_id',sort=False)['continue_id'].cumsum()
        
        df['feat_continue_user_history_correct_nums'] = df.groupby(['user_id','continue_id'],sort=False).cumcount()+1
        df['feat_continue_user_history_incorrect_nums'] = 0
        
        correct_index = (df['label']==1)
        df.loc[~correct_index,'feat_continue_user_history_incorrect_nums'] = \
        df.loc[~correct_index,'feat_continue_user_history_correct_nums']
        
        df.loc[~correct_index,'feat_continue_user_history_correct_nums'] = 0
        
        columns = ['feat_continue_user_history_correct_nums','feat_continue_user_history_incorrect_nums']
        
        result = df.groupby('user_id',sort=False)[columns].last().astype(np.int)
        result_v = np.zeros((500000,2),dtype=np.int)
        result_v[result.index,:] = result.values
        
        df['task_container_id'] = table.df_model['task_container_id']
        
        tmp = df.groupby(['user_id','task_container_id'],sort=False)[columns].last()
        tmp = tmp.groupby('user_id',sort=False).shift().fillna(0).astype(np.int)
        
        df = table.df_model[['user_id','task_container_id']].copy()
        df = df.merge(tmp,how='left',on=['user_id','task_container_id'])
        
        
        feat = df[columns]
        
        return feat,[result_v,columns]
    
    # @timeclass('feat_continue_user_history_correct_and_incorrect_nums')
    def generate_test_feat(self,table,tmp):
        result_v,columns = tmp
        
        feat = result_v[table.df_test_model['user_id'],:]
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=columns).astype(np.int)
        
        return feat
    

    # @timeclass('feat_continue_user_history_correct_and_incorrect_nums')
    def update_intermediate_feat(self,table,tmp):
        result_v,columns = tmp
        
        df = table.last_group_model[['user_id','label']].copy()
        
        if df.shape[0] == 0:
            return tmp
        
        df.set_index('user_id',inplace=True)
        df = df['label']
        
        for i,v in zip(df.index,df.values):
            if v == 1:
                result_v[i,0] += 1
                result_v[i,1] = 0
            else:
                result_v[i,0] = 0
                result_v[i,1] += 1
            
        return [result_v,columns]


class feat_this_container_question_and_lecture_nums(Feat):
    @timeclass('feat_this_container_question_and_lecture_nums')
    def generate_feat(self,table):
        df = table.df[['user_id','task_container_id','content_type_id']].copy()
        
        df = df.groupby(['user_id','task_container_id'],sort=False)['content_type_id'].agg(['count','sum']).astype(np.int)
        df['count'] -= df['sum']
        
        columns = ['this_container_question_nums','this_container_lecture_nums']
        df.columns = columns
            
        feat = table.df_model[['user_id','task_container_id']].copy()
        
        feat = feat.merge(df,how='left',on=['user_id','task_container_id'])
        feat = feat[columns]
        feat.index = table.df_model.index
        
        return feat,[columns]
    
    # @timeclass('feat_this_container_question_and_lecture_nums')
    def generate_test_feat(self,table,tmp):
        columns, = tmp
        
        df = table.df_test[['user_id','task_container_id','content_type_id']].copy()
        df['content_type_id'] = df['content_type_id'].astype(bool)
        
        df = df.groupby(['user_id','task_container_id'],sort=False)['content_type_id'].agg(['count','sum'])
        df['count'] -= df['sum']
        
        df.columns = columns
            
        feat = table.df_test_model[['user_id','task_container_id']].copy()
        
        feat = feat.merge(df,how='left',on=['user_id','task_container_id'])
        feat = feat[columns]
        feat.index = table.df_test_model.index
        
        return feat
    

    # @timeclass('feat_this_container_question_and_lecture_nums')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    

class feat_user_this_part_history_loop_group_question_corroct_rate_mean(Feat):
    @timeclass('feat_user_this_part_history_loop_group_question_corroct_rate_mean')
    def generate_feat(self,table):
        df = table.df_model[['user_id','part','feat_loop_group_question_corroct_rate']].copy()
        #编码编码编码
        df.set_index(['user_id','part'],inplace=True)
        tmp = pd.concat([df.groupby(['user_id','part'],sort=False).cumsum(),df.groupby(['user_id','part'],sort=False).cumcount()+1],axis=1)
        tmp.columns = ['user_this_part_history_loop_group_question_corroct_rate_mean','count']
        
        result = tmp.groupby(['user_id','part'],sort=False).last()
        # df.index = df['user_id']*7+df['part']
        
        tmp['user_this_part_history_loop_group_question_corroct_rate_mean'] /= tmp['count']
        
        feat = tmp[['user_this_part_history_loop_group_question_corroct_rate_mean']]
        feat.index = table.df_model.index
        
        result_val = np.zeros((500000*7,2))
        result_val[result.reset_index()['user_id']*7+result.reset_index()['part'],:] = result.values
        
        return feat,[result_val]
    
    
    # @timeclass('feat_user_this_part_history_loop_group_question_corroct_rate_mean')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        df = table.df_test_model[['user_id','part','feat_loop_group_question_corroct_rate']].copy()
        df_index = df['user_id']*7+df['part']
        feat_n = df.shape[0]
        
        feat = np.zeros((feat_n,1))
        
        i = 0
        for user,corroct_rate in zip(df_index,df['feat_loop_group_question_corroct_rate']):
            result[user,1] += 1
            result[user,0] += corroct_rate
            feat[i,0] = result[user,0]/result[user,1]
            
            i += 1
        
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['user_this_part_history_loop_group_question_corroct_rate_mean'])
        
        #这里result没有返回，不过也会更新的，因为直接改了内存中的值
        return feat

    # @timeclass('feat_user_this_part_history_loop_group_question_corroct_rate_mean')
    def update_intermediate_feat(self,table,tmp):
        return tmp       
    
    
class feat_loop_group_container_corroct_rate(Feat):
    @timeclass('feat_loop_group_container_corroct_rate')
    def generate_feat(self,table):
        df = table.df_model[['user_id','task_container_id','label']].copy()
        
        user_n = df['user_id'].nunique()
        k = 5
        
        np.random.seed(seed)
        rand_group = np.random.randint(0,k,user_n)
        
        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))

        
        columns = ['feat_loop_group_container_corroct_rate']
        
        tmp_list = []
        for i in range(k):
            tmp_a = df.loc[df['group']!=i].groupby('task_container_id')['label'].agg(['mean'])
            tmp_a.columns = columns
            
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i
        
            tmp_list.append(tmp_a)
        
        tmp = pd.concat(tmp_list,axis=0)
        

        
        df = df.merge(tmp,how='left',on=['group','task_container_id'])
        df.index = table.df_model.index

        feat = df[columns]

        #测试集两种方式，5个的mean；整体的mean
        #1
        result = tmp.groupby(['task_container_id'])[columns].mean()
        
        
        return feat,[result]
    
    # @timeclass('feat_loop_group_container_corroct_rate')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        columns = ['feat_loop_group_container_corroct_rate']
        
        df_test_model = table.df_test_model[['task_container_id']].copy()
        for col in columns:
            df_test_model[col] = df_test_model['task_container_id'].map(result[col])
        
        feat = df_test_model[columns]
        
        return feat

    # @timeclass('feat_loop_group_container_corroct_rate')
    def update_intermediate_feat(self,table,tmp):
        return tmp


class feat_user_history_rolling_k_question_loop_group_question_corroct_rate_mean(Feat):
    #这里说一下，一个task_container里可能有多个question，而且是同一batch给出，所以必须只能统计本task_container之前的值
    @timeclass('feat_user_history_rolling_k_question_loop_group_question_corroct_rate_mean')
    def generate_feat(self,table):
        data_type = np.float32
        k_list = [3,6,9]
        max_k = np.max(k_list)
        df = table.df_model[['user_id','feat_loop_group_question_corroct_rate']].copy()
        
        
        result = df.groupby('user_id',sort=False).tail(max_k)
        result['num'] = result.groupby('user_id',sort=False).cumcount()+1
        
        result['num_sum'] = result['user_id'].map(result.groupby('user_id').size())
        result['num_sum'] = max_k-result['num_sum']
        result['num'] += result['num_sum']
        result['feat_loop_group_question_corroct_rate'] = result['feat_loop_group_question_corroct_rate'].astype(data_type)
        
        result = pd.pivot_table(result,index='user_id',columns='num',values='feat_loop_group_question_corroct_rate')
        
        result_val = np.zeros((500000,max_k),dtype=data_type)*np.nan
        result_val[result.index,:] = result.values
        
        df = df.set_index('user_id')['feat_loop_group_question_corroct_rate']
        
        tmp_list = []
        for k in k_list:
            print(f'feat rolling {k}')
            tmp = df.groupby('user_id',sort=False).rolling(window=k,min_periods=1).mean()
                
            tmp.reset_index(drop=True,inplace=True)
            tmp.rename(f'feat_user_history_rolling_{k}_question_loop_group_question_corroct_rate_mean',inplace=True)
            
            tmp_list.append(tmp)
        
        tmp = pd.concat(tmp_list,axis=1)
        tmp.index = table.df_model.index
        
        return tmp,[k_list,result_val,data_type,tmp.columns]
    
    # @timeclass('feat_user_history_rolling_k_question_loop_group_question_corroct_rate_mean')
    def generate_test_feat(self,table,tmp):
        k_list,result_val,data_type,columns = tmp
        
        df = table.df_test_model[['user_id']].copy()
        
        df_n = df.shape[0]
        
        feat = np.zeros((df_n,len(k_list)),dtype=data_type)
        
        for k,i in zip(k_list,range(len(k_list))):
            feat[:,i] = np.nanmean(result_val[df['user_id'],-k:],axis=1)
        
        feat = pd.DataFrame(feat,index=df.index,columns=columns)
        
        return feat

    # @timeclass('feat_user_history_rolling_k_question_loop_group_question_corroct_rate_mean')
    def update_intermediate_feat(self,table,tmp):
        
        k_list,result_val,data_type,columns = tmp
        
        df = table.last_group_model[['user_id','feat_loop_group_question_corroct_rate']].copy()
        
        for user,corroct_rate in zip(df['user_id'],df['feat_loop_group_question_corroct_rate']):
            result_val[user,:-1] = result_val[user,1:]
            result_val[user,-1] = corroct_rate
        
        return [k_list,result_val,data_type,columns]
    
    
class feat_this_question_last_lecture_num_and_rate(Feat):
    @timeclass('feat_this_question_last_lecture_num_and_rate')
    def generate_feat(self, table):
        N = 3
        columns = [f'last_{i + 1}_lecture_id' for i in range(N)]
        df = table.df_model.copy()
        df = df[columns + ['content_id']]
        for column in columns:
            df.loc[~df[column].isna(), column] = 1
            df[column] = df[column].fillna(0)
        last1 = df.groupby(['content_id'], sort=False)[columns[0]].agg(['size', sum])
        last1.columns = ['qustion_num1', 'last1_lecture_num']
        last1['question_last1_lecture_rate'] = last1['last1_lecture_num'] / last1['qustion_num1']

        last2 = df.groupby(['content_id'], sort=False)[columns[1]].agg(['size', sum])
        last2.columns = ['qustion_num2', 'last2_lecture_num']
        last2['question_last2_lecture_rate'] = last2['last2_lecture_num'] / last2['qustion_num2']

        last3 = df.groupby(['content_id'], sort=False)[columns[2]].agg(['size', sum])
        last3.columns = ['qustion_num3', 'last3_lecture_num']
        last3['question_last3_lecture_rate'] = last3['last3_lecture_num'] / last3['qustion_num3']

        df = table.df_model[['content_id']].copy()
        df = df.merge(last1, how='left', on='content_id')
        df = df.merge(last2, how='left', on='content_id')
        df = df.merge(last3, how='left', on='content_id')
        df.index = table.df_model.index
        feat = df[['last1_lecture_num', 'last2_lecture_num', 'last3_lecture_num', 'question_last1_lecture_rate', 'question_last2_lecture_rate', 'question_last3_lecture_rate']]

        last1_lecture_num = defaultdict(int)
        question_last1_lecture_rate = defaultdict(int)
        last2_lecture_num = defaultdict(int)
        question_last2_lecture_rate = defaultdict(int)
        last3_lecture_num = defaultdict(int)
        question_last3_lecture_rate = defaultdict(int)

        last1_lecture_num.update(last1['last1_lecture_num'])
        question_last1_lecture_rate.update(last1['question_last1_lecture_rate'])
        last2_lecture_num.update(last2['last2_lecture_num'])
        question_last2_lecture_rate.update(last2['question_last2_lecture_rate'])
        last3_lecture_num.update(last3['last3_lecture_num'])
        question_last3_lecture_rate.update(last3['question_last3_lecture_rate'])
        return feat, [last1_lecture_num, question_last1_lecture_rate, last2_lecture_num, question_last2_lecture_rate, last3_lecture_num, question_last3_lecture_rate]

    def generate_test_feat(self, table, tmp):
        last1_lecture_num, question_last1_lecture_rate, last2_lecture_num, question_last2_lecture_rate, last3_lecture_num, question_last3_lecture_rate = tmp
        N = 3
        df = table.df_test_model[['content_id']].copy()
        df['last1_lecture_num'] = df['content_id'].map(last1_lecture_num)
        df['question_last1_lecture_rate'] = df['content_id'].map(question_last1_lecture_rate)
        df['last2_lecture_num'] = df['content_id'].map(last2_lecture_num)
        df['question_last2_lecture_rate'] = df['content_id'].map(question_last2_lecture_rate)
        df['last3_lecture_num'] = df['content_id'].map(last3_lecture_num)
        df['question_last3_lecture_rate'] = df['content_id'].map(question_last3_lecture_rate)
        feat = df[['last1_lecture_num', 'last2_lecture_num', 'last3_lecture_num', 'question_last1_lecture_rate', 'question_last2_lecture_rate', 'question_last3_lecture_rate']]
        feat.index = table.df_test_model.index
        return feat

    def update_intermediate_feat(self, table, tmp):
        return tmp
    
    
class feat_loop_group_qustionid_last1_lecture_id_corroct_rate(Feat):
    @timeclass('feat_loop_group_qustionid_last1_lecture_id_corroct_rate')
    def generate_feat(self, table):
        df = table.df_model[['user_id','content_id', 'last_1_lecture_id', 'label']].copy()
        # table.lectures_info['lecture_id'].nunique() == 418
        df['last_1_lecture_id'] = df['last_1_lecture_id'].fillna(418)
        
        user_n = df['user_id'].nunique()
        k = 5
        threshold = 10
        smoothly_n = 0
        
        np.random.seed(seed)
        rand_group = np.random.randint(0, k, user_n)

        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))

        columns = ['feat_loop_group_qustionid_last1_lecture_id_corroct_rate','feat_loop_group_qustionid_last1_lecture_id_count']
        tmp_list = []
        for i in range(k):
            tmp_a = df.loc[df['group'] != i].groupby(['content_id', 'last_1_lecture_id'],sort=False)['label'].agg(['sum','count'])
            tmp_a = tmp_a[tmp_a['count']>=threshold]
            tmp_a.columns = columns
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i

            tmp_list.append(tmp_a)

        tmp = pd.concat(tmp_list, axis=0)
        tmp['feat_loop_group_qustionid_last1_lecture_id_corroct_rate'] /= (tmp['feat_loop_group_qustionid_last1_lecture_id_count']+smoothly_n)
        
        df = df.merge(tmp, how='left', on=['group','content_id', 'last_1_lecture_id'])
        
        df.index = table.df_model.index

        feat = df[columns]

        # 测试集两种方式，5个的mean；整体的mean
        # 1
        # result = tmp.groupby(['content_id','last_1_lecture_id'])[columns].mean()
        result = tmp.groupby(['content_id','last_1_lecture_id']).agg({columns[0]:'mean',columns[1]:'sum'})
        
        result = result.reset_index()
        
        result.index = (result['content_id']*419+result['last_1_lecture_id']).astype(int)
        result = result[columns]
        
        result_val = np.zeros((table.questions_info.shape[0]*(table.lectures_info.shape[0]+1),2))*np.nan
        result_val[result.index,:] = result.values
        

        return feat, [result_val,columns]

    # @timeclass('feat_loop_group_bundle_id_corroct_rate')
    def generate_test_feat(self, table, tmp):
        result_val,columns = tmp
        df = table.df_test_model[['content_id','last_1_lecture_id']].copy()
        df['last_1_lecture_id'] = df['last_1_lecture_id'].fillna(418)
 
        df['key'] = (df['content_id']*419+df['last_1_lecture_id']).astype(int)
        
        feat = result_val[df['key'],:]
        
        feat = pd.DataFrame(feat,index=df.index,columns=columns)
        
        return feat

    # @timeclass('feat_loop_group_bundle_id_corroct_rate')
    def update_intermediate_feat(self, table, tmp):
        return tmp
    

class feat_loop_group_qustionid_last1_lecture_tag_corroct_rate(Feat):
    @timeclass('feat_loop_group_qustionid_last1_lecture_tag_corroct_rate')
    def generate_feat(self, table):
        df = table.df_model[['user_id','content_id', 'last_1_lecture_id', 'label']].copy()
        lecture2tag = table.lectures_info.set_index('lecture_id')['tag']
        
        cats_nums = table.lectures_info['tag'].nunique()
        
        df["last_1_lecture_tag"] = df['last_1_lecture_id'].map(lecture2tag)
        df["last_1_lecture_tag"] = df["last_1_lecture_tag"].fillna(cats_nums)
        
        user_n = df['user_id'].nunique()
        k = 5
        
        np.random.seed(seed)
        rand_group = np.random.randint(0, k, user_n)

        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))

        columns = ['feat_loop_group_qustionid_last1_lecture_tag_corroct_rate','feat_loop_group_qustionid_last1_lecture_tag_count']
        tmp_list = []
        for i in range(k):
            tmp_a = df.loc[df['group'] != i].groupby(['content_id', 'last_1_lecture_tag'],sort=False)['label'].agg(['sum','count'])
            tmp_a.columns = columns
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i

            tmp_list.append(tmp_a)

        tmp = pd.concat(tmp_list, axis=0)
        tmp[columns[0]] /= (tmp[columns[1]]+20)
        
        df = df.merge(tmp, how='left', on=['group','content_id', 'last_1_lecture_tag'])
        
        df.index = table.df_model.index

        feat = df[columns]
        # feat = df[columns+['last_1_lecture_tag']]

        # 测试集两种方式，5个的mean；整体的mean
        # 1
        result = tmp.groupby(['content_id','last_1_lecture_tag']).agg({columns[0]:'mean',columns[1]:'sum'})
        
        result = result.reset_index()
        
        result.index = (result['content_id']*(cats_nums+1)+result['last_1_lecture_tag']).astype(int)
        result = result[columns]
        
        result_val = np.zeros((table.questions_info.shape[0]*(cats_nums+1),2))*np.nan
        result_val[result.index,:] = result.values
        

        return feat, [result_val,columns,lecture2tag,cats_nums]

    # @timeclass('feat_loop_group_qustionid_last1_lecture_tag_corroct_rate')
    def generate_test_feat(self, table, tmp):
        result_val,columns,lecture2tag,cats_nums = tmp
        df = table.df_test_model[['content_id','last_1_lecture_id']].copy()
        df['last_1_lecture_tag'] = df['last_1_lecture_id'].map(lecture2tag)
        df['last_1_lecture_tag'] = df['last_1_lecture_tag'].fillna(cats_nums)
 
        df['key'] = (df['content_id']*(cats_nums+1)+df['last_1_lecture_tag']).astype(int)
        
        feat = result_val[df['key'],:]
        
        feat = pd.DataFrame(feat,index=df.index,columns=columns)
        # feat = pd.concat([feat,df['last_1_lecture_tag']],axis=1)
        
        return feat

    # @timeclass('feat_loop_group_qustionid_last1_lecture_tag_corroct_rate')
    def update_intermediate_feat(self, table, tmp):
        return tmp
    
class feat_loop_group_qustionid_last1_lecture_part_corroct_rate(Feat):
    @timeclass('feat_loop_group_qustionid_last1_lecture_part_corroct_rate')
    def generate_feat(self, table):
        df = table.df_model[['user_id','content_id', 'last_1_lecture_id', 'label']].copy()
        lecture2part = table.lectures_info.set_index('lecture_id')['part']
        
        cats_nums = table.lectures_info['part'].nunique()
        
        df["last_1_lecture_part"] = df['last_1_lecture_id'].map(lecture2part)
        df["last_1_lecture_part"] = df["last_1_lecture_part"].fillna(cats_nums)
        
        user_n = df['user_id'].nunique()
        k = 5
        
        np.random.seed(seed)
        rand_group = np.random.randint(0, k, user_n)

        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))

        columns = ['feat_loop_group_qustionid_last1_lecture_part_corroct_rate','feat_loop_group_qustionid_last1_lecture_part_count']
        tmp_list = []
        for i in range(k):
            tmp_a = df.loc[df['group'] != i].groupby(['content_id', 'last_1_lecture_part'],sort=False)['label'].agg(['sum','count'])
            tmp_a.columns = columns
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i

            tmp_list.append(tmp_a)

        tmp = pd.concat(tmp_list, axis=0)
        tmp[columns[0]] /= (tmp[columns[1]]+20)
        
        df = df.merge(tmp, how='left', on=['group','content_id', 'last_1_lecture_part'])
        
        df.index = table.df_model.index

        feat = df[columns]
        # feat = df[columns+['last_1_lecture_tag']]

        # 测试集两种方式，5个的mean；整体的mean
        # 1
        result = tmp.groupby(['content_id','last_1_lecture_part']).agg({columns[0]:'mean',columns[1]:'sum'})
        
        result = result.reset_index()
        
        result.index = (result['content_id']*(cats_nums+1)+result['last_1_lecture_part']).astype(int)
        result = result[columns]
        
        result_val = np.zeros((table.questions_info.shape[0]*(cats_nums+1),2))*np.nan
        result_val[result.index,:] = result.values
        

        return feat, [result_val,columns,lecture2part,cats_nums]

    # @timeclass('feat_loop_group_qustionid_last1_lecture_part_corroct_rate')
    def generate_test_feat(self, table, tmp):
        result_val,columns,lecture2part,cats_nums = tmp
        df = table.df_test_model[['content_id','last_1_lecture_id']].copy()
        df['last_1_lecture_part'] = df['last_1_lecture_id'].map(lecture2part)
        df['last_1_lecture_part'] = df['last_1_lecture_part'].fillna(cats_nums)
 
        df['key'] = (df['content_id']*(cats_nums+1)+df['last_1_lecture_part']).astype(int)
        
        feat = result_val[df['key'],:]
        
        feat = pd.DataFrame(feat,index=df.index,columns=columns)
        # feat = pd.concat([feat,df['last_1_lecture_tag']],axis=1)
        
        return feat

    # @timeclass('feat_loop_group_qustionid_last1_lecture_part_corroct_rate')
    def update_intermediate_feat(self, table, tmp):
        return tmp
    
class feat_loop_group_qustionid_last1_lecture_type_corroct_rate(Feat):
    @timeclass('feat_loop_group_qustionid_last1_lecture_type_corroct_rate')
    def generate_feat(self, table):
        df = table.df_model[['user_id','content_id', 'last_1_lecture_id', 'label']].copy()
        lecture2type = table.lectures_info.set_index('lecture_id')['type_of']
        
        cats_nums = table.lectures_info['type_of'].nunique()
        
        df["last_1_lecture_type"] = df['last_1_lecture_id'].map(lecture2type)
        df["last_1_lecture_type"] = df["last_1_lecture_type"].fillna(cats_nums)
        
        user_n = df['user_id'].nunique()
        k = 5
        
        np.random.seed(seed)
        rand_group = np.random.randint(0, k, user_n)

        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))

        columns = ['feat_loop_group_qustionid_last1_lecture_type_corroct_rate','feat_loop_group_qustionid_last1_lecture_type_count']
        tmp_list = []
        for i in range(k):
            tmp_a = df.loc[df['group'] != i].groupby(['content_id', 'last_1_lecture_type'],sort=False)['label'].agg(['sum','count'])
            tmp_a.columns = columns
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i

            tmp_list.append(tmp_a)

        tmp = pd.concat(tmp_list, axis=0)
        tmp[columns[0]] /= (tmp[columns[1]]+20)
        
        df = df.merge(tmp, how='left', on=['group','content_id', 'last_1_lecture_type'])
        
        df.index = table.df_model.index

        feat = df[columns]
        # feat = df[columns+['last_1_lecture_tag']]

        # 测试集两种方式，5个的mean；整体的mean
        # 1
        result = tmp.groupby(['content_id','last_1_lecture_type']).agg({columns[0]:'mean',columns[1]:'sum'})
        
        result = result.reset_index()
        
        result.index = (result['content_id']*(cats_nums+1)+result['last_1_lecture_type']).astype(int)
        result = result[columns]
        
        result_val = np.zeros((table.questions_info.shape[0]*(cats_nums+1),2))*np.nan
        result_val[result.index,:] = result.values
        

        return feat, [result_val,columns,lecture2type,cats_nums]

    # @timeclass('feat_loop_group_qustionid_last1_lecture_type_corroct_rate')
    def generate_test_feat(self, table, tmp):
        result_val,columns,lecture2type,cats_nums = tmp
        df = table.df_test_model[['content_id','last_1_lecture_id']].copy()
        df['last_1_lecture_type'] = df['last_1_lecture_id'].map(lecture2type)
        df['last_1_lecture_type'] = df['last_1_lecture_type'].fillna(cats_nums)
 
        df['key'] = (df['content_id']*(cats_nums+1)+df['last_1_lecture_type']).astype(int)
        
        feat = result_val[df['key'],:]
        
        feat = pd.DataFrame(feat,index=df.index,columns=columns)
        # feat = pd.concat([feat,df['last_1_lecture_tag']],axis=1)
        
        return feat

    # @timeclass('feat_loop_group_qustionid_last1_lecture_type_corroct_rate')
    def update_intermediate_feat(self, table, tmp):
        return tmp
    
    
   

class feat_new_container_id(Feat):
    @timeclass('feat_new_container_id')
    def generate_feat(self,table):
        df = table.df[['user_id','timestamp','task_container_id']].copy()
        tmp = df.groupby(['user_id','timestamp'],sort=False).first()
        tmp = tmp.groupby('user_id',sort=False).cumcount()
        tmp.rename('new_container_id',inplace=True)
        
        df = table.df_model[['user_id','timestamp']]
        df = df.merge(tmp,how='left',on=['user_id','timestamp'])
        
        feat = df[['new_container_id']]
        feat.index = table.df_model.index
        
        
        result = tmp.reset_index().groupby('user_id',sort=False)[['new_container_id']].last()
        result += 1
        
        result_val = np.zeros((500000,1),dtype=np.int)
        result_val[result.index,:] = result.values
        
        return feat,[result_val]
    
    
    # @timeclass('feat_new_container_id')
    def generate_test_feat(self,table,tmp):
        result_val, = tmp
        
        feat = result_val[table.df_test_model['user_id'],:]
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['new_container_id'])
        
        return feat

    # @timeclass('feat_new_container_id')
    def update_intermediate_feat(self,table,tmp):
        result_val, = tmp
        df = table.last_group['user_id'].unique()
        result_val[df,:] += 1
        
        return [result_val]      
    
# class feat_user_this_question_time_interval(Feat):
#     @timeclass('feat_user_this_question_time_interval')
#     def generate_feat(self, table):
#         df = table.df_model[['user_id','content_id','task_container_id','timestamp']].copy()
        
#         tmp = df.groupby(['user_id', 'task_container_id', 'content_id'], sort=False)['timestamp'].first()
        
        
#         result = tmp.groupby(['user_id', 'content_id'], sort=False).last()
#         last_question_timestamp = defaultdict(int)
#         last_question_timestamp.update(result)    
        
#         # pdb.set_trace()
        
#         tmp -= tmp.groupby(['user_id', 'content_id'], sort=False).shift(1).fillna(0)
        
#         del(df['timestamp'])
        
#         df= df.merge(tmp, how='left', on=['user_id', 'task_container_id', 'content_id'])
#         df = df.rename(columns={'timestamp':'diff_timestamp_of_last_question'})
        
#         feat = df[['diff_timestamp_of_last_question']]
        
#         return feat, [last_question_timestamp,]
    
#     def generate_test_feat(self,table,tmp):
#         last_question_timestamp, = tmp
        
#         df = table.df_test_model[['user_id','content_id','timestamp']].copy()
        
       
        
#         df = df.reset_index()
#         df = df.set_index(['user_id', 'content_id'])
#         df['diff_timestamp_of_last_question'] = df['timestamp']-df.index.map(last_question_timestamp)
#         df = df.reset_index()
#         df.index = table.df_test_model.index
        
#         feat = df[['diff_timestamp_of_last_question']]
        
        
#         return feat
    
#     def update_intermediate_feat(self,table,tmp):
#         last_question_timestamp, = tmp
#         df = table.last_group[['user_id', 'content_id', 'timestamp']].copy()
#         tmp1 = df.groupby(['user_id', 'content_id'], sort=False)['timestamp'].first()
        
#         tmp1_val = tmp1.values
#         i = 0
#         # pdb.set_trace()
#         for idx in tmp1.index:
#             last_question_timestamp[idx] = tmp1_val[i] 
#             i += 1
#         return tmp
    
    
class feat_coec(Feat):
    @timeclass('feat_coec')
    def generate_feat(self,table):
        df = table.df_model[['label','feat_user_this_question_history_nums','content_id']].copy()
        
        max_num = 4
        df = df[df['feat_user_this_question_history_nums']<=max_num]
        
        
        tmp = df.groupby(['feat_user_this_question_history_nums'])['label'].mean()
        tmp2 = df.groupby('content_id')['feat_user_this_question_history_nums'].value_counts()
        tmp2.name = 'count'
        
        tmp2 = tmp2.reset_index()
        tmp2['acc_rate'] = tmp2['feat_user_this_question_history_nums'].map(tmp)
        tmp2['coec'] = tmp2['count']*tmp2['acc_rate']
        result = tmp2.groupby('content_id')['coec'].sum()
        
        result = df.groupby('content_id')['label'].sum()/result
        
        
        df = table.df_model[['content_id']].copy()
        df['feat_coec'] = df['content_id'].map(result)
        
        feat = df[['feat_coec']]
        
        return feat,[result]
    
    
    # @timeclass('feat_new_container_id')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        
        df = table.df_test_model[['content_id']].copy()
        df['feat_coec'] = df['content_id'].map(result)
        
        feat = df[['feat_coec']]
        
        return feat

    # @timeclass('feat_new_container_id')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
class feat_user_coec(Feat):
    @timeclass('feat_coec')
    def generate_feat(self,table):
        df = table.df_model[['label','feat_user_history_question_nums','content_id']].copy()
        
        df['question_nums_bins'],bins = pd.qcut(df['feat_user_history_question_nums'],10,labels=range(10),retbins=True)
        df['question_nums_bins'] = df['question_nums_bins'].astype(np.int8)
        
        tmp = df.groupby(['question_nums_bins'])['label'].mean()
        tmp2 = df.groupby('content_id')['question_nums_bins'].value_counts()
        tmp2.name = 'count'
        
        tmp2 = tmp2.reset_index()
        tmp2['acc_rate'] = tmp2['question_nums_bins'].map(tmp)
        tmp2['coec'] = tmp2['count']*tmp2['acc_rate']
        result = tmp2.groupby('content_id')['coec'].sum()
        
        result = df.groupby('content_id')['label'].sum()/result
        
        df = table.df_model[['content_id']].copy()
        df['feat_user_coec'] = df['content_id'].map(result)
        
        feat = df[['feat_user_coec']]
        
        return feat,[result]
    
    
    # @timeclass('feat_new_container_id')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        
        df = table.df_test_model[['content_id']].copy()
        df['feat_user_coec'] = df['content_id'].map(result)
        
        feat = df[['feat_user_coec']]
        
        return feat

    # @timeclass('feat_new_container_id')
    def update_intermediate_feat(self,table,tmp):
        return tmp    
    
    
# class feat_user_this_question_time_interval(Feat):
#     @timeclass('feat_user_this_question_time_interval')
#     def generate_feat(self, table):
#         df = table.df_model[['user_id','content_id','task_container_id','timestamp']].copy()
        
#         tmp = df.groupby(['user_id', 'task_container_id', 'content_id'], sort=False)['timestamp'].first()
        
        
#         result = tmp.groupby(['user_id', 'content_id'], sort=False).last().astype(np.uint64).reset_index()
#         result.index = result['user_id'].astype(np.int64)*20000+result['content_id']
#         result.drop(columns=['user_id','content_id'],inplace=True)
  
        
#         tmp -= tmp.groupby(['user_id', 'content_id'], sort=False).shift(1)
        
#         del(df['timestamp'])
        
#         df= df.merge(tmp, how='left', on=['user_id', 'task_container_id', 'content_id'])
#         df = df.rename(columns={'timestamp':'diff_timestamp_of_last_question'})
        
#         feat = df[['diff_timestamp_of_last_question']]
    
#         intermediate_feat = {}
#         pdb.set_trace()
#         return feat, [result,intermediate_feat,]
    
#     def generate_test_feat(self,table,tmp):
#         result, intermediate_feat = tmp
#         df = table.df_test_model[['user_id', 'content_id', 'timestamp']].copy()
#         df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
#         df.drop(columns=['user_id','content_id'],inplace=True)
        
#         df_val = df.values
        
#         df_n = df.shape[0]
        
#         feat = np.zeros((df_n))
        
#         for i,idx in zip(range(df_n),df.index):
#             if idx in result.index:
#                 feat[i] = df_val[i]-result.loc[idx]
#             elif idx in intermediate_feat:
#                 feat[i] = df_val[i]-intermediate_feat[idx]
#             else:
#                 feat[i] = np.nan
        
                
#         feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['diff_timestamp_of_last_question'])
        
#         return feat
    
#     def update_intermediate_feat(self,table,tmp):
#         result,intermediate_feat = tmp
        
#         df = table.last_group_model[['user_id','content_id', 'timestamp']].copy()
        
#         df_n = df.shape[0]
        
#         if df_n == 0:
#             return tmp
        
#         df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
#         df.drop(columns=['user_id','content_id'],inplace=True)
        
#         df_val = df.values
        
#         for i, idx in zip(range(df_n), df.index):
#             if idx in result.index:
#                 result.loc[idx] = df_val[i]
#             else:
#                 intermediate_feat[idx] = df_val[i]
        
#         return [result,intermediate_feat]


 
class feat_user_this_question_time_interval(Feat):
    @timeclass('feat_user_this_question_time_interval')
    def generate_feat(self, table):
        df = table.df_model[['user_id','content_id','timestamp']].copy()
        
        result = df.groupby(['user_id', 'content_id'], sort=False).last().astype(np.uint64).reset_index()
        result.index = result['user_id'].astype(np.int64)*20000+result['content_id']
        result.drop(columns=['user_id','content_id'],inplace=True)
  
        
        df['timestamp'] -= df.groupby(['user_id', 'content_id'], sort=False)['timestamp'].shift(1)
        
        df = df.rename(columns={'timestamp':'diff_timestamp_of_last_question'})
        
        feat = df[['diff_timestamp_of_last_question']]
    
        intermediate_feat = {}
        return feat, [result,intermediate_feat,]
    
    def generate_test_feat(self,table,tmp):
        result, intermediate_feat = tmp
        df = table.df_test_model[['user_id', 'content_id', 'timestamp']].copy()
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        df_n = df.shape[0]
        
        feat = np.zeros((df_n,1))
        
        for i,idx,v in zip(range(df_n),df.index,df['timestamp']):
            if idx in result.index:
                feat[i,0] = v-result.loc[idx]
            elif idx in intermediate_feat:
                feat[i,0] = v-intermediate_feat[idx]
            else:
                feat[i,0] = np.nan
        
                
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['diff_timestamp_of_last_question'])
        
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        result,intermediate_feat = tmp
        df = table.last_group_model[['user_id','content_id', 'timestamp']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        df.drop(columns=['user_id','content_id'],inplace=True)
        
        for i, idx, v in zip(range(df_n), df.index, df['timestamp']):
            if idx in result.index:
                result.loc[idx] = v
            else:
                intermediate_feat[idx] = v
        
        return [result,intermediate_feat]


class feat_user_this_question_history_nums_and_correct_nums_and_rate_join_time_interval(Feat):
    @timeclass('feat_user_this_question_history_nums_and_correct_nums_and_rate_join_time_interval')
    def generate_feat(self,table):
        df = table.df_model[['user_id','content_id','timestamp']].copy()
        
        result = df.groupby(['user_id', 'content_id'], sort=False).last().astype(np.uint64).reset_index()
        result.index = result['user_id'].astype(np.int64)*20000+result['content_id']
        result.drop(columns=['user_id','content_id'],inplace=True)
  
        
        df['timestamp'] -= df.groupby(['user_id', 'content_id'], sort=False)['timestamp'].shift(1)
        
        df = df.rename(columns={'timestamp':'diff_timestamp_of_last_question'})
        
        df.index = table.df_model.index
        feat = df[['diff_timestamp_of_last_question']]
        
        
        ################# 分割线 #################
        
        df2 = table.df_model[['user_id','content_id','label']].copy()
        df2 = df2.set_index(['user_id','content_id'])
        
        tmp = df2.groupby(['user_id','content_id'],sort=False)['label'].agg(['cumcount','cumsum'])

        tmp['cumcount'] += 1
        
        tmp.columns = ['feat_user_this_question_history_nums','feat_user_this_question_history_correct_nums']
        
        result2 = tmp.groupby(['user_id','content_id'],sort=False).last().astype(np.uint8).reset_index()
        result2.index = result2['user_id'].astype(np.int64)*20000+result2['content_id']
        result2.drop(columns=['user_id','content_id'],inplace=True)
        
        tmp = tmp.groupby(['user_id','content_id'],sort=False).shift(1).fillna(0).astype(np.uint8)
        tmp['feat_user_this_question_history_correct_rate'] = tmp['feat_user_this_question_history_correct_nums']/tmp['feat_user_this_question_history_nums']
        tmp.index = table.df_model.index
        
        
        #结合两者
        feat = pd.concat([feat,tmp],axis=1)
        result = pd.concat([result,result2],axis=1)
        
        intermediate_feat = {}
        
        return feat,[result,intermediate_feat]
    
    

    # @timeclass('feat_user_this_question_history_nums_and_correct_nums_and_rate_join_time_interval')
    def generate_test_feat(self,table,tmp):
        result, intermediate_feat = tmp
        df = table.df_test_model[['user_id', 'content_id', 'timestamp']].copy()
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        df_n = df.shape[0]
        
        feat = np.zeros((df_n,3),np.float64)
        
        for i,idx,v in zip(range(df_n),df.index,df['timestamp']):
            if idx in result.index:
                feat[i,:] = result.loc[idx]
                feat[i,0] = v-feat[i,0]
            elif idx in intermediate_feat:
                feat[i,:] = intermediate_feat[idx]
                feat[i,0] = v-feat[i,0]
            else:
                feat[i,0] = np.nan
        
                
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['diff_timestamp_of_last_question','feat_user_this_question_history_nums','feat_user_this_question_history_correct_nums'])
        feat['feat_user_this_question_history_nums'] = feat['feat_user_this_question_history_nums'].astype(np.uint8)
        feat['feat_user_this_question_history_correct_nums'] = feat['feat_user_this_question_history_correct_nums'].astype(np.uint8)
        
        feat['feat_user_this_question_history_correct_rate'] = feat['feat_user_this_question_history_correct_nums']/feat['feat_user_this_question_history_nums']
        
        return feat
    
    # @timeclass('feat_user_this_question_history_nums_and_correct_nums_and_rate_join_time_interval')
    def update_intermediate_feat(self,table,tmp):
        result,intermediate_feat = tmp
        df = table.last_group_model[['user_id','content_id','timestamp','label']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        # pdb.set_trace()
        
        for i, idx, time_v, label_v in zip(range(df_n), df.index, df['timestamp'], df['label']):
            if idx in result.index:
                result.loc[idx] += np.array([0,1,label_v],dtype=np.uint8)
                result.loc[idx,'timestamp'] = time_v
            elif idx in intermediate_feat:
                intermediate_feat[idx] += np.array(([0,1,label_v]), dtype=np.int64)
                intermediate_feat[idx][0] = time_v
            else:
                intermediate_feat[idx] = np.array(([time_v,1,label_v]), dtype=np.int64)
                
        return [result,intermediate_feat]
    


class feat_time_interval_of_the_second_question(Feat):
    @timeclass('feat_time_interval_of_the_second_question')
    def generate_feat(self,table):
        df = table.df.copy()
        
        df = df.loc[~df['content_type_id'],['user_id','task_container_id','timestamp']]
        
        tmp = df.groupby(['user_id','task_container_id'],sort=False).first()
     
        last_2_container_timestamp = defaultdict(list)
        
        tmp1 = tmp.groupby('user_id',sort=False).tail(2)
        
        tmp1 = tmp1.groupby('user_id', sort=False).agg(list)
        
        last_2_container_timestamp.update(tmp1['timestamp'])
        
        # pdb.set_trace()
        tmp -= tmp.groupby('user_id', sort=False).shift(2).fillna(0)
        
        tmp.columns = ['time_interval_of_the_second_question']
        
        df = table.df_model[['user_id','task_container_id']].copy()
        
        df = df.merge(tmp, how='left',on=['user_id', 'task_container_id'])
        
        feat = df[['time_interval_of_the_second_question']]
        
        return feat,[last_2_container_timestamp]
        
    # @timeclass('feat_time_interval_of_the_last_question')
    def generate_test_feat(self,table,tmp):
        last_2_container_timestamp, = tmp
        df_test_model = table.df_test_model[['user_id','timestamp']].copy()
        
        tmp1 = df_test_model.groupby(['user_id'], sort=False).agg('first')
        tmp1.columns = ['timestamp_first']
        tmp1['time_interval_of_the_second_question'] = 0
        for user in tmp1.index:
            if( user in last_2_container_timestamp ):
                if( len(last_2_container_timestamp[user]) > 1 ):
                    tmp1.loc[user, 'time_interval_of_the_second_question'] = tmp1.loc[user,'timestamp_first']-last_2_container_timestamp[user][-2]
                    
        df_test_model = df_test_model.reset_index()
        df_test_model = df_test_model.merge(tmp1, how='left', on='user_id')
        df_test_model = df_test_model.set_index(['index'], drop=True)
        
        feat = df_test_model[['time_interval_of_the_second_question']]
        
        return feat
    
    
    # @timeclass('feat_time_interval_of_the_last_question')
    def update_intermediate_feat(self,table,tmp):
        last_2_container_timestamp, = tmp
        df = table.last_group.copy()
        df = df.loc[df['content_type_id']==0,['user_id','timestamp']]
        if df.shape[0] == 0:
            return tmp
        
        tmp2 = df.groupby(['user_id'],sort=False).first()
        tmp2.columns = ['last_timestamp']
        tmp2 = tmp2.groupby('user_id',sort=False).last()
        
        for user in tmp2.index:
            if( user in last_2_container_timestamp):
                last_2_container_timestamp[user].append(tmp2.loc[user,'last_timestamp'])
            else:
                last_2_container_timestamp[user] = [tmp2.loc[user,'last_timestamp']]
            if( len(last_2_container_timestamp[user]) > 2):
                del(last_2_container_timestamp[user][0])
        return [last_2_container_timestamp,]
    


class feat_user_this_part_last_question_time_interval(Feat):
    def generate_feat(self, table):
        df = table.df_model[['user_id','content_id','task_container_id','timestamp']].copy()
        question2part = table.questions_info.set_index('question_id')['part'].astype(np.int8)
        
        df['part'] = df['content_id'].map(question2part)
        

        tmp = df.groupby(['user_id', 'task_container_id', 'part'], sort=False)['timestamp'].first()
        
        
        result = tmp.groupby(['user_id', 'part'], sort=False).last().astype(np.uint64).reset_index()
        result.index = result['user_id'].astype(np.int64)*7+result['part']
        result.drop(columns=['user_id','part'],inplace=True)
        
        # pdb.set_trace()
        
        tmp -= tmp.groupby(['user_id', 'part'], sort=False).shift(1)
        
        del(df['timestamp'])
        
        df= df.merge(tmp, how='left', on=['user_id', 'task_container_id', 'part'])
        df = df.rename(columns={'timestamp':'diff_timestamp_of_last_part'})
        
        feat = df[['diff_timestamp_of_last_part']]
        
        intermediate_feat = {}
        # pdb.set_trace()
        return feat, [result,intermediate_feat,]
    
    def generate_test_feat(self,table,tmp):
        result, intermediate_feat = tmp
        
        df = table.df_test_model[['user_id','content_id','timestamp']].copy()
     
        question2part = table.questions_info.set_index('question_id')['part'].astype(np.int8)
        
        df['part'] = df['content_id'].map(question2part)
        
        df.index = df['user_id'].astype(np.int64)*7+df['part']
        df.drop(columns=['user_id','part', 'content_id'],inplace=True)
        
        df_val = df.values
        
        df_n = df.shape[0]
        
        feat = np.zeros((df_n),dtype=np.float64)
        
        for i,idx in zip(range(df_n),df.index):
            if idx in result.index:
                feat[i] = df_val[i]-result.loc[idx]
            elif idx in intermediate_feat:
                feat[i] = df_val[i]-intermediate_feat[idx]
            
        feat[feat==0] = np.nan
                
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['diff_timestamp_of_last_part'])
        
        # 更新update
        # pdb.set_trace()
        for i,idx in zip(range(df_n),df.index):
            if idx in result.index:
                result.loc[idx] = df_val[i]
            else:
                intermediate_feat[idx] = df_val[i]
        
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        return tmp

    
 
class feat_cur_container_question_num(Feat):
    #这里说一下，一个task_container里可能有多个question，而且是同一batch给出，所以必须只能统计本task_container之前的值
    @timeclass('feat_cur_container_question_num')
    def generate_feat(self, table):
        t1 = time.time()
        df = table.df.copy()
        # 不带label不用单独处理question
        df = df.loc[~df['content_type_id'],['user_id', 'task_container_id', 'content_id']]
        
        
        # 计算各个container中的活动数目
        tmp = df.groupby(['user_id', 'task_container_id'], sort=False)['content_id'].agg(['size'])
        tmp.columns = ['cur_container_question_num']
        df = df.merge(tmp, how='left', on = ['user_id', 'task_container_id'])
        
        feat = df[['cur_container_question_num']]
        
        return feat, []
    
    # @timeclass('feat_user_history_question_nums_and_corroct_nums_and_rate')
    def generate_test_feat(self,table,tmp):
        
        df = table.df_test_model[['user_id', 'content_id']].copy()
        tmp1 = df.groupby(['user_id'], sort=False)['content_id'].agg(['size'])
        tmp1.columns = ['cur_container_question_num']
        # pdb.set_trace()
        df = df.reset_index()
        df = df.merge(tmp1, how='left', on = ['user_id'])
        df = df.set_index(['index'], drop=True)
        feat = df[['cur_container_question_num']]
        return feat

    # @timeclass('feat_user_history_question_nums_and_corroct_nums_and_rate')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
        

class feat_user_this_tag_questions_history_nums_and_correct_nums_and_rate(Feat):
    @timeclass('feat_user_this_tag_questions_history_nums_and_correct_nums_and_rate')
    def generate_feat(self,table):
        df = table.df_model[['user_id','feat_question_tags_encoding','label']].copy()
        df = df.set_index(['user_id','feat_question_tags_encoding'])
        
        tmp = df.groupby(['user_id','feat_question_tags_encoding'],sort=False)['label'].agg(['cumcount','cumsum'])

        tmp['cumcount'] += 1
        
        tmp.columns = ['feat_user_this_tag_question_history_nums','feat_user_this_tag_question_history_correct_nums']
        
        result = tmp.groupby(['user_id','feat_question_tags_encoding'],sort=False).last().astype(np.uint8).reset_index()
        
        
        tmp = tmp.groupby(['user_id','feat_question_tags_encoding'],sort=False).shift(1).fillna(0).astype(np.uint8)
        tmp['feat_user_this_tag_question_history_correct_rate'] = tmp['feat_user_this_tag_question_history_correct_nums']/tmp['feat_user_this_tag_question_history_nums']
        tmp.index = table.df_model.index
        
        result.index = result['user_id'].astype(np.int64)*20000+result['feat_question_tags_encoding']
        result.drop(columns=['user_id','feat_question_tags_encoding'],inplace=True)
        
        intermediate_feat = {}
        
        
        return tmp,[result,intermediate_feat]
    
    # @timeclass('feat_user_this_question_history_nums_and_correct_nums_and_rate')
    def generate_test_feat(self,table,tmp):
        result,intermediate_feat = tmp
        df_test_model = table.df_test_model['user_id'].astype(np.int64)*20000+table.df_test_model['feat_question_tags_encoding']
        
        df_n = df_test_model.shape[0]
        
        
        feat = np.zeros((df_n,2),dtype=np.uint8)
        for i,index in zip(range(df_n),df_test_model.values):
            if index in result.index:
                feat[i,:] = result.loc[index]
            elif index in intermediate_feat:
                feat[i,:] = intermediate_feat[index]
        
        
        feat = pd.DataFrame(feat,index=df_test_model.index,columns=['feat_user_this_tag_question_history_nums','feat_user_this_tag_question_history_correct_nums'])
        
        feat['feat_user_this_tag_question_history_correct_rate'] = feat['feat_user_this_tag_question_history_correct_nums']/feat['feat_user_this_tag_question_history_nums']
        
        
        return feat
    
    # @timeclass('feat_user_this_question_history_nums_and_correct_nums_and_rate')
    def update_intermediate_feat(self,table,tmp):
        result,intermediate_feat = tmp
        
        df = table.last_group_model[['user_id','feat_question_tags_encoding','label']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*20000+df['feat_question_tags_encoding']

        df = df['label']
        
        for i,v in zip(df.index,df.values):
            if i in result.index:
                result.loc[i] += [1,v]
            elif i in intermediate_feat:
                intermediate_feat[i] += np.array((1,v),dtype=np.uint8)
            else:
                intermediate_feat[i] = np.array((1,v),dtype=np.uint8)
        
        return [result,intermediate_feat]
    
    
class feat_loop_group_question_part_corroct_rate(Feat):
    #这里说一下，一个task_container里可能有多个question，而且是同一batch给出，所以必须只能统计本task_container之前的值
    @timeclass('feat_loop_group_question_part_corroct_rate')
    def generate_feat(self,table):
        df = table.df_model[['user_id','part','label']].copy()
        
        user_n = df['user_id'].nunique()
        k = 5
        smoothly_n = 20
        
        np.random.seed(seed)
        rand_group = np.random.randint(0,k,user_n)
        
        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))
        
        
        columns = [f'feat_loop_group_question_part_{col}' for col in ['num','correct_num','corroct_rate']]
        
        tmp_list = []
        for i in range(k):
            tmp_a = df.loc[df['group']!=i].groupby('part')['label'].agg(['count','sum']).astype('int')
            tmp_a['mean'] = tmp_a['sum']/(tmp_a['count']+smoothly_n)
            
            tmp_a.columns = columns
            
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i
        
            tmp_list.append(tmp_a)
        
        tmp = pd.concat(tmp_list,axis=0)
        

        
        df = df.merge(tmp,how='left',on=['group','part'])
        df.index = table.df_model.index
        print(f"{df.loc[df['feat_loop_group_question_part_corroct_rate'].isnull(),'part'].nunique()} question is null")
        

        feat = df[columns]

        #测试集两种方式，5个的mean；整体的mean
        #1
        result = tmp.groupby('part')[columns].mean()
        result['feat_loop_group_question_part_num'] = result['feat_loop_group_question_part_num'].round().astype('int')
        result['feat_loop_group_question_part_correct_num'] = result['feat_loop_group_question_part_correct_num'].round().astype('int')
        
        
        
        return feat,[result]
    
    # @timeclass('feat_loop_group_question_part_corroct_rate')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        columns = [f'feat_loop_group_question_part_{col}' for col in ['num','correct_num','corroct_rate']]
        
        df_test_model = table.df_test_model[['part']].copy()
        for col in columns:
            df_test_model[col] = df_test_model['part'].map(result[col])
        
        feat = df_test_model[columns]
        
        return feat

    # @timeclass('feat_loop_group_question_part_corroct_rate')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    

# 反应本组题目的平均难度
class feat_cur_container_loop_correct_rate_mean(Feat):
    @timeclass('feat_cur_container_loop_correct_rate_mean')
    def generate_feat(self, table):
        
        # pdb.set_trace()
        df = table.df_model[['user_id','task_container_id','feat_loop_group_question_corroct_rate']].copy()
        
        tmp = df.groupby(['user_id', 'task_container_id'], sort=False)['feat_loop_group_question_corroct_rate'].agg(['mean', 'max', 'min', 'std'])
        
        tmp.columns = ['cur_container_loop_correct_rate_mean', 'cur_container_loop_correct_rate_max',
                       'cur_container_loop_correct_rate_min', 'cur_container_loop_correct_rate_std',]
        
        df = df.merge(tmp, how='left', on = ['user_id', 'task_container_id'])
        
        feat = df[['cur_container_loop_correct_rate_mean', 'cur_container_loop_correct_rate_max',
                   'cur_container_loop_correct_rate_min', 'cur_container_loop_correct_rate_std',]]
        
        return feat, []
    
    def generate_test_feat(self,table,tmp):
        
        df = table.df_test_model[['user_id','feat_loop_group_question_corroct_rate']].copy()
        
        tmp = df.groupby(['user_id'], sort=False)['feat_loop_group_question_corroct_rate'].agg(['mean', 'max', 'min', 'std'])
        
        tmp.columns = ['cur_container_loop_correct_rate_mean', 'cur_container_loop_correct_rate_max',
                       'cur_container_loop_correct_rate_min', 'cur_container_loop_correct_rate_std',]
        
        df = df.merge(tmp, how='left', on = ['user_id'])
        
        feat = df[['cur_container_loop_correct_rate_mean', 'cur_container_loop_correct_rate_max',
                   'cur_container_loop_correct_rate_min', 'cur_container_loop_correct_rate_std',]]
        
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    
    

class feat_user_this_tag_last_question_time_interval(Feat):
    @timeclass('feat_user_this_tag_last_question_time_interval')
    def generate_feat(self, table):
        df = table.df_model[['user_id','feat_question_tags_encoding','task_container_id','timestamp']].copy()
        
        tmp = df.groupby(['user_id', 'task_container_id', 'feat_question_tags_encoding'], sort=False)['timestamp'].first()
        pdb.set_trace()
        
        result = tmp.groupby(['user_id', 'feat_question_tags_encoding'], sort=False).last()
        last_tag_timestamp = defaultdict(int)
        last_tag_timestamp.update(result)    
        
        # pdb.set_trace()
        
        #这里fillna(0) 有问题
        tmp -= tmp.groupby(['user_id', 'feat_question_tags_encoding'], sort=False).shift(1).fillna(0)
        
        del(df['timestamp'])
        
        df= df.merge(tmp, how='left', on=['user_id', 'task_container_id', 'feat_question_tags_encoding'])
        df = df.rename(columns={'timestamp':'diff_timestamp_of_last_tag'})
        
        feat = df[['diff_timestamp_of_last_tag']]
        
        return feat, [last_tag_timestamp,]
    
    def generate_test_feat(self,table,tmp):
        last_tag_timestamp, = tmp
        
        df = table.df_test_model[['user_id','feat_question_tags_encoding','timestamp']].copy()
        
       
        
        df = df.reset_index()
        df = df.set_index(['user_id', 'feat_question_tags_encoding'])
        df['diff_timestamp_of_last_tag'] = df['timestamp']-df.index.map(last_tag_timestamp)
        df = df.reset_index()
        df.index = table.df_test_model.index
        
        feat = df[['diff_timestamp_of_last_tag']]
        
        tmp1 = df.groupby(['user_id', 'feat_question_tags_encoding'], sort=False)['timestamp'].first()
        
        tmp1_val = tmp1.values
        i = 0
        # pdb.set_trace()
        for idx in tmp1.index:
            last_tag_timestamp[idx] = tmp1_val[i] 
            i += 1
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    
class feat_user_this_question_time_interval_k_list(Feat):
    @timeclass('feat_user_this_question_time_interval_k_list')
    def generate_feat(self, table):
        data_type = np.int64
        k_list = [2]
        max_k = np.max(k_list)
        
        key = ['user_id','content_id']
        
        df = table.df_model[key+['timestamp']].copy()
        
        result = df.groupby(key,sort=False).tail(max_k)
        
        columns = []
        for i in k_list:
            df[f'diff_{i}_timestamp_of_last_question'] = df['timestamp'] - df.groupby(key, sort=False)['timestamp'].shift(i)
            columns.append(f'diff_{i}_timestamp_of_last_question')
        
        feat = df[columns]
        feat.index = table.df_model.index
        
        result['index_key'] = result['user_id'].astype(np.int64)*20000+result['content_id']
        result.drop(columns=key,inplace=True)
        
        result['num'] = result.groupby('index_key',sort=False).cumcount()+1
        result['num_sum'] = result['index_key'].map(result.groupby('index_key').size())
        result['num_sum'] = max_k-result['num_sum']
        result['num'] += result['num_sum']
        
        result = pd.pivot_table(result,index='index_key',columns='num',values='timestamp')
        
        result.columns = [max_k-i+1 for i in result.columns]
        dict_k_list = [max_k-i for i in k_list]
        
        intermediate_feat = {}
        
        return feat, [result,intermediate_feat,columns,k_list,dict_k_list,max_k]
    
    
    def generate_test_feat(self,table,tmp):
        result,intermediate_feat,columns,k_list,dict_k_list,max_k = tmp
        df = table.df_test_model[['user_id', 'content_id', 'timestamp']].copy()
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        
        df_n = df.shape[0]
        
        feat = np.zeros((df_n,len(k_list)))*np.nan
        
        for i,idx in zip(range(df_n),df.index):
            if idx in result.index:
                feat[i,:] = result.loc[idx,k_list]
            elif idx in intermediate_feat:
                feat[i,:] = intermediate_feat[idx][dict_k_list]
                
        
        
        feat = df['timestamp'].values.reshape(-1,1) - feat
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=columns)
        
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        result,intermediate_feat,columns,k_list,dict_k_list,max_k = tmp
        
        df = table.last_group_model[['user_id','content_id', 'timestamp']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        for idx,time_v in zip(df.index,df['timestamp'].values):
            if idx in result.index:
                val = result.loc[idx].values
                val[:-1] = val[1:]
                val[-1] = time_v
                result.loc[idx] = val
            elif idx in intermediate_feat:
                val = intermediate_feat[idx]
                val[:-1] = val[1:]
                val[-1] = time_v
                intermediate_feat[idx] = val
            else:
                intermediate_feat[idx] = np.array([np.nan]*(max_k-1)+[time_v])
        
        return [result,intermediate_feat,columns,k_list,dict_k_list,max_k]



class feat_user_this_question_history_label_k_list(Feat):
    @timeclass('feat_user_this_question_history_label_k_list')
    def generate_feat(self, table):
        data_type = np.int64
        k_list = [1,2,3]
        max_k = np.max(k_list)
        
        key = ['user_id','content_id']
        
        df = table.df_model[key+['label']].copy()
        result = df.groupby(key,sort=False).tail(max_k)
        
        columns = []
        for i in k_list:
            df[f'user_this_question_history_label_{i}'] = df.groupby(key, sort=False)['label'].shift(i)
            columns.append(f'user_this_question_history_label_{i}')
        
        feat = df[columns]
        feat.index = table.df_model.index
        
        
        
        result['index_key'] = result['user_id'].astype(np.int64)*20000+result['content_id']
        result.drop(columns=key,inplace=True)
        
        result['num'] = result.groupby('index_key',sort=False).cumcount()+1
        result['num_sum'] = result['index_key'].map(result.groupby('index_key').size())
        result['num_sum'] = max_k-result['num_sum']
        result['num'] += result['num_sum']
        
        result = pd.pivot_table(result,index='index_key',columns='num',values='label')
        
        result.columns = [max_k-i+1 for i in result.columns]
        dict_k_list = [max_k-i for i in k_list]
        
        intermediate_feat = {}
        
        return feat, [result,intermediate_feat,columns,k_list,dict_k_list,max_k]
    
    
    def generate_test_feat(self,table,tmp):
        result,intermediate_feat,columns,k_list,dict_k_list,max_k = tmp
        df = table.df_test_model[['user_id', 'content_id']].copy()
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        
        df_n = df.shape[0]
        
        feat = np.zeros((df_n,len(k_list)))*np.nan
        
        for i,idx in zip(range(df_n),df.index):
            if idx in result.index:
                feat[i,:] = result.loc[idx,k_list]
            elif idx in intermediate_feat:
                feat[i,:] = intermediate_feat[idx][dict_k_list]
                
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=columns)
        
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        result,intermediate_feat,columns,k_list,dict_k_list,max_k = tmp
        
        df = table.last_group_model[['user_id','content_id', 'label']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        for idx,label_v in zip(df.index,df['label'].values):
            if idx in result.index:
                val = result.loc[idx].values
                val[:-1] = val[1:]
                val[-1] = label_v
                result.loc[idx] = val
            elif idx in intermediate_feat:
                val = intermediate_feat[idx]
                val[:-1] = val[1:]
                val[-1] = label_v
                intermediate_feat[idx] = val
            else:
                intermediate_feat[idx] = np.array([np.nan]*(max_k-1)+[label_v])
        
        return [result,intermediate_feat,columns,k_list,dict_k_list,max_k]
    


class feat_user_this_question_history_label_rolling_k(Feat):
    @timeclass('feat_user_this_question_history_label_rolling_k')
    def generate_feat(self, table):
        data_type = np.int64
        k_list = [1,2,3]
        max_k = np.max(k_list)
        
        key = ['user_id','content_id']
        
        df = table.df_model[key+['label']].copy()
        result = df.groupby(key,sort=False).tail(max_k)
        
        columns = []
        for i in k_list:
            df[f'user_this_question_history_label_{i}'] = df.groupby(key, sort=False)['label'].shift(i)
            columns.append(f'user_this_question_history_label_{i}')
        
        feat = df[columns]
        feat[f'user_this_question_history_label_rolling_{max_k}'] = feat.values.mean(axis=1)
        feat.index = table.df_model.index
        columns = [f'user_this_question_history_label_rolling_{max_k}']
        feat = feat[columns]
        
        
        result['index_key'] = result['user_id'].astype(np.int64)*20000+result['content_id']
        result.drop(columns=key,inplace=True)
        
        result['num'] = result.groupby('index_key',sort=False).cumcount()+1
        result['num_sum'] = result['index_key'].map(result.groupby('index_key').size())
        result['num_sum'] = max_k-result['num_sum']
        result['num'] += result['num_sum']
        
        result = pd.pivot_table(result,index='index_key',columns='num',values='label')
        
        result.columns = [max_k-i+1 for i in result.columns]
        dict_k_list = [max_k-i for i in k_list]
        
        intermediate_feat = {}
        
        return feat, [result,intermediate_feat,columns,k_list,dict_k_list,max_k]
    
    
    def generate_test_feat(self,table,tmp):
        result,intermediate_feat,columns,k_list,dict_k_list,max_k = tmp
        df = table.df_test_model[['user_id', 'content_id']].copy()
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        
        df_n = df.shape[0]
        
        feat = np.zeros((df_n,len(k_list)))*np.nan
        
        for i,idx in zip(range(df_n),df.index):
            if idx in result.index:
                feat[i,:] = result.loc[idx,k_list]
            elif idx in intermediate_feat:
                feat[i,:] = intermediate_feat[idx][dict_k_list]
                
        
        feat = feat.mean(axis=1)
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=columns)
        
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        result,intermediate_feat,columns,k_list,dict_k_list,max_k = tmp
        
        df = table.last_group_model[['user_id','content_id', 'label']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        for idx,label_v in zip(df.index,df['label'].values):
            if idx in result.index:
                val = result.loc[idx].values
                val[:-1] = val[1:]
                val[-1] = label_v
                result.loc[idx] = val
            elif idx in intermediate_feat:
                val = intermediate_feat[idx]
                val[:-1] = val[1:]
                val[-1] = label_v
                intermediate_feat[idx] = val
            else:
                intermediate_feat[idx] = np.array([np.nan]*(max_k-1)+[label_v])
        
        return [result,intermediate_feat,columns,k_list,dict_k_list,max_k]
    
    

class feat_user_this_question_history_elapsed_time_k_list(Feat):
    @timeclass('feat_user_this_question_history_elapsed_time_k_list')
    def generate_feat(self, table):
        data_type = np.int64
        k_list = [1]
        max_k = np.max(k_list)
        
        key = ['user_id','content_id']
        
        df = table.df_model[key+['prior_question_elapsed_time']].copy()
        df['prior_question_elapsed_time'] = df.groupby('user_id',sort=False)['prior_question_elapsed_time'].shift(-1)
        
        result = df.groupby(key,sort=False).tail(max_k)
        
        columns = []
        for i in k_list:
            df[f'user_this_question_history_elapsed_time_{i}'] = df.groupby(key, sort=False)['prior_question_elapsed_time'].shift(i)
            columns.append(f'user_this_question_history_elapsed_time_{i}')
        
        feat = df[columns]
        feat.index = table.df_model.index
        
        
        
        result['index_key'] = result['user_id'].astype(np.int64)*20000+result['content_id']
        result.drop(columns=key,inplace=True)
        
        result['num'] = result.groupby('index_key',sort=False).cumcount()+1
        result['num_sum'] = result['index_key'].map(result.groupby('index_key').size())
        result['num_sum'] = max_k-result['num_sum']
        result['num'] += result['num_sum']
        
        result = pd.pivot_table(result,index='index_key',columns='num',values='prior_question_elapsed_time')
        
        result.columns = [max_k-i+1 for i in result.columns]
        dict_k_list = [max_k-i for i in k_list]
        
        intermediate_feat = {}
        
        return feat, [result,intermediate_feat,columns,k_list,dict_k_list,max_k]
    
    
    def generate_test_feat(self,table,tmp):
        result,intermediate_feat,columns,k_list,dict_k_list,max_k = tmp
        df = table.df_test_model[['user_id', 'content_id']].copy()
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        
        df_n = df.shape[0]
        
        feat = np.zeros((df_n,len(k_list)))*np.nan
        
        for i,idx in zip(range(df_n),df.index):
            if idx in result.index:
                feat[i,:] = result.loc[idx,k_list]
            elif idx in intermediate_feat:
                feat[i,:] = intermediate_feat[idx][dict_k_list]
                
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=columns)
        
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        #!!!!!这个特征没写完！！！！不能用奥
        result,intermediate_feat,columns,k_list,dict_k_list,max_k = tmp
        
        df = table.last_group_model[['user_id','content_id', 'prior_question_elapsed_time']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        for idx,label_v in zip(df.index,df['label'].values):
            if idx in result.index:
                val = result.loc[idx].values
                val[:-1] = val[1:]
                val[-1] = label_v
                result.loc[idx] = val
            elif idx in intermediate_feat:
                val = intermediate_feat[idx]
                val[:-1] = val[1:]
                val[-1] = label_v
                intermediate_feat[idx] = val
            else:
                intermediate_feat[idx] = np.array([np.nan]*(max_k-1)+[label_v])
        
        return [result,intermediate_feat,columns,k_list,dict_k_list,max_k]
    


class feat_user_this_question_history_explanation_k_list(Feat):
    @timeclass('feat_user_this_question_history_explanation_k_list')
    def generate_feat(self, table):
        data_type = np.int64
        k_list = [1,2,3]
        max_k = np.max(k_list)
        
        key = ['user_id','content_id']
        
        df = table.df_model[key+['prior_question_had_explanation']].copy()
        df['prior_question_had_explanation'] = df.groupby('user_id',sort=False)['prior_question_had_explanation'].shift(-1)
        
        result = df.groupby(key,sort=False).tail(max_k)
        
        columns = []
        for i in k_list:
            df[f'user_this_question_history_explanation_{i}'] = df.groupby(key, sort=False)['prior_question_had_explanation'].shift(i)
            columns.append(f'user_this_question_history_explanation_{i}')
        
        feat = df[columns]
        feat.index = table.df_model.index
        
        
        
        result['index_key'] = result['user_id'].astype(np.int64)*20000+result['content_id']
        result.drop(columns=key,inplace=True)
        
        result['num'] = result.groupby('index_key',sort=False).cumcount()+1
        result['num_sum'] = result['index_key'].map(result.groupby('index_key').size())
        result['num_sum'] = max_k-result['num_sum']
        result['num'] += result['num_sum']
        
        result = pd.pivot_table(result,index='index_key',columns='num',values='prior_question_had_explanation')
        
        result.columns = [max_k-i+1 for i in result.columns]
        dict_k_list = [max_k-i for i in k_list]
        
        intermediate_feat = {}
        
        return feat, [result,intermediate_feat,columns,k_list,dict_k_list,max_k]
    
    
    def generate_test_feat(self,table,tmp):
        result,intermediate_feat,columns,k_list,dict_k_list,max_k = tmp
        df = table.df_test_model[['user_id', 'content_id']].copy()
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        
        df_n = df.shape[0]
        
        feat = np.zeros((df_n,len(k_list)))*np.nan
        
        for i,idx in zip(range(df_n),df.index):
            if idx in result.index:
                feat[i,:] = result.loc[idx,k_list]
            elif idx in intermediate_feat:
                feat[i,:] = intermediate_feat[idx][dict_k_list]
                
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=columns)
        
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        result,intermediate_feat,columns,k_list,dict_k_list,max_k = tmp
        
        #!!!!!这个特征没写完！！！！不能用奥
        df = table.last_group_model[['user_id','content_id', 'prior_question_elapsed_time']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        for idx,label_v in zip(df.index,df['label'].values):
            if idx in result.index:
                val = result.loc[idx].values
                val[:-1] = val[1:]
                val[-1] = label_v
                result.loc[idx] = val
            elif idx in intermediate_feat:
                val = intermediate_feat[idx]
                val[:-1] = val[1:]
                val[-1] = label_v
                intermediate_feat[idx] = val
            else:
                intermediate_feat[idx] = np.array([np.nan]*(max_k-1)+[label_v])
        
        return [result,intermediate_feat,columns,k_list,dict_k_list,max_k]
    
    
  
class feat_user_time_interval_k_list(Feat):
    @timeclass('feat_user_time_interval_k_list')
    def generate_feat(self, table):
        k_list = [i for i in range(5,0,-1)]
        max_k = np.max(k_list)
        
        key = ['user_id']
        
        df = table.df_model[key+['task_container_id','timestamp']].copy()
        
        tmp = df.groupby(key+['task_container_id'],sort=False).first()
        tmp['timestamp'] = tmp['timestamp'].astype(np.float64)
        
        result = tmp.groupby(key,sort=False).tail(max_k)
        columns = []
        for i in k_list:
            tmp[f'feat_user_time_interval_{i}'] = tmp['timestamp'] - tmp.groupby(key, sort=False)['timestamp'].shift(i)
            columns.append(f'feat_user_time_interval_{i}')
            
        tmp = tmp[columns]
        df = df.merge(tmp,how='left',on=key+['task_container_id'])
        
        feat = df[columns]
        feat.index = table.df_model.index
        
        
        result = result.reset_index()
        result['index_key'] = result['user_id']
        result.drop(columns=key+['task_container_id'],inplace=True)
        
        result['num'] = result.groupby('index_key',sort=False).cumcount()+1
        result['num_sum'] = result['index_key'].map(result.groupby('index_key').size())
        result['num_sum'] = max_k-result['num_sum']
        result['num'] += result['num_sum']
        
        result = pd.pivot_table(result,index='index_key',columns='num',values='timestamp')
        
        
        result_val = np.zeros((500000,max_k),np.float64)*np.nan
        result_val[result.index,:] = result.values
        
        need_list = [max_k-i for i in k_list]
        
        return feat, [result_val,columns,k_list,need_list,max_k]
    
    
    def generate_test_feat(self,table,tmp):
        result_val,columns,k_list,need_list,max_k = tmp
        df = table.df_test_model[['user_id', 'timestamp']].values
        
        feat = result_val[df[:,0:1],need_list]
        feat = df[:,1:] - feat
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=columns)
        feat.index = table.df_test_model.index
        
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        result_val,columns,k_list,need_list,max_k = tmp
        
        df = table.last_group_model[['user_id','task_container_id','timestamp']].copy()
        df = df.groupby(['user_id','task_container_id'],sort=False).first()
        df = df.reset_index()
        
        result_val[df['user_id'],:-1] = result_val[df['user_id'],1:]
        result_val[df['user_id'],-1] = df['timestamp'].values
        
        
        return [result_val,columns,k_list,need_list,max_k]
    
    

class feat_user_this_part_time_interval_k_list(Feat):
    @timeclass('feat_user_time_interval_k_list')
    def generate_feat(self, table):
        k_list = [i for i in range(5,0,-1)]
        max_k = np.max(k_list)
        
        key = ['user_id','part']
        
        df = table.df_model[key+['task_container_id','timestamp']].copy()
        
        tmp = df.groupby(key+['task_container_id'],sort=False).first()
        tmp['timestamp'] = tmp['timestamp'].astype(np.float64)
        
        result = tmp.groupby(key,sort=False).tail(max_k)
        columns = []
        for i in k_list:
            tmp[f'feat_user_this_part_time_interval_{i}'] = tmp['timestamp'] - tmp.groupby(key, sort=False)['timestamp'].shift(i)
            columns.append(f'feat_user_this_part_time_interval_{i}')
            
        tmp = tmp[columns]
        df = df.merge(tmp,how='left',on=key+['task_container_id'])
        
        feat = df[columns]
        feat.index = table.df_model.index
        
        
        result = result.reset_index()
        result['index_key'] = result['user_id']*7+result['part']
        result.drop(columns=key+['task_container_id'],inplace=True)
        
        result['num'] = result.groupby('index_key',sort=False).cumcount()+1
        result['num_sum'] = result['index_key'].map(result.groupby('index_key').size())
        result['num_sum'] = max_k-result['num_sum']
        result['num'] += result['num_sum']
        
        result = pd.pivot_table(result,index='index_key',columns='num',values='timestamp')
        
        
        result_val = np.zeros((500000*7,max_k),np.float64)*np.nan
        result_val[result.index,:] = result.values
        
        need_list = [max_k-i for i in k_list]
        
        return feat, [result_val,key,columns,k_list,need_list,max_k]
    
    
    def generate_test_feat(self,table,tmp):
        result_val,key,columns,k_list,need_list,max_k = tmp
        df = table.df_test_model[['timestamp']].copy()
        df.index= table.df_test_model['user_id']*7+table.df_test_model['part']
        
        feat = result_val[df.index.values.reshape(-1,1),need_list]
        feat = df.values - feat
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=columns)
        feat.index = table.df_test_model.index
        
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        result_val,key,columns,k_list,need_list,max_k = tmp
        
        df = table.last_group_model[key+['task_container_id','timestamp']].copy()
        df = df.groupby(key+['task_container_id'],sort=False).first()
        df = df.reset_index()
        df.index = df['user_id']*7+df['part']
        
        result_val[df.index,:-1] = result_val[df.index,1:]
        result_val[df.index,-1] = df['timestamp'].values
        
        
        return [result_val,key,columns,k_list,need_list,max_k]
    
    

class feat_user_this_tags_time_interval_k_list(Feat):
    @timeclass('feat_user_this_tags_time_interval_k_list')
    def generate_feat(self, table):
        data_type = np.int64
        k_list = [1]
        max_k = np.max(k_list)
        
        key = ['user_id','feat_question_tags_encoding']
        
        df = table.df_model[key+['task_container_id','timestamp']].copy()
        
        tmp = df.groupby(['user_id', 'task_container_id', 'feat_question_tags_encoding'], sort=False).head(1)
        
        # result = tmp.groupby(key,sort=False).tail(max_k)
        columns = []
        for i in k_list:
            tmp[f'diff_{i}_timestamp_of_last_tags'] = tmp['timestamp'] - tmp.groupby(key, sort=False)['timestamp'].shift(i)
            columns.append(f'diff_{i}_timestamp_of_last_tags')
        
        tmp = tmp[columns+key+['task_container_id']]
        
        df = df.merge(tmp,how='left',on=key+['task_container_id'])
        
        feat = df[columns]
        feat.index = table.df_model.index
        
        
        # feat = df[columns]
        # feat.index = table.df_model.index
        
        # result['index_key'] = result['user_id'].astype(np.int64)*20000+result['content_id']
        # result.drop(columns=key,inplace=True)
        
        # result['num'] = result.groupby('index_key',sort=False).cumcount()+1
        # result['num_sum'] = result['index_key'].map(result.groupby('index_key').size())
        # result['num_sum'] = max_k-result['num_sum']
        # result['num'] += result['num_sum']
        
        # result = pd.pivot_table(result,index='index_key',columns='num',values='timestamp')
        
        # result.columns = [max_k-i+1 for i in result.columns]
        # dict_k_list = [max_k-i for i in k_list]
        
        # intermediate_feat = {}
        
        # return feat, [result,intermediate_feat,columns,k_list,dict_k_list,max_k]
        
        return feat, []
    
    
    def generate_test_feat(self,table,tmp):
        result,intermediate_feat,columns,k_list,dict_k_list,max_k = tmp
        df = table.df_test_model[['user_id', 'content_id', 'timestamp']].copy()
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        
        df_n = df.shape[0]
        
        feat = np.zeros((df_n,len(k_list)))*np.nan
        
        for i,idx in zip(range(df_n),df.index):
            if idx in result.index:
                feat[i,:] = result.loc[idx,k_list]
            elif idx in intermediate_feat:
                feat[i,:] = intermediate_feat[idx][dict_k_list]
                
        
        
        feat = df['timestamp'].values.reshape(-1,1) - feat
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=columns)
        
        return feat
    
    def update_intermediate_feat(self,table,tmp):
        result,intermediate_feat,columns,k_list,dict_k_list,max_k = tmp
        
        df = table.last_group_model[['user_id','content_id', 'timestamp']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*20000+df['content_id']
        
        for idx,time_v in zip(df.index,df['timestamp'].values):
            if idx in result.index:
                val = result.loc[idx].values
                val[:-1] = val[1:]
                val[-1] = time_v
                result.loc[idx] = val
            elif idx in intermediate_feat:
                val = intermediate_feat[idx]
                val[:-1] = val[1:]
                val[-1] = time_v
                intermediate_feat[idx] = val
            else:
                intermediate_feat[idx] = np.array([np.nan]*(max_k-1)+[time_v])
        
        return [result,intermediate_feat,columns,k_list,dict_k_list,max_k]
    
    

class feat_user_this_tags_history_nums_and_correct_nums_and_rate_join_time_interval(Feat):
    @timeclass('feat_user_this_tags_history_nums_and_correct_nums_and_rate_join_time_interval')
    def generate_feat(self, table):
        df = table.df_model[['user_id','feat_question_tags_encoding','task_container_id','timestamp']].copy()
        
        tmp = df.groupby(['user_id', 'task_container_id', 'feat_question_tags_encoding'], sort=False)['timestamp'].first()
        
        
        result = tmp.groupby(['user_id', 'feat_question_tags_encoding'], sort=False).last().reset_index()
        result.index = result['user_id'].astype(np.int64)*10000+result['feat_question_tags_encoding']
        result.drop(columns=['user_id','feat_question_tags_encoding'],inplace=True)
        
        
        tmp -= tmp.groupby(['user_id', 'feat_question_tags_encoding'], sort=False).shift(1)
        df.drop(columns=['timestamp'],inplace=True)
        
        df = df.merge(tmp, how='left', on=['user_id', 'task_container_id', 'feat_question_tags_encoding'])
        df = df.rename(columns={'timestamp':'diff_timestamp_of_last_tag'})
        
        df.index = table.df_model.index
        feat = df[['diff_timestamp_of_last_tag']]
        
        
        ################# 分割线 #################
        
        df2 = table.df_model[['user_id','task_container_id','feat_question_tags_encoding','label']].copy()
        
        tmp2 = df2.groupby(['user_id','task_container_id', 'feat_question_tags_encoding'],sort=False)['label'].agg(['size',sum])

        tmp2 = tmp2.groupby(['user_id','feat_question_tags_encoding'],sort=False).cumsum()
        
        tmp2.columns = ['feat_user_this_tags_history_question_nums','feat_user_this_tags_history_corroct_nums']
        
        
        result2 = tmp2.groupby(['user_id','feat_question_tags_encoding'],sort=False).last().reset_index()
        result2.index = result2['user_id'].astype(np.int64)*10000+result2['feat_question_tags_encoding']
        result2.drop(columns=['user_id','feat_question_tags_encoding'],inplace=True)
        
        
        tmp2 = tmp2.groupby(['user_id','feat_question_tags_encoding'],sort=False).shift(1).fillna(0).astype(np.int)
        
        df2.drop(columns=['label'],inplace=True)
        df2 = df2.merge(tmp2,how='left',on=['user_id','task_container_id','feat_question_tags_encoding'])
        
        df2.index = table.df_model.index
        
        df2['feat_user_this_tags_history_corroct_rate'] = df2['feat_user_this_tags_history_corroct_nums']/df2['feat_user_this_tags_history_question_nums']
        
        feat2 = df2[['feat_user_this_tags_history_question_nums','feat_user_this_tags_history_corroct_nums','feat_user_this_tags_history_corroct_rate']]
        
        
        #结合两者
        feat = pd.concat([feat,feat2],axis=1)
        result = pd.concat([result,result2],axis=1)
        
        intermediate_feat = {}
        
        
        return feat,[result,intermediate_feat]
    
    
    # @timeclass('feat_user_this_tags_history_nums_and_correct_nums_and_rate_join_time_interval')
    def generate_test_feat(self,table,tmp):
        result, intermediate_feat = tmp
        df = table.df_test_model[['user_id', 'feat_question_tags_encoding', 'timestamp']].copy()
        df.index = df['user_id'].astype(np.int64)*10000+df['feat_question_tags_encoding']
        
        df_n = df.shape[0]
        
        feat = np.zeros((df_n,3),np.float64)
        
        for i,idx,v in zip(range(df_n),df.index,df['timestamp']):
            if idx in result.index:
                feat[i,:] = result.loc[idx]
                feat[i,0] = v-feat[i,0]
            elif idx in intermediate_feat:
                feat[i,:] = intermediate_feat[idx]
                feat[i,0] = v-feat[i,0]
            else:
                feat[i,0] = np.nan
        
                
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['diff_timestamp_of_last_tag','feat_user_this_tags_history_question_nums','feat_user_this_tags_history_corroct_nums'])
        feat['feat_user_this_tags_history_question_nums'] = feat['feat_user_this_tags_history_question_nums'].astype(np.int64)
        feat['feat_user_this_tags_history_corroct_nums'] = feat['feat_user_this_tags_history_corroct_nums'].astype(np.int64)
        
        feat['feat_user_this_tags_history_corroct_rate'] = feat['feat_user_this_tags_history_corroct_nums']/feat['feat_user_this_tags_history_question_nums']
        
        return feat

    
    # @timeclass('feat_user_this_tags_history_nums_and_correct_nums_and_rate_join_time_interval')
    def update_intermediate_feat(self,table,tmp):
        result,intermediate_feat = tmp
        df = table.last_group_model[['user_id','feat_question_tags_encoding','timestamp','label']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        df.index = df['user_id'].astype(np.int64)*10000+df['feat_question_tags_encoding']
        
        
        for i, idx, time_v, label_v in zip(range(df_n), df.index, df['timestamp'], df['label']):
            if idx in result.index:
                val = result.loc[idx].values
                val[1] += 1
                val[2] += label_v
                val[0] = time_v
                
                result.loc[idx] = val
                
                #废弃方法1
                # result.loc[idx] += np.array([0,1,label_v],dtype=np.int64)
                # result.loc[idx,'timestamp'] = time_v
                
                #废弃方法2
                # result.loc[idx,'timestamp'] = time_v
                # result.loc[idx,'feat_user_this_tags_history_question_nums'] += 1
                # result.loc[idx,'feat_user_this_tags_history_corroct_nums'] += label_v
                
            elif idx in intermediate_feat:
                intermediate_feat[idx] += np.array(([0,1,label_v]),dtype=np.int64)
                intermediate_feat[idx][0] = time_v
            else:
                intermediate_feat[idx] = np.array(([time_v,1,label_v]),dtype=np.int64)
                
        return [result,intermediate_feat]
    


class feat_user_this_session_history_loop_group_question_corroct_rate_mean(Feat):
    @timeclass('feat_user_this_session_history_loop_group_question_corroct_rate_mean')
    def generate_feat(self,table):
        df = table.df_model[['user_id','session','feat_loop_group_question_corroct_rate']].copy()
        #编码编码编码
        df.set_index(['user_id','session'],inplace=True)
        tmp = pd.concat([df.groupby(['user_id','session'],sort=False).cumsum(),df.groupby(['user_id','session'],sort=False).cumcount()+1],axis=1)
        tmp.columns = ['feat_user_this_session_history_loop_group_question_corroct_rate_mean','count']
        
        result = tmp.reset_index().groupby('user_id',sort=False).last()
        # df.index = df['user_id']*7+df['part']
        
        tmp['feat_user_this_session_history_loop_group_question_corroct_rate_mean'] /= tmp['count']
        
        feat = tmp[['feat_user_this_session_history_loop_group_question_corroct_rate_mean']]
        feat.index = table.df_model.index
        
        result_val = np.zeros((500000,3))
        result_val[result.index,:] = result.values
        
        return feat,[result_val]
    
    
    # @timeclass('feat_user_this_part_history_loop_group_question_corroct_rate_mean')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        df = table.df_test_model[['user_id','session','feat_loop_group_question_corroct_rate']].copy()
        
        feat_n = df.shape[0]
        
        feat = np.zeros((feat_n,1))
        
        for i,user,session,corroct_rate in zip(range(feat_n),df['user_id'],df['session'],df['feat_loop_group_question_corroct_rate']):
            #0session,1cumsum,2count
            if result[user,0] == session:
                result[user,2] += 1
                result[user,1] += corroct_rate
                feat[i,0] = result[user,1]/result[user,2]
                
            else:
                result[user,2] = 1
                result[user,1] = corroct_rate
                feat[i,0] = corroct_rate
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['feat_user_this_session_history_loop_group_question_corroct_rate_mean'])
        
        #这里result没有返回，不过也会更新的，因为直接改了内存中的值
        return feat

    # @timeclass('feat_user_this_part_history_loop_group_question_corroct_rate_mean')
    def update_intermediate_feat(self,table,tmp):
        return tmp       
    
        
class feat_user_container_id_diff1(Feat):
    @timeclass('feat_user_container_id_diff1')
    def generate_feat(self, table):
        df = table.df[['user_id', 'task_container_id', 'timestamp']].copy()
        
        tmp = df.groupby(['user_id','timestamp'], sort=False)['task_container_id'].agg(['first'])
        
        tmp.columns = ['task_container_id']
        
        result = tmp.reset_index().groupby('user_id',sort=False)['task_container_id'].agg(['last'])
        
        result_val = np.full((500000,1),np.nan)
        
        result_val[result.index,:] = result.values
        
        tmp.columns = ['feat_user_container_id_diff1']
        
        tmp -= tmp.groupby(['user_id'], sort=False).shift(1)
        
        df = table.df_model[['user_id', 'timestamp']].copy()
        
        df = df.merge(tmp, how='left', on=['user_id', 'timestamp'])
        
        df.index = table.df_model.index
        
        feat = df[['feat_user_container_id_diff1']]
        
        # pdb.set_trace()
        
        return feat,[result_val]
    
    
    def generate_test_feat(self, table, tmp): 
        result_val, = tmp
        
        df = table.df_test_model[['user_id', 'task_container_id']].copy()
        
        
        df_n = df.shape[0]
        
        feat = np.full(df_n, np.nan)
        
        for i,user,v in zip(range(df_n), df['user_id'], df['task_container_id']):
            feat[i] = v-result_val[user] #原来是nan 减完还是nan
        
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['feat_user_container_id_diff1'])
        
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        result_val, = tmp
        
        # last_group中存在lecture
        df = table.last_group[['user_id', 'task_container_id']].copy()
        
        df_n = df.shape[0]
        if(df_n == 0):
            return tmp
        
        tmp = df.groupby(['user_id'], sort=False)['task_container_id'].first()
        for user in tmp.index:
            result_val[user,:] = tmp[user]
               
        return [result_val,]
    

# 对该session中的container进行编号
class feat_user_this_session_container_num(Feat):
    @timeclass('feat_user_this_session_container_num')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'new_container_id', 'session']].copy()
        
        tmp = df.groupby(['user_id', 'session'], sort=False)['new_container_id'].agg(['first'])
        
        tmp.columns = ['task_container_encoding_diff']
        # pdb.set_trace()
        
        df = df.merge(tmp, how='left', on = ['user_id', 'session'])
        
        result = df.groupby(['user_id'], sort=False)['session', 'task_container_encoding_diff'].last()
        
        result.columns = ['user_last_session','user_last_session_first_container_encoding']
        
        user_last_session = {}
        user_last_session_first_container_encoding = {}
        
        
        
        user_last_session.update(result['user_last_session'])
        user_last_session_first_container_encoding.update(result['user_last_session_first_container_encoding'])
        
        
        df['task_container_encoding_diff'] = df['new_container_id']-df['task_container_encoding_diff']
        
        feat = df[['task_container_encoding_diff']]
        # pdb.set_trace()
        return feat, [user_last_session, user_last_session_first_container_encoding]
    
    
    def generate_test_feat(self, table, tmp): 
        user_last_session, user_last_session_first_container_encoding = tmp
        df = table.df_test_model[['user_id', 'new_container_id', 'session']].copy()
        
        df = df.set_index(['user_id'], drop=True)
        
        df_val = df.values
        
        df_n = df.shape[0]
        
        feat = np.zeros(df_n, dtype=int)
        
        
        
        for user, i in zip(df.index, range(df_n)):
            if user in user_last_session:
                if( df_val[i,1] == user_last_session[user] ):
                    # pdb.set_trace()
                    feat[i] = df_val[i,0]-user_last_session_first_container_encoding[user]
        
        # pdb.set_trace()
        
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['task_container_encoding_diff'])
              
        
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        user_last_session, user_last_session_first_container_encoding = tmp
       
        df = table.last_group_model[['user_id', 'new_container_id', 'session']].copy()
        
        df = df.set_index(['user_id'], drop=True)
        
        df_val = df.values
        
        df_n = df.shape[0]
        # pdb.set_trace()
        for user, i in zip(df.index, range(df_n)):
            if user in user_last_session:
                if( df_val[i,1] != user_last_session[user] ): 
                    user_last_session[user] = df_val[i,1]
                    user_last_session_first_container_encoding[user] = df_val[i,0]
            else:
                user_last_session[user] = df_val[i,1]
                user_last_session_first_container_encoding[user] = df_val[i,0]
                
        return [user_last_session, user_last_session_first_container_encoding]
    
    
class feat_user_this_session_accumulated_time(Feat):
    @timeclass('feat_user_this_session_accumulated_time')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'task_container_id', 'session', 'prior_question_elapsed_time']].copy()
        
        tmp = pd.concat([df.groupby(['user_id', 'task_container_id'], sort=False)['prior_question_elapsed_time'].agg(['first', 'size']),
                         df.groupby(['user_id', 'task_container_id'], sort=False)['session'].agg(['first'])], axis=1)
        
        tmp.columns = ['cur_question_elapsed_time', 'cur_container_size', 'session']
        
        # pdb.set_trace()
        
        
        
        tmp['cur_question_elapsed_time'] = tmp.groupby(['user_id'], sort=False)['cur_question_elapsed_time'].shift(-1)
        
        tmp['pre_container_elapsed_time_sum'] = tmp['cur_question_elapsed_time']*tmp['cur_container_size']
        
        tmp['pre_container_elapsed_time_sum'] = tmp.groupby(['user_id','session'], sort=False)['pre_container_elapsed_time_sum'].cumsum()
        
        tmp['pre_container_elapsed_time_sum'] = tmp.groupby(['user_id'], sort=False)['pre_container_elapsed_time_sum'].shift(1)
        
        # pdb.set_trace()
        
        result = tmp.groupby(['user_id'], sort=False)['cur_container_size','pre_container_elapsed_time_sum','session'].last()
        
        result_val = np.full((500000,3),np.nan)
        
        result_val[result.index,:] = result.values
        
        df = df.merge(tmp, how='left', on = ['user_id', 'task_container_id'])
        
        feat = df[['pre_container_elapsed_time_sum']]
        
        return feat, [result_val,]
    
    
    def generate_test_feat(self, table, tmp): 
        result_val, = tmp
        df = table.df_test_model[['user_id', 'session', 'prior_question_elapsed_time']].copy()
        
        tmp1 = df.groupby(['user_id'], sort=False)['session','prior_question_elapsed_time'].agg(['first'])
        
        tmp1.columns = ['session','prior_question_elapsed_time']
        
        tmp1['cur_container_size'] = result_val[tmp1.index,0]
        
        tmp1['pre_container_elapsed_time_sum'] = result_val[tmp1.index,1]
        
        tmp1['pre_container_elapsed_time_sum'] += tmp1['prior_question_elapsed_time']*tmp1['cur_container_size']
        
        for user, ss in zip(tmp1.index,tmp1['session']):
            if result_val[user,2] != ss:
                tmp1.loc[user,'pre_container_elapsed_time_sum'] = np.nan 
                result_val[user,2] = ss
        
        df = df.merge(tmp1[['pre_container_elapsed_time_sum']], how='left', on=['user_id'])
              
        feat = df[['pre_container_elapsed_time_sum']]
        
        # 这里更新
        result_val[tmp1.index,1] = tmp1['pre_container_elapsed_time_sum']
        
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        result_val, = tmp
       
        df = table.last_group_model[['user_id', 'prior_question_elapsed_time']].copy()
        
        if df.shape[0] == 0:
            return tmp
        
        tmp1 = df.groupby(['user_id'], sort=False)['prior_question_elapsed_time'].agg(['size'])
        
        tmp1.columns = ['cur_container_size']
        
        result_val[tmp1.index,0] = tmp1['cur_container_size']
        
        return [result_val,]
    
    
class feat_user_this_question_container_num_interval(Feat):
    @timeclass('feat_user_this_question_container_num_interval')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'content_id', 'task_container_id', 'new_container_id']].copy()
        
        result = df.groupby(['user_id', 'content_id'], sort=False)['new_container_id'].last()
        
        user_this_question_last_task_container_encoding = {}
        
        user_this_question_last_task_container_encoding.update(result)
        
        tmp = df.groupby(['user_id', 'content_id', 'task_container_id'], sort=False)['new_container_id'].first()
        
        tmp -= tmp.groupby(['user_id', 'content_id'], sort=False).shift(1)
        
        # drop 一下
        df.drop(columns=['new_container_id'],inplace=True)
        
        df = df.merge(tmp, how='left', on = ['user_id', 'content_id', 'task_container_id'])
        
        df = df.rename(columns={'new_container_id':'feat_user_this_question_container_num_interval'})
        
        feat = df[['feat_user_this_question_container_num_interval']]
        
        # pdb.set_trace()
        return feat, [user_this_question_last_task_container_encoding,]
    
    
    def generate_test_feat(self, table, tmp): 
        user_this_question_last_task_container_encoding, = tmp
        
        df = table.df_test_model[['user_id', 'content_id', 'new_container_id']].copy()
        
        df = df.set_index(['user_id', 'content_id'], drop=True)
        
        df_n = df.shape[0]
        
        df_val = df.values
        
        feat = np.zeros(df_n,np.float64)
        
        for i, idx in zip( range(df_n), df.index ):
            if idx in user_this_question_last_task_container_encoding:
                feat[i] = df_val[i][0]-user_this_question_last_task_container_encoding[idx]
            else:
                feat[i] = np.nan
        # pdb.set_trace()
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['feat_user_this_question_container_num_interval'])
              
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        user_this_question_last_task_container_encoding, = tmp
       
        df = table.last_group_model[['user_id', 'content_id', 'new_container_id']].copy()
        
        df = df.set_index(['user_id','content_id'], drop=True)
        
        df_val = df.values
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        # pdb.set_trace()
        for i, idx in zip(range(df_n), df.index):
            user_this_question_last_task_container_encoding[idx] = df_val[i][0]
                
        return [user_this_question_last_task_container_encoding,]
    
class feat_user_this_part_question_container_num_interval(Feat):
    @timeclass('feat_user_this_part_question_container_num_interval')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'part', 'task_container_id', 'new_container_id']].copy()
        
        result = df.groupby(['user_id', 'part'], sort=False)['new_container_id'].last()
        
        user_this_part_question_last_task_container_encoding = {}
        
        user_this_part_question_last_task_container_encoding.update(result)
        
        tmp = df.groupby(['user_id', 'part', 'task_container_id'], sort=False)['new_container_id'].first()
        
        tmp -= tmp.groupby(['user_id', 'part'], sort=False).shift(1)
        
        # drop 一下
        df.drop(columns=['new_container_id'],inplace=True)
        
        df = df.merge(tmp, how='left', on = ['user_id', 'part', 'task_container_id'])
        
        df = df.rename(columns={'new_container_id':'feat_user_this_part_question_container_num_interval'})
        
        feat = df[['feat_user_this_part_question_container_num_interval']]
        
        # pdb.set_trace()
        return feat, [user_this_part_question_last_task_container_encoding,]
    
    
    def generate_test_feat(self, table, tmp): 
        user_this_part_question_last_task_container_encoding, = tmp
        
        df = table.df_test_model[['user_id', 'part', 'new_container_id']].copy()
        
        df = df.set_index(['user_id', 'part'], drop=True)
        
        df_n = df.shape[0]
        
        df_val = df.values
        
        feat = np.zeros(df_n,np.float64)
        
        for i, idx in zip( range(df_n), df.index ):
            if idx in user_this_part_question_last_task_container_encoding:
                feat[i] = df_val[i][0]-user_this_part_question_last_task_container_encoding[idx]
            else:
                feat[i] = np.nan
        # pdb.set_trace()
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['feat_user_this_part_question_container_num_interval'])
              
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        user_this_part_question_last_task_container_encoding, = tmp
       
        df = table.last_group_model[['user_id', 'part', 'new_container_id']].copy()
        
        df = df.set_index(['user_id','part'], drop=True)
        
        df_val = df.values
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        # pdb.set_trace()
        for i, idx in zip(range(df_n), df.index):
            user_this_part_question_last_task_container_encoding[idx] = df_val[i][0]
                
        return [user_this_part_question_last_task_container_encoding,]
    
class feat_user_this_feat_question_tags_encoding_question_container_num_interval(Feat):
    @timeclass('feat_user_this_feat_question_tags_encoding_question_container_num_interval')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'feat_question_tags_encoding', 'task_container_id', 'new_container_id']].copy()
        
        result = df.groupby(['user_id', 'feat_question_tags_encoding'], sort=False)['new_container_id'].last()
        
        user_this_feat_question_tags_encoding_question_last_task_container_encoding = {}
        
        user_this_feat_question_tags_encoding_question_last_task_container_encoding.update(result)
        
        tmp = df.groupby(['user_id', 'feat_question_tags_encoding', 'task_container_id'], sort=False)['new_container_id'].first()
        
        tmp -= tmp.groupby(['user_id', 'feat_question_tags_encoding'], sort=False).shift(1)
        
        # drop 一下
        df.drop(columns=['new_container_id'],inplace=True)
        
        df = df.merge(tmp, how='left', on = ['user_id', 'feat_question_tags_encoding', 'task_container_id'])
        
        df = df.rename(columns={'new_container_id':'feat_user_this_feat_question_tags_encoding_question_container_num_interval'})
        
        feat = df[['feat_user_this_feat_question_tags_encoding_question_container_num_interval']]
        
        # pdb.set_trace()
        return feat, [user_this_feat_question_tags_encoding_question_last_task_container_encoding,]
    
    
    def generate_test_feat(self, table, tmp): 
        user_this_feat_question_tags_encoding_question_last_task_container_encoding, = tmp
        
        df = table.df_test_model[['user_id', 'feat_question_tags_encoding', 'new_container_id']].copy()
        
        df = df.set_index(['user_id', 'feat_question_tags_encoding'], drop=True)
        
        df_n = df.shape[0]
        
        df_val = df.values
        
        feat = np.zeros(df_n,np.float64)
        
        for i, idx in zip( range(df_n), df.index ):
            if idx in user_this_feat_question_tags_encoding_question_last_task_container_encoding:
                feat[i] = df_val[i][0]-user_this_feat_question_tags_encoding_question_last_task_container_encoding[idx]
            else:
                feat[i] = np.nan
        # pdb.set_trace()
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['feat_user_this_feat_question_tags_encoding_question_container_num_interval'])
              
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        user_this_feat_question_tags_encoding_question_last_task_container_encoding, = tmp
       
        df = table.last_group_model[['user_id', 'feat_question_tags_encoding', 'new_container_id']].copy()
        
        df = df.set_index(['user_id','feat_question_tags_encoding'], drop=True)
        
        df_val = df.values
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        # pdb.set_trace()
        for i, idx in zip(range(df_n), df.index):
            user_this_feat_question_tags_encoding_question_last_task_container_encoding[idx] = df_val[i][0]
                
        return [user_this_feat_question_tags_encoding_question_last_task_container_encoding,]
    


class feat_new_content_id(Feat):
    @timeclass('feat_new_content_id')
    def generate_feat(self,table):
        df = table.df[['user_id','task_container_id', 'content_id', 'content_type_id']].copy()
        
        df['new_content_id'] = df.groupby('user_id',sort=False).cumcount()
        
        
        df = df[df['content_type_id']==0]
        
        feat = df[['new_content_id']]
        feat.index = table.df_model.index
        
        result = df.groupby(['user_id'], sort=False)[['new_content_id']].last()
        
        # result = tmp.reset_index().groupby('user_id',sort=False)[['new_container_id']].last()
        result += 1
        
        result_val = np.zeros((500000,1),dtype=np.int)
        result_val[result.index,:] = result.values
        # pdb.set_trace()
        return feat,[result_val]
    
    
    # @timeclass('feat_new_container_id')
    def generate_test_feat(self,table,tmp):
        result_val, = tmp
        
        df = table.df_test[['user_id', 'content_id', 'content_type_id']].copy()
        
        df['new_content_id'] = result_val[df['user_id'],:]
        
        df['new_content_id'] += df.groupby(['user_id'], sort=False).cumcount()
        
        df = df[df['content_type_id']==0]
        
        df.index = table.df_test_model.index
        
        feat = df[['new_content_id']]
        
        return feat

    # @timeclass('feat_new_container_id')
    def update_intermediate_feat(self,table,tmp):
        result_val, = tmp
        df = table.last_group[['user_id', 'content_id']].copy()
        tmp1 = df.groupby(['user_id'], sort=False).size()
        
        for user in tmp1.index: 
            result_val[user,:] += tmp1[user]
        
        return [result_val]
    

    
class feat_new_content_id(Feat):
    @timeclass('feat_new_content_id')
    def generate_feat(self,table):
        df = table.df[['user_id','task_container_id', 'content_id', 'content_type_id']].copy()
        
        df['new_content_id'] = df.groupby('user_id',sort=False).cumcount()
        
        
        df = df[df['content_type_id']==0]
        
        feat = df[['new_content_id']]
        feat.index = table.df_model.index
        
        result = df.groupby(['user_id'], sort=False)[['new_content_id']].last()
        
        # result = tmp.reset_index().groupby('user_id',sort=False)[['new_container_id']].last()
        result += 1
        
        result_val = np.zeros((500000,1),dtype=np.int)
        result_val[result.index,:] = result.values
        # pdb.set_trace()
        return feat,[result_val]
    
    
    # @timeclass('feat_new_container_id')
    def generate_test_feat(self,table,tmp):
        result_val, = tmp
        
        df = table.df_test[['user_id', 'content_id', 'content_type_id']].copy()
        
        df['new_content_id'] = result_val[df['user_id'],:]
        
        df['new_content_id'] += df.groupby(['user_id'], sort=False).cumcount()
        
        df = df[df['content_type_id']==0]
        
        df.index = table.df_test_model.index
        
        feat = df[['new_content_id']]
        
        return feat

    # @timeclass('feat_new_container_id')
    def update_intermediate_feat(self,table,tmp):
        result_val, = tmp
        df = table.last_group[['user_id', 'content_id']].copy()
        tmp1 = df.groupby(['user_id'], sort=False).size()
        
        for user in tmp1.index: 
            result_val[user,:] += tmp1[user]
        
        return [result_val]

    
class feat_user_this_session_question_order_number(Feat):
    @timeclass('feat_user_this_session_question_order_number')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'new_content_id', 'session']].copy()
        
        tmp = df.groupby(['user_id', 'session'], sort=False)['new_content_id'].agg(['first'])
        
        tmp.columns = ['question_diff']
        # pdb.set_trace()
        
        df = df.merge(tmp, how='left', on = ['user_id', 'session'])
        
        result = df.groupby(['user_id'], sort=False)['session', 'question_diff'].last()
        
        result.columns = ['user_last_session','user_last_session_first_question_new_content_id']
        
        user_last_session = {}
        user_last_session_first_question_new_content_id = {}
        
        
        
        user_last_session.update(result['user_last_session'])
        user_last_session_first_question_new_content_id.update(result['user_last_session_first_question_new_content_id'])
        
        
        df['question_diff'] = df['new_content_id']-df['question_diff']
        
        feat = df[['question_diff']]
        # pdb.set_trace()
        return feat, [user_last_session, user_last_session_first_question_new_content_id]
    
    
    def generate_test_feat(self, table, tmp): 
        user_last_session, user_last_session_first_question_new_content_id = tmp
        df = table.df_test_model[['user_id', 'new_content_id', 'session']].copy()
        
        df = df.set_index(['user_id'], drop=True)
        
        df_val = df.values
        
        df_n = df.shape[0]
        
        feat = np.zeros(df_n, dtype=int)
        
        
        
        for user, i in zip(df.index, range(df_n)):
            if user in user_last_session:
                if( df_val[i,1] == user_last_session[user] ):
                    # pdb.set_trace()
                    feat[i] = df_val[i,0]-user_last_session_first_question_new_content_id[user]
        
        # pdb.set_trace()
        
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['question_diff'])
              
        
        return feat
    
    
    def update_intermediate_feat(self, table, tmp):
        user_last_session, user_last_session_first_question_new_content_id = tmp
       
        df = table.last_group_model[['user_id', 'new_content_id', 'session']].copy()
        
        if df.shape[0] == 0:
            return tmp
        # pdb.set_trace()
        
        tmp1 = df.groupby(['user_id'], sort=False).agg(['first'])
        # pdb.set_trace()
        tmp1.columns = ['new_content_id', 'session']
        tmp1_val = tmp1.values
        tmp1_n = tmp1.shape[0]
        
        
        for user, i in zip(tmp1.index, range(tmp1_n)):
            if user in user_last_session:
                if( tmp1_val[i,1] != user_last_session[user] ): 
                    user_last_session[user] = tmp1_val[i,1]
                    user_last_session_first_question_new_content_id[user] = tmp1_val[i,0]
            else:
                user_last_session[user] = tmp1_val[i,1]
                user_last_session_first_question_new_content_id[user] = tmp1_val[i,0]
                
        return [user_last_session, user_last_session_first_question_new_content_id]
    
class feat_user_this_question_question_num_interval(Feat):
    @timeclass('feat_user_this_question_question_num_interval')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'content_id', 'task_container_id', 'new_content_id']].copy()
        
        result = df.groupby(['user_id', 'content_id'], sort=False)['new_content_id'].last()
        
        user_this_question_last_new_content_id = {}
        
        user_this_question_last_new_content_id.update(result)
        
        tmp = df.groupby(['user_id', 'content_id', 'task_container_id'], sort=False)['new_content_id'].first()
        
        tmp -= tmp.groupby(['user_id', 'content_id'], sort=False).shift(1)
        
        # drop 一下
        df.drop(columns=['new_content_id'],inplace=True)
        
        df = df.merge(tmp, how='left', on = ['user_id', 'content_id', 'task_container_id'])
        
        df = df.rename(columns={'new_content_id':'feat_user_this_question_question_num_interval'})
        
        feat = df[['feat_user_this_question_question_num_interval']]
        
        # pdb.set_trace()
        return feat, [user_this_question_last_new_content_id,]
    
    
    def generate_test_feat(self, table, tmp): 
        user_this_question_last_new_content_id, = tmp
        
        df = table.df_test_model[['user_id', 'content_id', 'new_content_id']].copy()
        
        df = df.set_index(['user_id', 'content_id'], drop=True)
        
        df_n = df.shape[0]
        
        df_val = df.values
        
        feat = np.zeros(df_n,np.float64)
        
        for i, idx in zip( range(df_n), df.index ):
            if idx in user_this_question_last_new_content_id:
                feat[i] = df_val[i][0]-user_this_question_last_new_content_id[idx]
            else:
                feat[i] = np.nan
        # pdb.set_trace()
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['feat_user_this_question_question_num_interval'])
              
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        user_this_question_last_new_content_id, = tmp
       
        df = table.last_group_model[['user_id', 'content_id', 'new_container_id']].copy()
        
        df = df.set_index(['user_id','content_id'], drop=True)
        
        df_val = df.values
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        # pdb.set_trace()
        for i, idx in zip(range(df_n), df.index):
            user_this_question_last_new_content_id[idx] = df_val[i][0]
                
        return [user_this_question_last_new_content_id,]
    
class feat_user_this_part_question_question_num_interval(Feat):
    @timeclass('feat_user_this_part_question_question_num_interval')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'part', 'task_container_id', 'new_container_id']].copy()
        
        result = df.groupby(['user_id', 'part'], sort=False)['new_container_id'].last()
        
        user_this_part_question_last_new_container_id = {}
        
        user_this_part_question_last_new_container_id.update(result)
        
        tmp = df.groupby(['user_id', 'part', 'task_container_id'], sort=False)['new_container_id'].first()
        
        tmp -= tmp.groupby(['user_id', 'part'], sort=False).shift(1)
        
        # drop 一下
        df.drop(columns=['new_container_id'],inplace=True)
        
        df = df.merge(tmp, how='left', on = ['user_id', 'part', 'task_container_id'])
        
        df = df.rename(columns={'new_container_id':'feat_user_this_part_question_question_num_interval'})
        
        feat = df[['feat_user_this_part_question_question_num_interval']]
        
        # pdb.set_trace()
        return feat, [user_this_part_question_last_new_container_id,]
    
    
    def generate_test_feat(self, table, tmp): 
        user_this_part_question_last_new_container_id, = tmp
        
        df = table.df_test_model[['user_id', 'part', 'new_content_id']].copy()
        
        df = df.set_index(['user_id', 'part'], drop=True)
        
        df_n = df.shape[0]
        
        df_val = df.values
        
        feat = np.zeros(df_n,np.float64)
        
        for i, idx in zip( range(df_n), df.index ):
            if idx in user_this_part_question_last_new_container_id:
                feat[i] = df_val[i][0]-user_this_part_question_last_new_container_id[idx]
            else:
                feat[i] = np.nan
        # pdb.set_trace()
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['feat_user_this_part_question_question_num_interval'])
              
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        user_this_part_question_last_new_container_id, = tmp
       
        df = table.last_group_model[['user_id', 'part', 'new_container_id']].copy()
        
        df = df.set_index(['user_id','part'], drop=True)
        
        df_val = df.values
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        # pdb.set_trace()
        for i, idx in zip(range(df_n), df.index):
            user_this_part_question_last_new_container_id[idx] = df_val[i][0]
                
        return [user_this_part_question_last_new_container_id,]
    
    
class feat_user_last_container_elapsed_time_sum(Feat):
    @timeclass('feat_user_last_container_elapsed_time_sum')
    def generate_feat(self, table):
        # pdb.set_trace()
        df = table.df_model[['user_id', 'task_container_id', 'prior_question_elapsed_time']].copy()
        
        tmp = df.groupby(['user_id', 'task_container_id'], sort=False)['prior_question_elapsed_time'].agg(['first','size'])
        
        
        tmp.columns = ['prior_question_elapsed_time', 'prior_question_num']
        
        result = tmp.reset_index().groupby('user_id',sort=False)['prior_question_num'].agg(['last'])
        
        result_val = np.full((500000,1),np.nan)
        
        result_val[result.index,:] = result.values
        
        tmp['prior_question_num'] = tmp.groupby(['user_id'], sort=False)['prior_question_num'].shift(1)
        
        tmp['prior_container_elapsed_time_sum'] = tmp['prior_question_elapsed_time']*tmp['prior_question_num']
        
        df = df.merge(tmp[['prior_container_elapsed_time_sum']], how='left', on=['user_id', 'task_container_id'])
        
        
        feat = df[['prior_container_elapsed_time_sum']]
        
        return feat, [result_val,]
    
    
    def generate_test_feat(self, table, tmp): 
        result_val, = tmp
        
        df = table.df_test_model[['user_id', 'prior_question_elapsed_time']].copy()
        
        tmp1 = df.groupby(['user_id'], sort=False)['prior_question_elapsed_time'].agg(['first'])
        
        tmp1.columns = ['prior_container_elapsed_time_sum']
        
        tmp1['prior_question_num'] = result_val[tmp1.index,:]
        
        tmp1['prior_container_elapsed_time_sum'] *= tmp1['prior_question_num']
        
        df = df.merge(tmp1, how='left', on='user_id')
        
        feat = df[['prior_container_elapsed_time_sum']]
        
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        result_val, = tmp
       
        df = table.last_group_model[['user_id', 'prior_question_elapsed_time']].copy()
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        
        tmp1 = df.groupby(['user_id'], sort=False).size()
        # pdb.set_trace()
        for user in tmp1.index:
            result_val[user,:] = tmp1[user]
                
        return [result_val,]
    
class feat_user_this_session_container_id_diff1(Feat):
    @timeclass('feat_user_this_session_container_id_diff1')
    def generate_feat(self, table):
        
        # 只对 qusetion 做了 session，这里做diff也只能做question的
        df = table.df_model[['user_id', 'task_container_id', 'timestamp', 'session']].copy()
        
        tmp = df.groupby(['user_id', 'session', 'timestamp'], sort=False)['task_container_id'].agg(['first'])
        
        tmp.columns = ['task_container_id']
        # pdb.set_trace()
        
        # session 递增，记录最后一个即可
        result = tmp.reset_index().groupby(['user_id'],sort=False)['task_container_id','session'].agg(['last'])
        
        result_val = np.full((500000,2),np.nan)
        
        result_val[result.index,:] = result.values
        
        tmp.columns = ['feat_user_this_session_container_id_diff1']
        
        # pdb.set_trace()
        
        tmp -= tmp.groupby(['user_id', 'session'], sort=False).shift(1)
        
        df = df.merge(tmp, how='left', on=['user_id', 'session', 'timestamp'])
        
        
        df.index = table.df_model.index
        
        feat = df[['feat_user_this_session_container_id_diff1']]
        
        return feat, [result_val,]
    
    
    def generate_test_feat(self, table, tmp): 
        result_val, = tmp
        
        df = table.df_test_model[['user_id', 'task_container_id', 'session']].copy()
        
        
        df_n = df.shape[0]
        
        feat = np.full(df_n, np.nan)
        
        for i,user,v,sn in zip(range(df_n), df['user_id'], df['task_container_id'], df['session']):
            if result_val[user][1] == sn:
                feat[i] = v-result_val[user][0] #原来是nan 减完还是nan
        
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['feat_user_this_session_container_id_diff1'])
        
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        result_val, = tmp
       
        df = table.last_group_model[['user_id', 'task_container_id', 'session']].copy()
        
        df_n = df.shape[0]
        if df_n == 0:
            return tmp
        
        tmp1 = df.groupby(['user_id'], sort=False)['task_container_id', 'session'].first()
        tmp1.columns = ['task_container_id', 'session']
        
        # pdb.set_trace()
        for user in tmp1.index:
            result_val[user,:] = tmp1.loc[user]
                 
        return [result_val,]
    
class feat_user_this_question_session_num_interval(Feat):
    @timeclass('feat_user_this_question_session_num_interval')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'content_id', 'task_container_id', 'session']].copy()
        
        result = df.groupby(['user_id', 'content_id'], sort=False)['session'].last()
        
        user_this_question_last_session = {}
        
        user_this_question_last_session.update(result)
        
        tmp = df.groupby(['user_id', 'content_id', 'task_container_id'], sort=False)['session'].first()
        
        tmp -= tmp.groupby(['user_id', 'content_id'], sort=False).shift(1)
        
        # drop 一下
        df.drop(columns=['session'],inplace=True)
        
        df = df.merge(tmp, how='left', on = ['user_id', 'content_id', 'task_container_id'])
        
        df = df.rename(columns={'session':'feat_user_this_question_session_num_interval'})
        
        feat = df[['feat_user_this_question_session_num_interval']]
        
        # pdb.set_trace()
        return feat, [user_this_question_last_session,]
    
    
    def generate_test_feat(self, table, tmp): 
        user_this_question_last_session, = tmp
        
        df = table.df_test_model[['user_id', 'content_id', 'session']].copy()
        
        df = df.set_index(['user_id', 'content_id'], drop=True)
        
        df_n = df.shape[0]
        
        df_val = df.values
        
        feat = np.zeros(df_n,np.float64)
        
        for i, idx in zip( range(df_n), df.index ):
            if idx in user_this_question_last_session:
                feat[i] = df_val[i][0]-user_this_question_last_session[idx]
            else:
                feat[i] = np.nan
        # pdb.set_trace()
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['feat_user_this_question_session_num_interval'])
              
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        user_this_question_last_session, = tmp
       
        df = table.last_group_model[['user_id', 'content_id', 'session']].copy()
        
        df = df.set_index(['user_id','content_id'], drop=True)
        
        df_val = df.values
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        # pdb.set_trace()
        for i, idx in zip(range(df_n), df.index):
            user_this_question_last_session[idx] = df_val[i][0]
                
        return [user_this_question_last_session,]
    
class feat_user_this_part_question_session_num_interval(Feat):
    @timeclass('feat_user_this_part_question_session_num_interval')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'part', 'task_container_id', 'session']].copy()
        
        result = df.groupby(['user_id', 'part'], sort=False)['session'].last()
        
        user_this_part_question_last_session = {}
        
        user_this_part_question_last_session.update(result)
        
        tmp = df.groupby(['user_id', 'part', 'task_container_id'], sort=False)['session'].first()
        
        tmp -= tmp.groupby(['user_id', 'part'], sort=False).shift(1)
        
        # drop 一下
        df.drop(columns=['session'],inplace=True)
        
        df = df.merge(tmp, how='left', on = ['user_id', 'part', 'task_container_id'])
        
        df = df.rename(columns={'session':'feat_user_this_part_question_session_num_interval'})
        
        feat = df[['feat_user_this_part_question_session_num_interval']]
        
        # pdb.set_trace()
        return feat, [user_this_part_question_last_session,]
    
    
    def generate_test_feat(self, table, tmp): 
        user_this_part_question_last_session, = tmp
        
        df = table.df_test_model[['user_id', 'part', 'session']].copy()
        
        df = df.set_index(['user_id', 'part'], drop=True)
        
        df_n = df.shape[0]
        
        df_val = df.values
        
        feat = np.zeros(df_n,np.float64)
        
        for i, idx in zip( range(df_n), df.index ):
            if idx in user_this_part_question_last_session:
                feat[i] = df_val[i][0]-user_this_part_question_last_session[idx]
            else:
                feat[i] = np.nan
        # pdb.set_trace()
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['feat_user_this_part_question_session_num_interval'])
              
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        user_this_part_question_last_session, = tmp
       
        df = table.last_group_model[['user_id', 'part', 'session']].copy()
        
        df = df.set_index(['user_id','part'], drop=True)
        
        df_val = df.values
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        # pdb.set_trace()
        for i, idx in zip(range(df_n), df.index):
            user_this_part_question_last_session[idx] = df_val[i][0]
                
        return [user_this_part_question_last_session,]
    
class feat_user_this_feat_question_tags_encoding_question_session_num_interval(Feat):
    @timeclass('feat_user_this_feat_question_tags_encoding_question_session_num_interval')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'feat_question_tags_encoding', 'task_container_id', 'session']].copy()
        
        result = df.groupby(['user_id', 'feat_question_tags_encoding'], sort=False)['session'].last()
        
        user_this_feat_question_tags_encoding_question_last_session = {}
        
        user_this_feat_question_tags_encoding_question_last_session.update(result)
        
        tmp = df.groupby(['user_id', 'feat_question_tags_encoding', 'task_container_id'], sort=False)['session'].first()
        
        tmp -= tmp.groupby(['user_id', 'feat_question_tags_encoding'], sort=False).shift(1)
        
        # drop 一下
        df.drop(columns=['session'],inplace=True)
        
        df = df.merge(tmp, how='left', on = ['user_id', 'feat_question_tags_encoding', 'task_container_id'])
        
        df = df.rename(columns={'session':'feat_user_this_feat_question_tags_encoding_question_session_num_interval'})
        
        feat = df[['feat_user_this_feat_question_tags_encoding_question_session_num_interval']]
        
        # pdb.set_trace()
        return feat, [user_this_feat_question_tags_encoding_question_last_session,]
    
    
    def generate_test_feat(self, table, tmp): 
        user_this_feat_question_tags_encoding_question_last_session, = tmp
        
        df = table.df_test_model[['user_id', 'feat_question_tags_encoding', 'session']].copy()
        
        df = df.set_index(['user_id', 'feat_question_tags_encoding'], drop=True)
        
        df_n = df.shape[0]
        
        df_val = df.values
        
        feat = np.zeros(df_n,np.float64)
        
        for i, idx in zip( range(df_n), df.index ):
            if idx in user_this_feat_question_tags_encoding_question_last_session:
                feat[i] = df_val[i][0]-user_this_feat_question_tags_encoding_question_last_session[idx]
            else:
                feat[i] = np.nan
        # pdb.set_trace()
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['feat_user_this_feat_question_tags_encoding_question_session_num_interval'])
              
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        user_this_feat_question_tags_encoding_question_last_session, = tmp
       
        df = table.last_group_model[['user_id', 'feat_question_tags_encoding', 'session']].copy()
        
        df = df.set_index(['user_id','feat_question_tags_encoding'], drop=True)
        
        df_val = df.values
        
        df_n = df.shape[0]
        
        if df_n == 0:
            return tmp
        # pdb.set_trace()
        for i, idx in zip(range(df_n), df.index):
            user_this_feat_question_tags_encoding_question_last_session[idx] = df_val[i][0]
                
        return [user_this_feat_question_tags_encoding_question_last_session,]
    


class feat_user_container_id_max(Feat):
    @timeclass('feat_user_container_id_max')
    def generate_feat(self, table):
        df = table.df[['user_id', 'task_container_id', 'timestamp']].copy()
        
        tmp = df.groupby(['user_id','timestamp'], sort=False)['task_container_id'].agg(['first'])
        
        tmp.columns = ['task_container_id']
        
        result = tmp.reset_index().groupby('user_id',sort=False)['task_container_id'].agg(['max'])
        
        result_val = np.full((500000,1),np.nan)
        
        result_val[result.index,:] = result.values
        
        tmp.columns = ['feat_user_container_id_max']
        
        tmp = tmp.reset_index()
        
        tmp['feat_user_container_id_max'] = tmp['feat_user_container_id_max'].astype(np.float64)
        
        tmp_val = tmp.values
        
        tmp_n = tmp.shape[0]
        
        user, mx = -1, -1.0
        
        # pdb.set_trace()
        
        for i in range(tmp_n):
            if tmp_val[i,0] == user:
                tp = tmp_val[i,2]
                tmp_val[i,2] =  mx
                if mx < tp:
                    mx = tp
            else:
                user = tmp_val[i,0]
                mx = tmp_val[i,2]
                tmp_val[i,2] =  np.nan
            
        tmp['feat_user_container_id_max'] = tmp_val[:,2]
        
        df = table.df_model[['user_id', 'task_container_id' ,'timestamp']].copy()
        
        df = df.merge(tmp, how='left', on=['user_id', 'timestamp'])
        
        feat = df[['feat_user_container_id_max']]
        
        # pdb.set_trace()
        
        return feat,[result_val]
    
    
    def generate_test_feat(self, table, tmp): 
        result_val, = tmp
        
        df = table.df_test_model[['user_id', 'task_container_id']].copy()
        
        
        df_n = df.shape[0]
        
        feat = np.full(df_n, np.nan)
        
        for i,user,v in zip(range(df_n), df['user_id'], df['task_container_id']):
            feat[i] = v-result_val[user] #原来是nan 减完还是nan
        
        feat = pd.DataFrame(feat, index=table.df_test_model.index, columns = ['feat_user_container_id_max'])
        
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        result_val, = tmp
        
        # last_group中存在lecture
        df = table.last_group[['user_id', 'task_container_id']].copy()
        
        tmp = df.groupby(['user_id'], sort=False)['task_container_id'].first()
        for user in tmp.index:
            tp = result_val[user,0]
            if tp == np.nan:
                result_val[user,:] = tmp[user]
            elif(tp < tmp[user]):
                result_val[user,:] = tmp[user]
                
               
        return [result_val,]
    


class feat_last_container_part_question_num_and_correct(Feat):
    @timeclass('feat_last_container_part_question_num_and_correct')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'task_container_id', 'part', 'label']].copy()
        
        tmp = pd.concat([df.groupby(['user_id','task_container_id'], sort=False)['part'].agg(['first']), 
                         df.groupby(['user_id','task_container_id'], sort=False)['label'].agg(['sum', 'size'])], axis=1)
        
        
        tmp.columns = ['part', 'last_this_part_correct_quesion_num', 'last_this_part_question_sum']
        
        result = tmp.groupby(['user_id', 'part'], sort=False).last().astype(np.uint64).reset_index()
        
        result.index = result['user_id'].astype(np.int64)*7+result['part']
        
        result.drop(columns=['user_id','part'],inplace=True)
        
        intermediate_feat = {}
        
        
        
        tmp = tmp.groupby(['user_id', 'part'], sort=False)['last_this_part_correct_quesion_num', 'last_this_part_question_sum'].shift(1) # 这个地方是nan还是0好，试一下
        
        
        df = df.merge(tmp, how='left', on = ['user_id', 'task_container_id'])
        
        feat = df[['last_this_part_correct_quesion_num', 'last_this_part_question_sum']]
        
        feat['last_this_part_correct_quesion_rate'] = feat['last_this_part_correct_quesion_num']/feat['last_this_part_question_sum']
        
        return feat,[result,intermediate_feat,]
    
    
    def generate_test_feat(self, table, tmp): 
        result, intermediate_feat = tmp
        
        df = table.df_test_model[['user_id', 'part']].copy()
        
        index = df['user_id'].astype(np.int64)*7+df['part'] 
        
        df_n = df.shape[0]
        
        feat = np.full((df_n,2),np.nan)
        
        for idx,i in zip(index,range(df_n)):
            if idx in result.index:
                feat[i,:] = result.loc[idx]
            elif idx in intermediate_feat:
                feat[i,:] = intermediate_feat[idx]
                
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['last_this_part_correct_quesion_num', 'last_this_part_question_sum'])
        
        feat['last_this_part_correct_quesion_rate'] = feat['last_this_part_correct_quesion_num']/feat['last_this_part_question_sum']
        
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        result, intermediate_feat = tmp
        
        df = table.last_group_model[['user_id', 'part', 'label']].copy()
        
        tmp1 = df.groupby(['user_id', 'part'], sort=False)['label'].agg(['sum', 'size'])
        
        tmp1 = tmp1.reset_index()
        
        tmp1.index = tmp1['user_id'].astype(np.int64)*7+tmp1['part'] 
        
        tmp1.drop(columns=['user_id','part'],inplace=True)
        
        # pdb.set_trace()
        
        tmp1_n = tmp1.shape[0]

        if tmp1_n == 0:
            return tmp
        
        tmp1_val = tmp1.values
        
        for idx, i in zip(tmp1.index, range(tmp1_n)):
            if idx in result.index:
                result.loc[idx] += tmp1_val[i,:]
            elif idx in intermediate_feat:
                intermediate_feat[idx] += tmp1_val[i,:]
            else:
                intermediate_feat[idx] = tmp1_val[i,:]
        
        return [result,intermediate_feat,]


class feat_this_session_part_question_num_and_correct(Feat):
    @timeclass('feat_this_session_part_question_num_and_correct')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'task_container_id', 'part', 'session', 'label']].copy()
        
        tmp = pd.concat([df.groupby(['user_id','task_container_id'], sort=False)['part', 'session'].agg(['first']), 
                         df.groupby(['user_id','task_container_id'], sort=False)['label'].agg(['sum', 'size'])], axis=1)
        
        
        tmp.columns = ['part', 'session', 'this_session_part_correct_quesion_num', 'this_session_part_question_sum']
        
        result = tmp.groupby(['user_id', 'part'], sort=False).last().astype(np.uint64).reset_index()
        
        result.index = result['user_id'].astype(np.int64)*7+result['part']
        
        result.drop(columns=['user_id','part'],inplace=True)
        
        # pdb.set_trace()
        
        intermediate_feat = {}
        
        # pdb.set_trace()
        
        tmp[['this_session_part_correct_quesion_num', 'this_session_part_question_sum']]  = tmp.groupby(['user_id', 'part'], sort=False)['this_session_part_correct_quesion_num', 'this_session_part_question_sum'].cumsum() # 这个地方是nan还是0好，试一下
        
        tmp = tmp.groupby(['user_id', 'part'], sort=False)['this_session_part_correct_quesion_num', 'this_session_part_question_sum'].shift(1)
        
        
        df = df.merge(tmp, how='left', on = ['user_id', 'task_container_id'])
        
        feat = df[['this_session_part_correct_quesion_num', 'this_session_part_question_sum']]
        
        # feat['this_session_part_correct_quesion_rate'] = feat['this_session_part_correct_quesion_num']/feat['this_session_part_question_sum']
        
        return feat,[result,intermediate_feat,]
    
    
    def generate_test_feat(self, table, tmp): 
        result, intermediate_feat = tmp
        
        df = table.df_test_model[['user_id', 'part', 'session']].copy()
        
        df.index = df['user_id'].astype(np.int64)*7+df['part'] 
        
        df_n = df.shape[0]
        
        feat = np.full((df_n,2),np.nan)
        
        for idx,i,ss in zip(df.index,range(df_n),df['session']):
            if idx in result.index:
                if result.loc[idx].values[0] == ss:
                    feat[i,:] = result.loc[idx].values[1:3]
            elif idx in intermediate_feat:
                if intermediate_feat[idx][0] == ss:
                    feat[i,:] = intermediate_feat[idx][1:3]
                
        
        feat = pd.DataFrame(feat,index=table.df_test_model.index,columns=['this_session_part_correct_quesion_num', 'this_session_part_question_sum'])
        
        # feat['this_session_part_correct_quesion_rate'] = feat['this_session_part_correct_quesion_num']/feat['this_session_part_question_sum']
        
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        result, intermediate_feat = tmp
        
        df = table.last_group_model[['user_id', 'part', 'session', 'label']].copy()
        
        tmp1 = pd.concat( [df.groupby(['user_id', 'part'], sort=False)['session'].agg(['first']),
                           df.groupby(['user_id', 'part'], sort=False)['label'].agg(['sum', 'size'])], axis=1)
                         
        
        tmp1 = tmp1.reset_index()
        
        tmp1.index = tmp1['user_id'].astype(np.int64)*7+tmp1['part'] 
        
        tmp1.drop(columns=['user_id','part'],inplace=True)
        
        # pdb.set_trace()
        
        tmp1_n = tmp1.shape[0]

        if tmp1_n == 0:
            return tmp
        
        tmp1_val = tmp1.values
        
        for idx,i in zip(df.index,range(tmp1_n)):
            if idx in result.index:
                if result.loc[idx].values[0] == tmp1_val[i,0]:
                    val = result.loc[idx].values
                    val[0] = tmp1_val[i,0]
                    val[1] += tmp1_val[i,1]
                    val[2] += tmp1_val[i,2]
                    result.loc[idx] = val
                else:
                    result.loc[idx] = tmp1_val[i,:]
            elif idx in intermediate_feat:
                if intermediate_feat[idx][0] == tmp1_val[i,0]:
                    intermediate_feat[idx][1] += tmp1_val[i,1]
                    intermediate_feat[idx][2] += tmp1_val[i,2]
                else:
                    intermediate_feat[idx] = tmp1_val[i,:]
            else:
                intermediate_feat[idx] = tmp1_val[i,:]
        
        return [result,intermediate_feat,]




class feat_every_session_loop_group_question_corroct_rate(Feat):
    @timeclass('feat_every_session_loop_group_question_corroct_rate')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'content_id', 'session', 'label']].copy()
        
        df.loc[df['session']>9,'session'] = 9
        
        user_n = df['user_id'].nunique()
        k = 5
        smoothly_n = 20
        
        np.random.seed(seed)
        rand_group = np.random.randint(0,k,user_n)
        
        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))
        
        
        columns = [f'feat_loop_group_session_question_{col}' for col in ['num','correct_num','corroct_rate']]
        
        tmp_list = []
        for i in range(k):
            tmp_a = df.loc[df['group']!=i].groupby(['content_id','session'])['label'].agg(['count','sum']).astype('int')
            tmp_a['mean'] = tmp_a['sum']/(tmp_a['count']+smoothly_n)
            
            tmp_a.columns = columns
            
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i
            tmp_list.append(tmp_a)
        
        # pdb.set_trace()
        
        # 纵向连接
        tmp = pd.concat(tmp_list,axis=0)
        
        df = df.merge(tmp,how='left',on=['group','content_id','session'])
        
        df.index = table.df_model.index
        
        feat = df[columns]
        
        result = tmp.groupby(['session','content_id'])[columns].mean()
        result['feat_loop_group_session_question_num'] = result['feat_loop_group_session_question_num'].round().astype('int')
        result['feat_loop_group_session_question_correct_num'] = result['feat_loop_group_session_question_correct_num'].round().astype('int')
        
        return feat,[result]
    
    
    def generate_test_feat(self, table, tmp): 
        result, = tmp
        
        columns = [f'feat_loop_group_session_question_{col}' for col in ['num','correct_num','corroct_rate']]
        
        df = table.df_test_model[['session', 'content_id']].copy()
        
        df.loc[df['session']>9,'session'] = 9
        
        # pdb.set_trace()
        
        df = df.set_index(['session', 'content_id'])
        
        for col in columns:
            df[col] = df.index.map(result[col])
            
        df.index = table.df_test_model.index
        
        feat = df[columns]
        
        # pdb.set_trace()
        
        return feat
    
    def update_intermediate_feat(self, table, tmp):
        return tmp
    
class feat_loop_group_session_corroct_rate(Feat):
    @timeclass('feat_loop_group_session_corroct_rate')
    def generate_feat(self,table):
        df = table.df_model[['user_id','session','label']].copy()
        
        df.loc[df['session']>9,'session'] = 9
        user_n = df['user_id'].nunique()
        k = 5
        
        np.random.seed(seed)
        rand_group = np.random.randint(0,k,user_n)
        
        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))

        
        columns = ['feat_loop_group_session_corroct_rate']
        
        tmp_list = []
        for i in range(k):
            tmp_a = df.loc[df['group']!=i].groupby('session')['label'].agg(['mean'])
            tmp_a.columns = columns
            
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i
        
            tmp_list.append(tmp_a)
        
        tmp = pd.concat(tmp_list,axis=0)
        

        
        df = df.merge(tmp,how='left',on=['group','session'])
        df.index = table.df_model.index

        feat = df[columns]

        #测试集两种方式，5个的mean；整体的mean
        #1
        result = tmp.groupby(['session'])[columns].mean()
        
        
        return feat,[result]
    
    # @timeclass('feat_loop_group_session_corroct_rate')
    def generate_test_feat(self,table,tmp):
        result, = tmp
        columns = ['feat_loop_group_session_corroct_rate']
        
        df = table.df_test_model[['session']].copy()
        df.loc[df['session']>9,'session'] = 9
        for col in columns:
            df[col] = df['session'].map(result[col])
        
        feat = df[columns]
        
        return feat

    # @timeclass('feat_loop_group_session_corroct_rate')
    def update_intermediate_feat(self,table,tmp):
        return tmp
    
    
    
    
class feat_use_every_session_question_num_and_correct_rate(Feat):
    @timeclass('feat_user_history_every_part_num_and_correct_rate')
    def generate_feat(self, table):
        df = table.df_model[ ['user_id', 'task_container_id','session','label']]
        
        df = pd.concat([df[['user_id', 'task_container_id','label']], pd.get_dummies(df['session'], prefix='session')], axis=1)
        for i in range(7):
            df['session_'+str(i)+'_question_correct_num'] = df['session_'+str(i)] & df['label']

        df = df.groupby(['user_id', 'task_container_id'], sort=False).sum()
        df = df.drop(['label'],axis=1)

        columns = [f'user_history_part{i}_nums' for i in range(7)]+ [f'user_history__correct_part{i}_nums' for i in range(7)]
        df.columns = columns
        df = df.groupby('user_id', sort=False).cumsum()
        result = df.groupby('user_id', sort=False).last()
        result2 = np.zeros((500000, 14))
        result2[result.index, :] = result.values

        df = df.groupby('user_id', sort=False).shift(1).fillna(0).astype(int)

        feat = table.df_model[['user_id', 'task_container_id']].copy()
        feat = feat.merge(df, how='left', on=['user_id', 'task_container_id'])
        feat_columns = [f'user_history_part{i}_correct_rate' for i in range(7)]
        for i in range(7):
            feat[feat_columns[i]] = feat[f'user_history__correct_part{i}_nums']/(feat[f'user_history_part{i}_nums']+1)
        all_columns  = columns+feat_columns
        feat = feat[all_columns]
        feat.index = table.df_model.index

        # unpate update_intermediate_feat时候用
        question2part = table.questions_info.set_index('question_id')['part']
        question2part = question2part - 1
        # df['part'] = df['content_id'].map(question2part)

        return feat, [result2, columns,question2part]

    # @timeclass('feat_user_question_history_every_answer_nums')
    def generate_test_feat(self, table, tmp):
        result, columns,question2part = tmp

        feat = pd.DataFrame(result[table.df_test_model['user_id'], :], index=table.df_test_model.index, columns=columns)
        feat_columns = [f'user_history_part{i}_correct_rate' for i in range(7)]
        for i in range(7):
            feat[feat_columns[i]] = feat[f'user_history__correct_part{i}_nums']/(feat[f'user_history_part{i}_nums']+1)
        all_columns  = columns+feat_columns
        feat = feat[all_columns]
        return feat

    # @timeclass('feat_user_question_history_every_answer_nums')
    def update_intermediate_feat(self, table, tmp):
        result, columns, question2part = tmp

        # 性能优化
        df = table.last_group[['content_type_id', 'user_id', 'content_id','answered_correctly']].copy()
        df['content_type_id'] = df['content_type_id'].astype(bool)
        df = df.loc[~df['content_type_id'], ['user_id','content_id','answered_correctly']]
        df['part'] = df['content_id'].map(question2part)

        for index,row in df.iterrows():
            result[row['user_id'],row['part']] += 1
            result[row['user_id'], row['part']+7] += row['answered_correctly']

        return [result, columns,question2part]
    


class feat_use_every_session_question_num_and_correct_rate(Feat):
    @timeclass('feat_use_every_session_question_num_and_correct_rate')
    def generate_feat(self, table):
        df = table.df_model[['user_id', 'content_id','session','label']].copy()
        
        df.loc[df['session']>9,'session'] = 9
        
        df['session'] = df['session'].astype(np.uint8)
        
        # pdb.set_trace()
        
        user_n = df['user_id'].nunique()
        k = 5
        smoothly_n = 20
        
        np.random.seed(seed)
        rand_group = np.random.randint(0,k,user_n)
        
        df['group'] = pd.Categorical(df['user_id']).codes
        df['group'] = df['group'].map(pd.Series(rand_group))
        
        
        df1 = pd.concat([df, pd.get_dummies(df['session'], prefix='session')], axis=1)
        
        
        
        columns1 = [f'session_{i}' for i in range(10)]
        columns2 = [f'session_{i}_question_correct_num' for i in range(10)]
        
        columns = columns1+columns2
        
        df1[columns1] = df1[columns1].astype(bool)
        df['label'] = df['label'].astype(bool)
        
        # pdb.set_trace()
        
        for i in range(10):
            df1['session_'+str(i)+'_question_correct_num'] = df1['session_'+str(i)] & df1['label']
            
        
        columns1 = [f'session_{i}' for i in range(10)]
        columns2 = [f'session_{i}_question_correct_num' for i in range(10)]
        
        columns = columns1+columns2

        tmp_list = []
        for i in range(k):
            tmp_a = df1.loc[df1['group']!=i].groupby(['content_id','session'])[columns].agg(['sum']).astype('int')
            
            tmp_a.columns = columns
            
            tmp_a = tmp_a.reset_index()
            tmp_a['group'] = i
            tmp_list.append(tmp_a)
            
        tmp = pd.concat(tmp_list,axis=0)
    
        df = df.merge(tmp,how='left',on=['group','content_id','session'])
        
        df.index = table.df_model.index
        feat = df[columns]
        result = tmp.groupby(['session','content_id'])[columns].mean()
        
        # pdb.set_trace()
        
        return feat, [result]

    # @timeclass('feat_user_question_history_every_answer_nums')
    def generate_test_feat(self, table, tmp):
        # pdb.set_trace()
        result, = tmp
        
        columns1 = [f'session_{i}' for i in range(10)]
        
        columns2 = [f'session_{i}_question_correct_num' for i in range(10)]
       
        columns = columns1+columns2
        
        df = table.df_test_model[['session', 'content_id']].copy()
        
        df.loc[df['session']>9,'session'] = 9
        
        df = df.set_index(['session', 'content_id'])
        # pdb.set_trace()
        for col in columns:
            df[col] = df.index.map(result[col])
            
        df.index = table.df_test_model.index
        
        feat = df[columns]
        
        return feat

    # @timeclass('feat_user_question_history_every_answer_nums')
    def update_intermediate_feat(self, table, tmp):
        return tmp




    
class FirstGenerateFeatPipeline(FeatPipeline):
    def __init__(self):
        super(FirstGenerateFeatPipeline, self).__init__()
        self.main_init()

    def main_init(self):
        
        self.feats = [ 
            feat_loop_group_question_corroct_rate,
            feat_question_bundleid,
            feat_question_tags_encoding,
            feat_user_session,
            feat_question_part,
            feat_last_3_lecture_id,
            feat_new_container_id,
            # feat_user_this_question_history_nums_and_correct_nums_and_rate_join_time_interval,
            feat_user_history_question_nums_and_corroct_nums_and_rate,
            
            # feat_user_this_question_time_interval,
            # feat_user_this_question_history_nums_and_correct_nums_and_rate,
            
            feat_user_this_question_history_nums_and_correct_nums_and_rate_join_time_interval,
            feat_new_content_id,
            ]
        
        
        # self.feats = [ 
        #     # feat_user_this_question_history_nums_and_correct_nums_and_rate_join_time_interval
            
        #     # feat_user_this_question_time_interval,
        #     # feat_user_this_question_history_nums_and_correct_nums_and_rate,
            
        #     # feat_user_this_question_history_nums_and_correct_nums_and_rate_join_time_interval
        #        ]
        
        self.feats = []
        print('first running features num: ', len(self.feats))
        
class FirstMergeFeatPipeline(FeatPipeline):
    def __init__(self):
        super(FirstMergeFeatPipeline, self).__init__()
        self.main_init()

    def main_init(self):
        
        self.feats = [ 
            feat_loop_group_question_corroct_rate,
            feat_question_bundleid,
            feat_question_tags_encoding,
            feat_user_session,
            feat_question_part,
            feat_last_3_lecture_id,
            feat_new_container_id,
            # feat_user_this_question_history_nums_and_correct_nums_and_rate_join_time_interval,
            feat_user_history_question_nums_and_corroct_nums_and_rate,
            
            # feat_user_this_question_time_interval,
            # feat_user_this_question_history_nums_and_correct_nums_and_rate,
            
            feat_user_this_question_history_nums_and_correct_nums_and_rate_join_time_interval,
            feat_new_content_id,
            ]
        
        print('first feature merge num: ', len(self.feats))
        
    


class GenerateFeatPipeline(FeatPipeline):
    def __init__(self):
        super(GenerateFeatPipeline, self).__init__()
        self.main_init()

    def main_init(self):
        
        self.feats = [
            # feat_question_tags,
            feat_user_history_lecture_nums,
            # feat_question_asked_nums_and_corroct_nums_and_rate,
            # feat_question_first_tag,
            # feat_time_interval_of_the_last_question,
            feat_user_this_part_history_question_nums_and_corroct_nums_and_rate,
            # feat_user_this_part_history_lecture_nums,#基本没啥用啊，不过也可以先留着
            # user_in_task_container_rate,
            # wa_and_no_explanation,
            feat_user_history_rolling3_container_question_nums_and_corroct_nums_and_rate,
            # feat_question_bundle_id,
            
            #这四个全局特征的一致性，check
            feat_this_question_had_explanation_num_and_rate,
            feat_whole_user_lecture_nums,
            feat_whole_user_avg_questiontime,
            feat_whole_question_avg_questiontime,
            
            
            feat_about_last_N_Container_content_id,
            feat_about_last_N_Container_timestamp,
            # last_N_Container_question_correct_num_and_rate,
            # feat_timestamp
            
            feat_question_correct_answer,
            feat_user_question_history_every_answer_nums2,
            feat_question_first_tag6,
            # feat_user_history_rolling_k_container_question_nums_and_corroct_nums_and_rate, #先不加了，24列，跑得太慢，不过这个是有效果的，最后再加
            
            feat_question_tags_num,
            
            feat_user_history_loop_group_question_corroct_rate_mean,
            
            
            
            feat_loop_group_bundle_id_corroct_rate,
            feat_loop_group_tags_encoding_corroct_rate,
            
            
            feat_user_this_session_history_nums_and_correct_nums_and_rate,
            feat_loop_group_session_corroct_rate,
            
            # feat_continue_user_this_question_history_correct_and_incorrect_nums, #信息和this question的重合得太厉害了
            feat_session_timediff,
            feat_continue_user_history_correct_and_incorrect_nums,
            feat_this_container_question_and_lecture_nums,
            
            # feat_user_this_question_time_interval,
            
            
            # #天赐特征7个
            # feat_time_interval_of_the_second_question,
            
            # feat_user_this_part_last_question_time_interval,
            
            # feat_cur_container_question_num, #这个有了，feat_this_container_question_and_lecture_nums
            # feat_user_this_tag_questions_history_nums_and_correct_nums_and_rate,
            # feat_loop_group_question_part_corroct_rate,
            # feat_cur_container_loop_correct_rate_mean,
            
            # feat_user_this_tag_last_question_time_interval, # 很有用
            
            
            
            feat_user_this_part_history_loop_group_question_corroct_rate_mean,
            
            # # feat_loop_group_container_corroct_rate,
            
            # # feat_user_history_rolling_k_question_loop_group_question_corroct_rate_mean,
            
            #窦帅特征
            
            
            # feat_loop_group_qustionid_last1_lecture_id_corroct_rate,
            # feat_loop_group_qustionid_last1_lecture_tag_corroct_rate,
            # feat_loop_group_qustionid_last1_lecture_part_corroct_rate,
            # feat_loop_group_qustionid_last1_lecture_type_corroct_rate
            
            # feat_coec,
            
            # feat_user_coec,
            
            # feat_user_this_question_time_interval_k_list,
            # feat_user_this_question_history_label_k_list,
            # feat_user_this_question_history_label_rolling_k,
            # feat_user_this_question_history_elapsed_time_k_list,
            # feat_user_this_question_history_explanation_k_list,
            
            
            feat_user_time_interval_k_list,
            
            
            feat_user_this_part_time_interval_k_list,
            
            # feat_cur_container_loop_correct_rate_mean,
            
            # feat_user_this_tag_questions_history_nums_and_correct_nums_and_rate,
            # feat_user_this_tag_last_question_time_interval, # 很有用
            
            #question试过的，，tags都试试
            
            
            #不甘心的尝试，auc: 0.7948197142580915，好像还是没啥用
            # feat_user_this_question_time_interval_k_list,
            
            # feat_user_this_tags_time_interval_k_list,
            
            feat_user_this_tags_history_nums_and_correct_nums_and_rate_join_time_interval,
            #！！！feat_user_history_loop_group_question_corroct_rate_mean 这个groupby session搞一个
            # tag loop cummean
            
            #是不是有序的 container
            
            #距离上个lecture的条数，timediff
            
            #窦帅特征
            feat_this_question_last_lecture_num_and_rate,
            # feat_user_this_session_question_order_number,
            
            # base: 0.7909917951126094
            feat_user_container_id_diff1,   # 0.7921878561834392
            feat_user_this_question_container_num_interval,
            feat_user_this_part_question_container_num_interval,
            feat_user_this_question_question_num_interval,
            
            # feat_user_this_session_history_loop_group_question_corroct_rate_mean,
            
            # feat_loop_group_qustionid_last1_lecture_id_corroct_rate,
            feat_user_last_container_elapsed_time_sum,
            
            feat_user_this_session_container_id_diff1, #单跑看看
            
        ]

        
        self.feats = [feat_user_this_question_session_num_interval,
                      feat_user_this_part_question_session_num_interval,
                      feat_user_this_feat_question_tags_encoding_question_session_num_interval,]
        
        self.feats = [feat_loop_group_session_corroct_rate]
        
        self.feats = [feat_use_every_session_question_num_and_correct_rate]
        
        print('running features num: ', len(self.feats))
        
class MergeFeatPipeline(FeatPipeline):
    def __init__(self):
        super(MergeFeatPipeline, self).__init__()
        self.main_init()

    def main_init(self):
        self.feats = [
            # feat_question_tags,
            feat_user_history_lecture_nums,
            # feat_question_asked_nums_and_corroct_nums_and_rate,
            # feat_question_first_tag,
            # feat_time_interval_of_the_last_question,
            feat_user_this_part_history_question_nums_and_corroct_nums_and_rate,
            # feat_user_this_part_history_lecture_nums,#基本没啥用啊，不过也可以先留着
            # user_in_task_container_rate,
            # wa_and_no_explanation,
            feat_user_history_rolling3_container_question_nums_and_corroct_nums_and_rate,
            # feat_question_bundle_id,
            
            #这四个全局特征的一致性，check
            feat_this_question_had_explanation_num_and_rate,
            feat_whole_user_lecture_nums,
            feat_whole_user_avg_questiontime,
            feat_whole_question_avg_questiontime,
            
            
            feat_about_last_N_Container_content_id,
            feat_about_last_N_Container_timestamp,
            # last_N_Container_question_correct_num_and_rate,
            # feat_timestamp
            
            feat_question_correct_answer,
            feat_user_question_history_every_answer_nums2,
            feat_question_first_tag6,
            # feat_user_history_rolling_k_container_question_nums_and_corroct_nums_and_rate, #先不加了，24列，跑得太慢，不过这个是有效果的，最后再加
            
            feat_question_tags_num,
            
            feat_user_history_loop_group_question_corroct_rate_mean,
            
            
            
            feat_loop_group_bundle_id_corroct_rate,
            feat_loop_group_tags_encoding_corroct_rate,
            
            
            feat_user_this_session_history_nums_and_correct_nums_and_rate,
            feat_loop_group_session_corroct_rate,
            
            # feat_continue_user_this_question_history_correct_and_incorrect_nums, #信息和this question的重合得太厉害了
            feat_session_timediff,
            feat_continue_user_history_correct_and_incorrect_nums,
            feat_this_container_question_and_lecture_nums,
            
            # feat_user_this_question_time_interval,
            
            
            # #天赐特征7个
            # feat_time_interval_of_the_second_question,
            
            # feat_user_this_part_last_question_time_interval,
            
            # feat_cur_container_question_num, #这个有了，feat_this_container_question_and_lecture_nums
            # feat_user_this_tag_questions_history_nums_and_correct_nums_and_rate,
            # feat_loop_group_question_part_corroct_rate,
            # feat_cur_container_loop_correct_rate_mean,
            
            # feat_user_this_tag_last_question_time_interval, # 很有用
            
            
            
            feat_user_this_part_history_loop_group_question_corroct_rate_mean,
            
            # # feat_loop_group_container_corroct_rate,
            
            # # feat_user_history_rolling_k_question_loop_group_question_corroct_rate_mean,
            
            #窦帅特征
            
            
            # feat_loop_group_qustionid_last1_lecture_id_corroct_rate,
            # feat_loop_group_qustionid_last1_lecture_tag_corroct_rate,
            # feat_loop_group_qustionid_last1_lecture_part_corroct_rate,
            # feat_loop_group_qustionid_last1_lecture_type_corroct_rate
            
            # feat_coec,
            
            # feat_user_coec,
            
            # feat_user_this_question_time_interval_k_list,
            # feat_user_this_question_history_label_k_list,
            # feat_user_this_question_history_label_rolling_k,
            # feat_user_this_question_history_elapsed_time_k_list,
            # feat_user_this_question_history_explanation_k_list,
            
            
            feat_user_time_interval_k_list,
            
            
            feat_user_this_part_time_interval_k_list,
            
            # feat_cur_container_loop_correct_rate_mean,
            
            # feat_user_this_tag_questions_history_nums_and_correct_nums_and_rate,
            # feat_user_this_tag_last_question_time_interval, # 很有用
            
            #question试过的，，tags都试试
            
            
            #不甘心的尝试，auc: 0.7948197142580915，好像还是没啥用
            # feat_user_this_question_time_interval_k_list,
            
            # feat_user_this_tags_time_interval_k_list,
            
            feat_user_this_tags_history_nums_and_correct_nums_and_rate_join_time_interval,
            #！！！feat_user_history_loop_group_question_corroct_rate_mean 这个groupby session搞一个
            # tag loop cummean
            
            #是不是有序的 container
            
            #距离上个lecture的条数，timediff
            
            #窦帅特征
            feat_this_question_last_lecture_num_and_rate,
            
            # feat_user_this_session_history_loop_group_question_corroct_rate_mean,
            
            # feat_loop_group_qustionid_last1_lecture_id_corroct_rate,
            
            # base: 0.7909917951126094
            feat_user_container_id_diff1, # 0.7921878561834392
            # feat_user_this_session_container_num, # 0.7920183419980665 -1个万
            feat_user_this_question_container_num_interval, # 0.7923786946055553 +2个万
            feat_user_this_part_question_container_num_interval, # 0.7925642074288393  +2个万
            # feat_user_this_feat_question_tags_encoding_question_container_num_interval, # 0.7925989316049419 基本没啥用
            # feat_user_this_session_question_order_number, #  0.7922959586343549 -3个万
            # feat_user_this_question_question_num_interval, # 0.792648786437661 +1个万 内存消耗过大，放一下
            # feat_user_this_part_question_question_num_interval, #  0.7916607699737407 -1个千
            # feat_user_last_container_elapsed_time_sum, # 0.79239848953125 -2个万
            feat_user_this_session_container_id_diff1,  # 去掉feat_user_container_id_diff1单跑0.7925706429241586，加上0.7927564333866174
            
            # feat_user_container_id_max_diff1,
            # feat_user_this_question_session_num_interval,  # 0.792657452543696 1个万左右
            feat_user_this_part_question_session_num_interval, #  0.7927564333866174 +2个万
            
            
            #  0.7929847839756666 到这里有用的全加
            # feat_every_session_loop_group_question_corroct_rate, #  0.7926638751316227 -3个万
            # feat_user_every_session_question_num_and_correct_rate  # 0.7925662708975981 -4个万
            
            # feat_last_container_part_question_num_and_correct, # 0.7881927345899832 -4个千
            # feat_this_session_part_question_num_and_correct, #0.792186872846739 -8个万
            
            # feat_user_container_id_max, # 0.7922931256826705 -7个万
            
            # feat_user_this_feat_question_tags_encoding_question_session_num_interval, # 0.7925511764252919 没啥用
            #0.7925337327953458
            # feat_user_this_session_accumulated_time, #0.79223416507486 -4个万
             
        ]
        
        # self.feats = [ feat_dnn_question_tags,
        #               feat_question_part]
        
        # self.feats = [feat_loop_group_qustionid_last1_lecture_tag_corroct_rate]
        
        
        print('feature merge num: ', len(self.feats))    
    

if __name__ == '__main__':
    t1 = time.time()
    
    OPT_ROUNDS = 365
    fix_seed(seed)
    
    table = Table()
    
    
    if False or ((not offline) and (load is None)):
        #读原生的数据，只有第一遍运行才需要
        table.read_data()
        table.save_table()
    
    
    
    if load is not None:
        #直接加载训练好的模型
        print(f'use models {load}')
        table.read_info_data()
        model = load_pickle(all_model_dir+f'{load}')
    
    else:
        #直接读pkl，只有本地做特征的时候才需要load模型
        table.load_table()
        
        if valid:
            # valid_tmp, valid_index, valid_model_index = table.split_valid2(table)
            # pdb.set_trace()
            valid_tmp, valid_index, valid_model_index, train_index, train_model_index, useless_index, useless_model_index = table.split_valid3(table)
            
            dump_pickle(valid_index, feat_merge_dir+'valid_index.pkl')
            dump_pickle(valid_model_index, feat_merge_dir+'valid_model_index.pkl')
            
            
            dump_pickle(train_model_index, feat_merge_dir+'train_model_index.pkl')
            
            if valid_mode == 1:
                pass
            elif valid_mode == 2:
                valid_group_index = table.valid2group(valid_tmp)
                del valid_tmp
                gc.collect()
                table.valid_group_index = valid_group_index
                
                table.all_valid = table.df.loc[valid_index]
                table.all_valid_model = table.df_model.loc[valid_model_index]
                
                # table.df = table.df.loc[~table.df.index.isin(valid_index)]
                # table.df_model = table.df_model.loc[~table.df_model.index.isin(valid_model_index)]
                
                
                # table.all_useless = table.df.loc[useless_index]
                # table.all_useless_model = table.df_model.loc[useless_model_index]
                
                table.df = table.df.loc[train_index]
                table.df_model = table.df_model.loc[train_model_index]
                
                
                
                
        
        
        #首先生成基础数据特征
        first_generate_pipeline = FirstGenerateFeatPipeline()
        feat_engine = FeatEngine(first_generate_pipeline)
        
        
        if valid and valid_mode == 2:
            feat_engine.generate_group_feat(table)
            
            # table.df = pd.concat([table.df,table.all_valid,table.all_useless],axis=0).sort_index()
            # table.df_model = pd.concat([table.df_model,table.all_valid_model,table.all_useless_model],axis=0).sort_index()
            
            
            table.df = pd.concat([table.df,table.all_valid],axis=0).sort_index()
            table.df_model = pd.concat([table.df_model,table.all_valid_model],axis=0).sort_index()
        
        else:
            feat_engine.generate_feat(table)
        
        
        # 首先合并基础数据特征
        first_merge_pipeline = FirstMergeFeatPipeline()
        feat_engine = FeatEngine(first_merge_pipeline)
        table.df_model = feat_engine.merge_feat(table)
        
        if valid and valid_mode == 2:
            table.all_valid = table.df.loc[valid_index]
            table.all_valid_model = table.df_model.loc[valid_model_index]
            
            # table.df = table.df.loc[~table.df.index.isin(valid_index)]
            # table.df_model = table.df_model.loc[~table.df_model.index.isin(valid_model_index)]
            
            
                
            # table.all_useless = table.df.loc[useless_index]
            # table.all_useless_model = table.df_model.loc[useless_model_index]
                
            table.df = table.df.loc[train_index]
            table.df_model = table.df_model.loc[train_model_index]
        
        # 生成特征
        generate_pipeline = GenerateFeatPipeline()
        feat_engine = FeatEngine(generate_pipeline)
        
        if valid and valid_mode == 2:
            feat_engine.generate_group_feat(table)
            
            table.df = pd.concat([table.df,table.all_valid],axis=0).sort_index()
            table.df_model = pd.concat([table.df_model,table.all_valid_model],axis=0).sort_index()
        else:
            feat_engine.generate_feat(table)
            
        
        # 合并特征
        merge_pipeline = MergeFeatPipeline()
        feat_engine = FeatEngine(merge_pipeline)
        data = feat_engine.merge_feat(table)
        
        
        ###############特征不动的时候上面就可以注释掉###########################
        
        # 不这样加载了，服务器硬盘满了
        # 直接加载合并好的特征
        # data = load_pickle(feat_merge_dir+'feat_merge.pkl')
        
        print('load all data')
        
        model = Model(table)
        
        
        del table
        gc.collect()
        
        
        fix_seed(seed)
        
        if valid:
            
            valid_model_index = load_pickle(feat_merge_dir+'valid_model_index.pkl')
            
            train_model_index = load_pickle(feat_merge_dir+'train_model_index.pkl')
            
            test_data = data.loc[valid_model_index]
            train_data  = data.loc[train_model_index]
            
            print(f'test data {test_data.shape[0]}, train data {train_data.shape[0]}')
            # time_weight = get_time_weight(train_data)
            # print(f'cal time weight: max {np.max(time_weight)},min {np.min(time_weight)}')
            time_weight = None
            del data
            gc.collect()
            
            train_Y = train_data['label']
            train_X = train_data.drop(model.drop_list, axis=1)
            
            del train_data
            gc.collect()
            
            test_Y = test_data['label']
            test_X = test_data.drop(model.drop_list, axis=1)
            
            del test_data
            gc.collect()
            
            dump_pickle([train_X, train_Y], valid_train_data_dir+'valid_train_data_dir.pkl')
            dump_pickle([test_X, test_Y], valid_test_data_dir+'valid_test_data_dir.pkl')
            
            del train_X, train_Y, test_X, test_Y
            gc.collect()
            
            print(f'start train and valid')
            
            model.train_and_valid(time_weight)
            # model.train_and_batch_valid(data,OPT_ROUNDS)
            dump_pickle(model,all_model_dir+f'valid-{version}.models')
            
            different_history_num_auc(model)
            different_user_num_auc(model)
            
        else:
            
            train_data = data.sample(frac=1,random_state=seed)
            
            print(f'train data {train_data.shape[0]}')
            
            # time_weight = get_time_weight(train_data)
            # print(f'cal time weight: max {np.max(time_weight)},min {np.min(time_weight)}')
            time_weight = None
            del data
            gc.collect()
            
            train_Y = train_data['label']
            train_X = train_data.drop(model.drop_list, axis=1)
            
            del train_data
            gc.collect()
            
            dump_pickle([train_X, train_Y], train_data_dir+'train_data_dir.pkl')
            
            del train_X, train_Y
            gc.collect()
            
            print(f'OPT_ROUNDS: {OPT_ROUNDS}')
            print(f'start train ')
            
            model.train(OPT_ROUNDS,time_weight)
            dump_pickle(model,all_model_dir+f'{version}.models')
            
    if (not valid) and offline and (not debug) and (load is None):
        make_submit_zip()
    
    
    if False and (not valid) and offline and (debug) and (load is None):
        make_small_model_big_data_submit_zip()
            
    t2 = time.time()
    print(f'total time {t2-t1:.2f}sec')
    
    table = Table()
    table.read_info_data()
    
    test = Test()
    test.predict_test(table,FeatEngine(FirstMergeFeatPipeline()),FeatEngine(MergeFeatPipeline()),model)
    
    
    # base：0.7911
